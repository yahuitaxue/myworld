---
title: MySQL优化
author: Yahui
layout: sql
category: SQL
---

书名：《---》

<pre style="text-align: left;">

主要就是围绕这两个来的。

SHOW VARIABLES;

SHOW STATUS;

<h1>以下摘自网络</h1>
用 status信息对mysql进行具体的优化。

mysql> show global status;

　　可以列出mysql服务器运行各种状态值,另外,查询mysql服务器配置信息语句：

mysql> show variables;

一、慢查询

mysql> show variables like 'slow%';
+------------------+-------+
| variable_name　　　　 | value |
+------------------+-------+
| log_slow_queries | on　　　　 |
| slow_launch_time | 2　　　　　 |
+------------------+-------+

mysql> show global status like 'slow%';
+---------------------+-------+
| variable_name　　　　　　　 | value |
+---------------------+-------+
| slow_launch_threads | 0　　　　　 |
| slow_queries　　　　　　　　 | 4148 |
+---------------------+-------+ 

配 置中打开了记录慢查询,执行时间超过2秒的即为慢查询,系统显示有4148个慢查询,你可以分析慢查询日志,找出有问题的sql语句,慢查询时间不宜设置 过长,否则意义不大,最好在5秒以内,如果你需要微秒级别的慢查询,可以考虑给mysql打补丁：http://www.percona.com /docs/wiki/release:start,记得找对应的版本。

打开慢查询日志可能会对系统性能有一点点影响,如果你的mysql是主－从结构,可以考虑打开其中一台从服务器的慢查询日志,这样既可以监控慢查询,对系统性能影响又小。

二、连接数

经 常会遇见”mysql: error 1040: too many connections”的情况,一种是访问量确实很高,mysql服务器抗不住,这个时候就要考虑增加从服务器分散读压力,另外一种情况是mysql配 置文件中max_connections值过小：

mysql> show variables like 'max_connections';
+-----------------+-------+
| variable_name　　　 | value |
+-----------------+-------+
| max_connections | 256　　 |
+-----------------+-------+

这台mysql服务器最大连接数是256,然后查询一下服务器响应的最大连接数：

mysql> show global status like 'max_used_connections';

mysql服务器过去的最大连接数是245,没有达到服务器连接数上限256,应该没有出现1040错误,比较理想的设置是

max_used_connections / max_connections * 100% ≈ 85%

最大连接数占上限连接数的85％左右,如果发现比例在10%以下,mysql服务器连接数上限设置的过高了。

三、key_buffer_size

key_buffer_size是对myisam表性能影响最大的一个参数,下面一台以myisam为主要存储引擎服务器的配置：

mysql> show variables like 'key_buffer_size';

+-----------------+------------+
| variable_name　　　 | value　　　　　　 |
+-----------------+------------+
| key_buffer_size | 536870912 |
+-----------------+------------+

分配了512mb内存给key_buffer_size,我们再看一下key_buffer_size的使用情况：

mysql> show global status like 'key_read%';
+------------------------+-------------+
| variable_name　　　　　　　　　　 | value　　　　　　　 |
+------------------------+-------------+
| key_read_requests　　　　　　 | 27813678764 |
| key_reads　　　　　　　　　　　　　　 | 6798830　　　　　 |
+------------------------+-------------+

　　一共有27813678764个索引读取请求,有6798830个请求在内存中没有找到直接从硬盘读取索引,计算索引未命中缓存的概率：

key_cache_miss_rate ＝ key_reads / key_read_requests * 100%

比 如上面的数据,key_cache_miss_rate为0.0244%,4000个索引读取请求才有一个直接读硬盘,已经很bt 了,key_cache_miss_rate在0.1%以下都很好（每1000个请求有一个直接读硬盘）,如果key_cache_miss_rate在 0.01%以下的话,key_buffer_size分配的过多,可以适当减少。

mysql服务器还提供了key_blocks_*参数：

mysql> show global status like 'key_blocks_u%';
+------------------------+-------------+
| variable_name　　　　　　　　　　 | value　　　　　　　 |
+------------------------+-------------+
| key_blocks_unused　　　　　　 | 0　　　　　　　　　　　 |
| key_blocks_used　　　　　　　　 | 413543　　　　　　 |
+------------------------+-------------+

key_blocks_unused 表示未使用的缓存簇(blocks)数,key_blocks_used表示曾经用到的最大的blocks数,比如这台服务器,所有的缓存都用到了,要么 增加key_buffer_size,要么就是过渡索引了,把缓存占满了。比较理想的设置：

key_blocks_used / (key_blocks_unused + key_blocks_used) * 100% ≈ 80%

四、临时表

mysql> show global status like 'created_tmp%';
+-------------------------+---------+
| variable_name　　　　　　　　　　　 | value　　　 |
+-------------------------+---------+
| created_tmp_disk_tables | 21197　　　 |
| created_tmp_files　　　　　　　 | 58　　　　　　 |
| created_tmp_tables　　　　　　 | 1771587 |
+-------------------------+---------+

每次创建临时表,created_tmp_tables增加,如果是在磁盘上创建临时表,created_tmp_disk_tables也增加,created_tmp_files表示mysql服务创建的临时文件文件数,比较理想的配置是：

　 　created_tmp_disk_tables / created_tmp_tables * 100% <= 25%比如上面的服务器created_tmp_disk_tables / created_tmp_tables * 100% ＝ 1.20%,应该相当好了。我们再看一下mysql服务器对临时表的配置：

mysql> show variables where variable_name in ('tmp_table_size', 'max_heap_table_size');
+---------------------+-----------+
| variable_name　　　　　　　 | value　　　　　 |
+---------------------+-----------+
| max_heap_table_size | 268435456 |
| tmp_table_size　　　　　　 | 536870912 |
+---------------------+-----------+

只有256mb以下的临时表才能全部放内存,超过的就会用到硬盘临时表。

五、open table情况

mysql> show global status like 'open%tables%';
+---------------+-------+
| variable_name | value |
+---------------+-------+
| open_tables　　　 | 919　　　 |
| opened_tables | 1951　 |
+---------------+-------+

open_tables 表示打开表的数量,opened_tables表示打开过的表数量,如果opened_tables数量过大,说明配置中 table_cache(5.1.3之后这个值叫做table_open_cache)值可能太小,我们查询一下服务器table_cache值：

mysql> show variables like 'table_cache';
+---------------+-------+
| variable_name | value |
+---------------+-------+
| table_cache　　　 | 2048　 |
+---------------+-------+

比较合适的值为：

open_tables / opened_tables * 100% >= 85%

open_tables / table_cache * 100% <= 95%

六、进程使用情况

mysql> show global status like 'thread%';
+-------------------+-------+
| variable_name　　　　　 | value |
+-------------------+-------+
| threads_cached　　　　 | 46　　　　 |
| threads_connected | 2　　　　　 |
| threads_created　　　 | 570　　　 |
| threads_running　　　 | 1　　　　　 |
+-------------------+-------+

如 果我们在mysql服务器配置文件中设置了thread_cache_size,当客户端断开之后,服务器处理此客户的线程将会缓存起来以响应下一个客户 而不是销毁（前提是缓存数未达上限）。threads_created表示创建过的线程数,如果发现threads_created值过大的话,表明 mysql服务器一直在创建线程,这也是比较耗资源,可以适当增加配置文件中thread_cache_size值,查询服务器 thread_cache_size配置：

mysql> show variables like 'thread_cache_size';
+-------------------+-------+
| variable_name　　　　　 | value |
+-------------------+-------+
| thread_cache_size | 64　　　　 |
+-------------------+-------+

示例中的服务器还是挺健康的。

七、查询缓存(query cache)

mysql> show global status like 'qcache%';
+-------------------------+-----------+
| variable_name　　　　　　　　　　　 | value　　　　　 |
+-------------------------+-----------+
| qcache_free_blocks　　　　　　 | 22756　　　　　 |
| qcache_free_memory　　　　　　 | 76764704　 |
| qcache_hits　　　　　　　　　　　　　 | 213028692 |
| qcache_inserts　　　　　　　　　　 | 208894227 |
| qcache_lowmem_prunes　　　　 | 4010916　　　 |
| qcache_not_cached　　　　　　　 | 13385031　 |
| qcache_queries_in_cache | 43560　　　　　 |
| qcache_total_blocks　　　　　 | 111212　　　　 |
+-------------------------+-----------+

mysql查询缓存变量解释：

qcache_free_blocks：缓存中相邻内存块的个数。数目大说明可能有碎片。flush query cache会对缓存中的碎片进行整理,从而得到一个空闲块。

qcache_free_memory：缓存中的空闲内存。

qcache_hits：每次查询在缓存中命中时就增大

qcache_inserts：每次插入一个查询时就增大。命中次数除以插入次数就是不中比率。

qcache_lowmem_prunes： 缓存出现内存不足并且必须要进行清理以便为更多查询提供空间的次数。这个数字最好长时间来看；如果这个数字在不断增长,就表示可能碎片非常严重,或者内存 很少。（上面的 free_blocks和free_memory可以告诉您属于哪种情况）

qcache_not_cached：不适合进行缓存的查询的数量,通常是由于这些查询不是 select 语句或者用了now()之类的函数。

qcache_queries_in_cache：当前缓存的查询（和响应）的数量。

qcache_total_blocks：缓存中块的数量。

我们再查询一下服务器关于query_cache的配置：

mysql> show variables like 'query_cache%';
+------------------------------+-----------+
| variable_name　　　　　　　　　　　　　　　　 | value　　　　　 |
+------------------------------+-----------+
| query_cache_limit　　　　　　　　　　　　 | 2097152　　　 |
| query_cache_min_res_unit　　　　　 | 4096　　　　　　 |
| query_cache_size　　　　　　　　　　　　　 | 203423744 |
| query_cache_type　　　　　　　　　　　　　 | on　　　　　　　　 |
| query_cache_wlock_invalidate | off　　　　　　　 |
+------------------------------+-----------+

各字段的解释：

query_cache_limit：超过此大小的查询将不缓存

query_cache_min_res_unit：缓存块的最小大小

query_cache_size：查询缓存大小

query_cache_type：缓存类型,决定缓存什么样的查询,示例中表示不缓存 select sql_no_cache 查询

query_cache_wlock_invalidate：当有其他客户端正在对myisam表进行写操作时,如果查询在query cache中,是否返回cache结果还是等写操作完成再读表获取结果。

query_cache_min_res_unit的配置是一柄”双刃剑”,默认是4kb,设置值大对大数据查询有好处,但如果你的查询都是小数据查询,就容易造成内存碎片和浪费。

查询缓存碎片率 = qcache_free_blocks / qcache_total_blocks * 100%

如果查询缓存碎片率超过20%,可以用flush query cache整理缓存碎片,或者试试减小query_cache_min_res_unit,如果你的查询都是小数据量的话。

查询缓存利用率 = (query_cache_size - qcache_free_memory) / query_cache_size * 100%

查询缓存利用率在25%以下的话说明query_cache_size设置的过大,可适当减小；查询缓存利用率在80％以上而且qcache_lowmem_prunes > 50的话说明query_cache_size可能有点小,要不就是碎片太多。

查询缓存命中率 = (qcache_hits - qcache_inserts) / qcache_hits * 100%

示例服务器 查询缓存碎片率 ＝ 20.46％,查询缓存利用率 ＝ 62.26％,查询缓存命中率 ＝ 1.94％,命中率很差,可能写操作比较频繁吧,而且可能有些碎片。

八、排序使用情况

mysql> show global status like 'sort%';
+-------------------+------------+
| variable_name　　　　　 | value　　　　　　 |
+-------------------+------------+
| sort_merge_passes | 29　　　　　　　　　 |
| sort_range　　　　　　　　 | 37432840　　　 |
| sort_rows　　　　　　　　　 | 9178691532 |
| sort_scan　　　　　　　　　 | 1860569　　　　 |
+-------------------+------------+

sort_merge_passes 包括两步。mysql 首先会尝试在内存中做排序,使用的内存大小由系统变量 sort_buffer_size 决定,如果它的大小不够把所有的记录都读到内存中,mysql 就会把每次在内存中排序的结果存到临时文件中,等 mysql 找到所有记录之后,再把临时文件中的记录做一次排序。这再次排序就会增加 sort_merge_passes。实际上,mysql 会用另一个临时文件来存再次排序的结果,所以通常会看到 sort_merge_passes 增加的数值是建临时文件数的两倍。因为用到了临时文件,所以速度可能会比较慢,增加 sort_buffer_size 会减少 sort_merge_passes 和 创建临时文件的次数。但盲目的增加 sort_buffer_size 并不一定能提高速度,见 how fast can you sort data with mysql?（引自http://qroom.blogspot.com/2007/09/mysql-select-sort.html,貌似被墙）

另外,增加read_rnd_buffer_size(3.2.3是record_rnd_buffer_size)的值对排序的操作也有一点的好处,参见：http://www.mysqlperformanceblog.com/2007/07/24/what-exactly-is-read_rnd_buffer_size/

九、文件打开数(open_files)

mysql> show global status like 'open_files';
+---------------+-------+
| variable_name | value |
+---------------+-------+
| open_files　　　　 | 1410　 |
+---------------+-------+

mysql> show variables like 'open_files_limit';
+------------------+-------+
| variable_name　　　　 | value |
+------------------+-------+
| open_files_limit | 4590　 |
+------------------+-------+

比较合适的设置：open_files / open_files_limit * 100% <= 75％

十、表锁情况

mysql> show global status like 'table_locks%';
+-----------------------+-----------+
| variable_name　　　　　　　　　 | value　　　　　 |
+-----------------------+-----------+
| table_locks_immediate | 490206328 |
| table_locks_waited　　　　 | 2084912　　　 |
+-----------------------+-----------+

　 　table_locks_immediate表示立即释放表锁数,table_locks_waited表示需要等待的表锁数,如果 table_locks_immediate / table_locks_waited > 5000,最好采用innodb引擎,因为innodb是行锁而myisam是表锁,对于高并发写入的应用innodb效果会好些。示例中的服务器 table_locks_immediate / table_locks_waited ＝ 235,myisam就足够了。

十一、表扫描情况

mysql> show global status like 'handler_read%';
+-----------------------+-------------+
| variable_name　　　　　　　　　 | value　　　　　　　 |
+-----------------------+-------------+
| handler_read_first　　　　 | 5803750　　　　　 |
| handler_read_key　　　　　　 | 6049319850　 |
| handler_read_next　　　　　 | 94440908210 |
| handler_read_prev　　　　　 | 34822001724 |
| handler_read_rnd　　　　　　 | 405482605　　　 |
| handler_read_rnd_next | 18912877839 |
+-----------------------+-------------+

各字段解释参见http://hi.baidu.com/thinkinginlamp/blog/item/31690cd7c4bc5cdaa144df9c.html,调出服务器完成的查询请求次数：

mysql> show global status like 'com_select';
+---------------+-----------+
| variable_name | value　　　　　 |
+---------------+-----------+
| com_select　　　　 | 222693559 |
+---------------+-----------+

计算表扫描率：

表扫描率 ＝ handler_read_rnd_next / com_select

如果表扫描率超过4000,说明进行了太多表扫描,很有可能索引没有建好,增加read_buffer_size值会有一些好处,但最好不要超过8mb。


1.原子性是指事务的原子性操作,对数据的修改要么全部执行成功,要么全部失败,实现事务的原子性,是基于日志的Redo/Undo机制。
2.一致性是指执行事务前后的状态要一致,可以理解为数据一致性,使数据库从一个一致性状态变到另一个一致性状态。
3.隔离性侧重指事务之间相互隔离,不受影响,这个与事务设置的隔离级别有密切的关系。
4.持久性则是指在一个事务提交后,这个事务的状态会被持久化到数据库中,也就是事务提交,对数据的新增、更新将会持久化到数据库中。

Redo/Undo机制
    Redo/Undo机制比较简单,它们将所有对数据的更新操作都写到日志中。
    Redo log用来记录某数据块被修改后的值,可以用来恢复未写入 data file 的已成功事务更新的数据；Undo log是用来记录数据更新前的值,保证数据更新失败能够回滚。
    假如数据库在执行的过程中,不小心崩了,可以通过该日志的方式,回滚之前已经执行成功的操作,实现事务的一致性。

mysql 四种隔离级别
一、将A的隔离级别设置为read uncommitted(读未提交)
    set session transaction isolation level read uncommitted;
    查看隔离级别是否设置成功
    select @@transaction_isolation （mysql版本 8.0 以后）
    select @@tx_isolation （mysql版本 8.0 之前）
    查看mysql版本 
    > status
    A：启动事务,此时数据为初始状态
     start transaction;
    B：启动事务,更新数据,但不提交
     start transaction;
    A：再次读取数据,发现数据已经被修改了,这就是所谓的“脏读”
    B：回滚事务
    rollback;
    A：再次读数据,发现数据变回初始状态
    经过上面的实验可以得出结论,事务B更新了一条记录,但是没有提交,此时事务A可以查询出未提交记录。造成脏读现象。未提交读是最低的隔离级别。
二、将客户端A的事务隔离级别设置为read committed(读已提交)(一般是对于update的操作)(大多数数据库系统的默认隔离级别)
    set session transaction isolation level read committed;
    A：启动事务,此时数据为初始状态
    B：启动事务,更新数据,但不提交
    A：再次读数据,发现数据未被修改
    B：提交事务
    A：再次读取数据,发现数据已发生变化,说明B提交的修改被事务中的A读到了,这就是所谓的“不可重复读”
    经过上面的实验可以得出结论,已提交读隔离级别解决了脏读的问题,但是出现了不可重复读的问题,即事务A在两次查询的数据不一致,因为在两次查询之间事务B更新了一条数据。已提交读只允许读取已提交的记录,但不要求可重复读。

三、将A的隔离级别设置为repeatable read(可重复读)(一般是针对inser操作)(MySQL的默认事务隔离级别)
    A：启动事务,此时数据为初始状态
    B：启动事务,更新数据,但不提交
    A：再次读取数据,发现数据未被修改
    B：提交事务
    A：再次读取数据,发现数据依然未发生变化,这说明这次可以重复读了
    B：插入一条新的数据,并提交
    A：再次读取数据,发现数据依然未发生变化,虽然可以重复读了,但是却发现读的不是最新数据,这就是所谓的“幻读”
    A：提交本次事务,再次读取数据,发现读取正常了
    由以上的实验可以得出结论,可重复读隔离级别只允许读取已提交记录,而且在一个事务两次读取一个记录期间,其他事务部的更新该记录。但该事务不要求与其他事务可串行化。例如,当一个事务可以找到由一个已提交事务更新的记录,但是可能产生幻读问题(注意是可能,因为数据库对隔离级别的实现有所差别)。像以上的实验,就没有出现数据幻读的问题

四、将A的隔离级别设置为可串行化(Serializable)
    A：启动事务,此时数据为初始状态
    B：发现B此时进入了等待状态,原因是因为A的事务尚未提交,只能等待（此时,B可能会发生等待超时）
    A：提交事务
    B：发现插入成功
    serializable完全锁定字段,若一个事务来查询同一份数据就必须等待,直到前一个事务完成并解除锁定为止。是完整的隔离级别,会锁定对应的数据表格,因而会有效率的问题。
    注:四大等级从上到下,隔离的效果是逐渐增强,但是性能却是越来越差
    数据库查询只能用到一个索引：倒不是说是和全表扫描/只使用一个索引的速度比起来,去分析两个索引二叉树更加耗费时间,所以绝大多数情况下数据库都是是用一个索引。
    如这条语句：
    select count(1) from table1 where column1 = 1 and column2 = 'foo' and column3 = 'bar'
我们来想象一下当数据库有N个索引并且查询中分别都要用上他们的情况：
    查询优化器（用大白话说就是生成执行计划的那个东西）需要进行N次主二叉树查找[这里主二叉树的意思是最外层的索引节点],此处的查找流程大概如下：
    查出第一条column1主二叉树等于1的值,然后去第二条column2主二叉树查出foo的值并且当前行的coumn1必须等于1,最后去column主二叉树查找bar的值并且column1必须等于1和column2必须等于foo。
    如果这样的流程被查询优化器执行一遍,就算不死也半条命了,查询优化器可等不及把以上计划都执行一遍,贪婪算法（最近邻居算法）可不允许这种情况的发生,所以当遇到以下语句的时候,数据库只要用到第一个筛选列的索引（column1）,就会直接去进行表扫描了。
    所以与其说是数据库只支持一条查询语句只使用一个索引,倒不如说N条独立索引同时在一条语句使用的消耗比只使用一个索引还要慢。所以如上条的情况,最佳推荐是使用index(column1,column2,column3） 这种联合索引,此联合索引可以把b+tree结构的优势发挥得淋漓尽致：
        一条主二叉树（column=1）,查询到column=1节点后基于当前节点进行二级二叉树column2=foo的查询,在二级二叉树查询到column2=foo后,去三级二叉树column3=bar查找。
        
MySQL索引那些事
    二叉树
        即二叉搜索树：
        1、所有非叶子结点至多拥有两个儿子（Left和Right）；
        2、所有结点存储一个关键字；
        3、非叶子结点的左指针指向小于其关键字的子树,右指针指向大于其关键字的子树；
        一个二叉树如果一直在单边增长,没有左子树。就和链表很像,也就是说二叉树在某些场景下退化成了链表,链表的查找是需要从头部遍历,这时候和没加索引从表的第一行遍历是没什么区别？这就是mysql索引底层没有使用二叉树这种数据结构的原因之一。
    如：
    <span class="image featured"><img src="{{ 'assets/images/other/mysqlbtree.jpg' | relative_url }}" alt="" /></span>
    
    红黑树
        是一种平衡二叉树,当有单边增长的趋势时红黑树会进行一个平衡（旋转）比二叉树又有了改进。
        当数据量越多,红黑树的树越高遍历次数会越多,会因为树的高度影响查询效率。所以我们要解决的问题就是减少树的高度,尽量控制它的高度在一个阈值范围内。
        
    B树(B-树)
        是一种多路搜索树（并不是二叉的）：
        1、定义任意非叶子结点最多只有M个儿子；且M>2；
        2、根结点的儿子数为[2, M]；
        3、除根结点以外的非叶子结点的儿子数为[M/2, M]；
        4、每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字）
        5、非叶子结点的关键字个数=指向儿子的指针个数-1；
        6、非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] < K[i+1]；
        7、非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树,P[M]指向关键字大于K[M-1]的子树,其它P[i]指向关键字属于(K[i-1], K[i])的子树；
        8、所有叶子结点位于同一层；
        如：（M=3）
        <span class="image featured"><img src="{{ 'assets/images/other/msyqlb-tree.jpg' | relative_url }}" alt="" /></span>
        B-树的搜索,从根结点开始,对结点内的关键字（有序）序列进行二分查找,如果命中则结束,否则进入查询关键字所属范围的儿子结点；重复,直到所对应的儿子指针为空,或已经是叶子结点；
        B-树的特性：
        1、关键字集合分布在整颗树中；
        2、任何一个关键字出现且只出现在一个结点中；
        3、搜索有可能在非叶子结点结束；
        4、其搜索性能等价于在关键字全集内做一次二分查找；
        5、自动层次控制；
        由于限制了除根结点以外的非叶子结点,至少含有M/2个儿子,确保了结点的至少利用率。
        所以B-树的性能总是等价于二分查找（与M值无关）,也就没有B树平衡的问题；
        由于M/2的限制,在插入结点时,如果结点已满,需要将结点分裂为两个各占M/2的结点；删除结点时,需将两个不足M/2的兄弟结点合并；
        B-树的插入操作
            插入操作是指插入一条记录,即（key, value）的键值对。如果B-树中已存在需要插入的键值对,则用需要插入的value替换旧的value。若B-树不存在这个key,则一定是在叶子结点中进行插入操作。
            1）根据要插入的key的值,找到叶子结点并插入。
            2）判断当前结点key的个数是否小于等于m-1,若满足则结束,否则进行第3步。
            3）以结点中间的key为中心分裂成左右两部分,然后将这个中间的key插入到父结点中,这个key的左子树指向分裂后的左半部分,这个key的右子支指向分裂后的右半部分,然后将当前结点指向父结点,继续进行第3步。 
        B-树的删除操作
            删除操作是指,根据key删除记录,如果B-树中的记录中不存对应key的记录,则删除失败。
            1）如果当前需要删除的key位于非叶子结点上,则用后继key（这里的后继key均指后继记录的意思）覆盖要删除的key,然后在后继key所在的子支中删除该后继key。此时后继key一定位于叶子结点上,这个过程和二叉搜索树删除结点的方式类似。删除这个记录后执行第2步
            2）该结点key个数大于等于Math.ceil(m/2)-1,结束删除操作,否则执行第3步。
            3）如果兄弟结点key个数大于Math.ceil(m/2)-1,则父结点中的key下移到该结点,兄弟结点中的一个key上移,删除操作结束。
            否则,将父结点中的key下移与当前结点及它的兄弟结点中的key合并,形成一个新的结点。原父结点中的key的两个孩子指针就变成了一个孩子指针,指向这个新结点。然后当前结点的指针指向父结点,重复上第2步。
            有些结点它可能即有左兄弟,又有右兄弟,那么我们任意选择一个兄弟结点进行操作即可。
    B+树
        B+树是B-树的变体,也是一种多路搜索树：
        1、其定义基本与B-树同,除了：
        2、非叶子结点的子树指针与关键字个数相同；
        3、非叶子结点的子树指针P[i],指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）；
        5、为所有叶子结点增加一个链指针；
        6、所有关键字都在叶子结点出现；
        如：（M=3）
        <span class="image featured"><img src="{{ 'assets/images/other/mysqlb+tree.jpg' | relative_url }}" alt="" /></span>
        B+的搜索与B-树也基本相同,区别是B+树只有达到叶子结点才命中（B-树可以在
        非叶子结点命中）,其性能也等价于在关键字全集做一次二分查找；
        B+的特性：
            1、所有关键字都出现在叶子结点的链表中（稠密索引）,且链表中的关键字恰好是有序的；
            2、不可能在非叶子结点命中；
            3、非叶子结点相当于是叶子结点的索引（稀疏索引）,叶子结点相当于是存储（关键字）数据的数据层；
            4、更适合文件索引系统；
            了解B-/B+树的概念之后,我们继续分析B+树提高效率的原理。
    B+树索引原理
        <span class="image featured"><img src="{{ 'assets/images/other/mysqlb+treeinfo.jpg' | relative_url }}" alt="" /></span>
        如上图,是一颗B+树,关于B+树的定义可以参见B+树,这里只说一些重点,浅蓝色的块我们称之为一个磁盘块,可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示）,如磁盘块1包含数据项17和35,包含指针P1、P2、P3,P1表示小于17的磁盘块,P2表示在17和35之间的磁盘块,P3表示大于35的磁盘块。真实的数据存在于叶子节点即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点只不存储真实的数据,只存储指引搜索方向的数据项,如17、35并不真实存在于数据表中。
    B+树的查找过程
        如图所示,如果要查找数据项29,那么首先会把磁盘块1由磁盘加载到内存,此时发生一次IO,在内存中用二分查找确定29在17和35之间,锁定磁盘块1的P2指针,内存时间因为非常短（相比磁盘的IO）可以忽略不计,通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存,发生第二次IO,29在26和30之间,锁定磁盘块3的P2指针,通过指针加载磁盘块8到内存,发生第三次IO,同时内存中做二分查找找到29,结束查询,总计三次IO。真实的情况是,3层的B+树可以表示上百万的数据,如果上百万的数据查找只需要三次IO,性能提高将是巨大的,如果没有索引,每个数据项都要发生一次IO,那么总共需要百万次的IO,显然成本非常非常高。
    B+树性质
        1、通过上面的分析,我们知道IO次数取决于b+数的高度h,假设当前数据表的数据为N,每个磁盘块的数据项的数量是m,则有h=㏒(m+1)N,当数据量N一定的情况下,m越大,h越小；而m = 磁盘块的大小 / 数据项的大小,磁盘块的大小也就是一个数据页的大小,是固定的,如果数据项占的空间越小,数据项的数量越多,树的高度越低。这就是为什么每个数据项,即索引字段要尽量的小,比如int占4字节,要比bigint8字节少一半。这也是为什么B+树要求把真实的数据放到叶子节点而不是内层节点,一旦放到内层节点,磁盘块的数据项会大幅度下降,导致树增高。当数据项等于1时将会退化成线性表。
        2、当B+树的数据项是复合的数据结构,比如(name,age,sex)的时候,B+数是按照从左到右的顺序来建立搜索树的,比如当(张三,20,F)这样的数据来检索的时候,B+树会优先比较name来确定下一步的所搜方向,如果name相同再依次比较age和sex,最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候,B+树就不知道下一步该查哪个节点,因为建立搜索树的时候name就是第一个比较因子,必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时,B+树可以用name来指定搜索方向,但下一个字段age的缺失,所以只能把名字等于张三的数据都找到,然后再匹配性别是F的数据了, 这个是非常重要的性质,即索引的最左匹配特性。
    B+树的插入操作
        1）若为空树,创建一个叶子结点,然后将记录插入其中,此时这个叶子结点也是根结点,插入操作结束。
        2）针对叶子类型结点：根据key值找到叶子结点,向这个叶子结点插入记录。插入后,若当前结点key的个数小于等于m-1,则插入结束。否则将这个叶子结点分裂成左右两个叶子结点,左叶子结点包含前m/2个记录,右结点包含剩下的记录,将第m/2+1个记录的key进位到父结点中（父结点一定是索引类型结点）,进位到父结点的key左孩子指针向左结点,右孩子指针向右结点。将当前结点的指针指向父结点,然后执行第3步。
        3）针对索引类型结点：若当前结点key的个数小于等于m-1,则插入结束。否则,将这个索引类型结点分裂成两个索引结点,左索引结点包含前(m-1)/2个key,右结点包含m-(m-1)/2个key,将第m/2个key进位到父结点中,进位到父结点的key左孩子指向左结点, 进位到父结点的key右孩子指向右结点。将当前结点的指针指向父结点,然后重复第3步。
    B+树的删除操作
        如果叶子结点中没有相应的key,则删除失败。否则执行下面的步骤
        1）删除叶子结点中对应的key。删除后若结点的key的个数大于等于Math.ceil(m-1)/2 – 1,删除操作结束,否则执行第2步。
        2）若兄弟结点key有富余（大于Math.ceil(m-1)/2 – 1）,向兄弟结点借一个记录,同时用借到的key替换父结（指当前结点和兄弟结点共同的父结点）点中的key,删除结束。否则执行第3步。
        3）若兄弟结点中没有富余的key,则当前结点和兄弟结点合并成一个新的叶子结点,并删除父结点中的key（父结点中的这个key两边的孩子指针就变成了一个指针,正好指向这个新的叶子结点）,将当前结点指向父结点（必为索引结点）,执行第4步（第4步以后的操作和B树就完全一样了,主要是为了更新索引结点）。
        4）若索引结点的key的个数大于等于Math.ceil(m-1)/2 – 1,则删除操作结束。否则执行第5步
        5）若兄弟结点有富余,父结点key下移,兄弟结点key上移,删除结束。否则执行第6步
        6）当前结点和兄弟结点及父结点下移key合并成一个新的结点。将当前结点指向父结点,重复第4步。
        注意,通过B+树的删除操作后,索引结点中存在的key,不一定在叶子结点中存在对应的记录。
        
    慢查询优化
        关于MySQL索引原理是比较枯燥的东西,大家只需要有一个感性的认识,并不需要理解得非常透彻和深入。我们回头来看看一开始我们说的慢查询,了解完索引原理之后,大家是不是有什么想法呢？先总结一下索引的几大基本原则
    建索引的几大原则
        1、最左前缀匹配原则,非常重要的原则,mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配,比如a 1="" and="" b="2" c=""> 3 and d = 4 如果建立(a,b,c,d)顺序的索引,d是用不到索引的,如果建立(a,b,d,c)的索引则都可以用到,a,b,d的顺序可以任意调整。
        2、=和in可以乱序,比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序,mysql的查询优化器会帮你优化成索引可以识别的形式
        3、尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*),表示字段不重复的比例,比例越大我们扫描的记录数越少,唯一键的区分度是1,而一些状态、性别字段可能在大数据面前区分度就是0,那可能有人会问,这个比例有什么经验值吗？使用场景不同,这个值也很难确定,一般需要join的字段我们都要求是0.1以上,即平均1条扫描10条记录
        4、索引列不能参与计算,保持列“干净”,比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引,原因很简单,b+树中存的都是数据表中的字段值,但进行检索时,需要把所有元素都应用函数才能比较,显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);
        5、尽量的扩展索引,不要新建索引。比如表中已经有a的索引,现在要加(a,b)的索引,那么只需要修改原来的索引即可
   
MySQL中位,字节,字符的关系
    一、位
        位（bit）是计算机内部数据存储的最小单位。8个“位”构成一个字节（byte）。
    二、字节
        字节（byte）是计算机中数据处理的基本单位,习惯上用大写B来表示。字节是内存的基本单位,也是编址单位。
    1B(byte,字节)=8bit(位)
    三、字符
        字符是指计算机中使用的字母、数字、字和各种符号,在不同的编码方式下一个字符占的字节不太一样。
        UTF-8中,一个汉字占三个字节,英文状态下一个字母或数字（称之为字符）占用一个字节。

MySQL中查询json字段
    // 保证字段不能为空
    select * from member_supplement where 字段名 -> '$.json中key' = json中value
去重查询,distinct与group by的比较总结
    在重复量较高的字段中,group by的效率会高,重复量低的字段中,distinct效率高,而且随着数据量的变大效率会更高.

备注
    1.如果采用MyISAM引擎,需要key_buffer_size加大。
    2.强烈推荐采用innodb引擎,default-storage-engine=Innodb
    3.调整innodb_buffer_pool_size大小,考虑设置为物理内存的50%-60%左右
    4.根据实际需要设置inno_flush_log_at_trx_commit,sync_binlog的值。
    5.如果要需要数据不能丢失,那么两个都设为1.如果允许丢失大一点数据,
    6.则可分别设为2和0,在slave上可设为0
    7.设置innodb_file_per_table = 1,使用独立表空间
    8.设置innodb_data_file_path = ibdata1:1G:autoextend,不要使用默认的10%
    9.设置innodb_log_file_size=256M,设置innodb_log_files_in_group=2,基本可满足90%以上的场景；
    10.不要将innodb_log_file_size参数设置太大,这样可以更快同时又更多的磁盘空间,
    11.丢掉多的日志通常是好的,在数据库崩溃后可以降低恢复数据库的事件
    12.设置long_query_time = 1记录那些执行较慢的SQL,用于后续的分析排查；
    13.根据业务实际需要,适当调整max_connection（最大连接数),max_connection_error（最大错误数,建议设置为10万以上,而open_files_limit、innodb_open_files、table_open_cache、table_definition_cache这几个参数则可设为约10倍于max_connection的大小；）不要设置太大,会将数据库撑爆
    14.tmp_table_szie、max_heap_table_size、sort_buffer_size、join_buffer_size、read_buffer_size、read_rnd_buffer_size等都是每个连接session分配的,因此不能设置过大
    15.建议关闭query cache功能或降低设置不要超过512M
</pre>