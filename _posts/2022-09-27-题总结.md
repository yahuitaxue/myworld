---
title: 面试题总结
author: Yahui
layout: Other
category: Other
---

书名:《-》

<pre style="text-align: left;">
rpc微服务框架
	解决的两个问题：
		1.解决分布式系统中，服务之间的调用问题。
		2.远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。
	RPC是一种技术的概念名词
		RPC=Remote Produce Call 是一种技术的概念名词，HTTP是一种协议,RPC可以通过 HTTP 来实现,也可以通过Socket自己实现一套协议来实现.所以题目可以换一种理解,为何 RPC 还有除 HTTP 之外的实现法,有何必要，毕竟除了HTTP实现外,私有协议不具备通用性.
	Go
		官方提供一个标准 RPC库: net/rpc。
		Golang 的 rpc 支持三个级别的 RPC: TCP、HTTP、JSONRPC。但 Go 的 RPC 包只支持 Go 开发的服务器与客户端之间的交互，因为内部采用 Gob 来编码。
		Go RPC 服务端通过注册对象，使用对象的类型名暴露服务。服务端可以注册多个不同类型的对象，不能注册相同类型的多个对象。并且对象的方法需要被远程访问，必须满足以下的条件：
			方法的类型是可输出的 (the method’s type is exported)
			方法本身也是可输出的 （the method is exported）
			方法必须由两个参数，必须是输出类型或者是内建类型 (the method has two arguments, both exported or builtin types)
			方法的第二个参数必须是指针类型 (the method’s second argument is a pointer)
			方法返回类型为 error (the method has return type error)
redis过期策略和内存淘汰策略
	淘汰策略
		volatile-lru：在设置过期时间的数据中淘汰最少使用的数据。(最后一次被使用到发生调度的时间长短)
		allkeys-lru：在所有的数据中淘汰最少使用的数据。
		volatile-lfu：在设置过期时间的数据中淘汰使用频率最低的数据。(一定时间段内页面被使用的频率)
		allkeys-lfu：在所有的数据中淘汰使用使用频率最低的数据。
		volatile-random：在设置过期时间的数据中淘汰任意随机数据。
		allkeys-random：在所有的数据中随机淘汰数据。
		volatile-ttl：在设置过期时间的数据中淘汰最早过期的数据。
		noeviction：默认策略，不淘汰数据，新增或者修改数据会抛异常，但是读操作正常进行，不受影响
	过期策略
		定时过期
		惰性过期
		定期过期
sql索引优化问题
	最大化利用索引
	尽可能避免全表扫描
	减少无效数据的查询
一个update语句的执行过程
	执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
	执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
	引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
	执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
	执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。
go的profile工具？
	性能分析引用runtime/pprof包即可。
	func main() {
		create, err := os.Create("cpu.pprof")
		if err != nil {
			fmt.Println("error")
		}
		err = pprof.StartCPUProfile(create)
		if err != nil {
			fmt.Println("error")
		}
		for i := 0; i < 10; i++{
			fmt.Println(i)
			time.Sleep(time.Second)
		}
		pprof.StopCPUProfile()
	}
	生成cpu.pprof文件
	使用go tool pprof cpu.pprof分析文件内容
http和tcp有什么区别
	1.
		Http协议是建立在TCP协议基础之上的。当浏览器需要从服务器 获取网页数据的时候，会发出一次http请求。
		Http通过TCP建立起一个到服务器的通道。
	2.	
		Http是无转态的连接
		TCP是有状态的长连接
		其实很多应用并非是通过tcp 的keepalive机制探活的，因为默认的两个多小时检查时间对于很多实时系统是完全没法满足的，通常的做法是通过应用层的定时监测如PING-PONG机制（就像打乒乓球，一来一回），应用层每隔一段时间发送心跳包，如websocket的ping-pong。
	3.
		http是一个简单的请求-响应协议。
		TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议。
用netstat看tcp连接的时候有关注过time_wait和close_wait吗？
	<span class="image featured"><img src="{{ 'assets/images/other/tcpfourgoodbye.jpg' | relative_url }}" alt="" /></span>
go语言的时候垃圾回收，写代码的时候如何减少小对象分配
	GC开始时将栈上可达对象全部标记为黑色（不需要二次扫描，无需STW）
	GC期间，任何栈上创建的新对象均为黑色
	被删除引用的对象标记为灰色
	被添加引用的对象标记为灰色
redis的存储结构？
	<span class="image featured"><img src="{{ 'assets/images/other/redis_base_struct.png' | relative_url }}" alt="" /></span>
	string
		<span class="image featured"><img src="{{ 'assets/images/other/redis_string.jpg' | relative_url }}" alt="" /></span>
		Redis中规定假如存储的是「整数型值」，比如set num 123这样的类型，就会使用 int的存储方式进行存储，在redisObject的「ptr属性」中就会保存该值。
		动态字符串
		raw和embstr是sds动态字符串，能够节约内存。当然int 是4个字节也是可以用作32位的位图，但是其大小固定比较单一。
			struct sdshdr {
			    //记录buf数组中已使用字节的数量,等于SDS所保存字符串的长度
			    unsigned int len;
			    //记录buf数组中未使用字节的数量
			    unsigned int free;
			    //char数组，用于保存字符串
			    char buf[];
			};
	双向链表
		<span class="image featured"><img src="{{ 'assets/images/other/redis_list.jpg' | relative_url }}" alt="" /></span>
	压缩列表
		<span class="image featured"><img src="{{ 'assets/images/other/redis_zipList.jpg' | relative_url }}" alt="" /></span>
		详情ziplist存储是连续的内存空间，可以做压缩。当涉及计算时，ziplist明显会比双向链表的指针检索慢，因此ziplist是牺牲时间换取空间的结构。list的底层采取的是压缩列表加双向链表的存储结构
		压缩列表由一下几个部分构成：
			zlbytes：表示列表长度，也就是整个压缩列表占用的内存字节数。
			zltail：表示列表尾的偏移量，也就是最后一个entry的首字节位置。
			zlen：表示列表中的entry个数。
			entry：表示列表的节点，代表一个存储元素。
			zlend：列表列表的结束，特殊值0xFF（十进制为255）
			压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。

			压缩列表节点结构
			每个 entry 的元数据包括下面几部分：

			prev_len：表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。
			当前一个节点的长度小于254个字节时， prev_len的长度为1个字节，直接存储前一个节点的字节长度；
			当前一个节点的长度大于或等于254个字节时， prev_len的长度为5个字节，其中的第一个字节被设置为0xFE，随后的四个字节保存前一个节点的字节长度。
			encoding：表示数据的类型，1 字节；
			len：表示自身长度，4 字节；
			key：保存实际数据。
	跳表
		1.跳表结合了链表和类似二分查找的思想；
		2.有很多层结构，由原始链表和一些通过“跳跃”生成的链表组成；
		3.每一层都是一个有序的链表；
		4.最底层(Level 1)的链表包含所有元素，越上层“跳跃”的越高，元素(索引)越少；
		5.查找时从顶层向下，不断缩小搜索范围；
		6.上层链表是下层链表的子序列；
		7.每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。
	整型数组
		<span class="image featured"><img src="{{ 'assets/images/other/redis_intset.jpg' | relative_url }}" alt="" /></span>
	hash表
		dict常见称之字典(dictionary)或映射(map)，其元素以键值对形式存在。是 Redis 最重要、常用的数据结构，可以说 Redis 本质就是一个 dict。dict 是为了解决算法中的查找问题而出现的，在无冲突下理论上能达到 O(1) 查找效率。Dict 本质其实就是一个 hashtable
		下面介绍Redis将一个键值对插入字典dict的过程：
			先用哈希函数计算键key的哈希值（Redis使用的是MurMurHash2算法来计算哈希值）
			hash = dict->type->hashFunction(key)
			借助sizemask和哈希值，计算出索引值（下面的x可以是0或者1）
			index = hash & dict->ht[x].sizemask
			上面计算出来index的值其实就是对应dictEntry*数组的下标，如果对应下标没有存放任何键值对，则直接存放，否则借助开链法，从链表头插入新的键值对（因为链表没有记录指向链表尾部的指针，所以从链表头插入效率更高，可以达到O(1)）
实现map的方法除了哈希还有哪些？
	Map通常用来存储键-值对有映射关系的数据，且key唯一不可重复，value可重复。
		HashMap
		Java中TreeMap(红黑树)
gin框架的路由是怎么处理的？
	每种请求方法管理一棵单独的树
	gin框架使用的是定制版本的httprouter，其路由的原理是大量使用公共前缀的树结构，它基本上是一个紧凑的Trie tree（或者只是Radix Tree）。具有公共前缀的节点也共享一个公共父节点。
sql索引优化方式，explain字段含义
	id：所泽标识符
	select_type：表示查询的类型
	table：输出结果集的表
	partitions：匹配的分区
	type：表示表的连接类型
		ALL(遍历全表进行匹配如：explain select * from a where 非索引列 > 9)
		index(遍历整个索引进行匹配如：explain select 索引列 from a)
		range(索引范围匹配，常见于<,<=,>,>=,between等如：explain select * from a where 索引列 > 9)
		ref(使用非唯一索引返回某个单独值的记录如：explain select * from a where 索引列 = 9)
		eq_ref(多表查询使用唯一索引使用primary key或者unique index作为关联，并且关联是只有一个对应的条件如：explain select * from 表1,表2 where 表1.id = 表2.id)
		const,system(单表中最多有一个匹配行如：explain select * from(select * from a where 主键索引或者唯一索引 = '某个值'))
		NULL(MySQL不用访问表或者索引就能得到结果如：explain select 1+2;)
	possible_keys：表示查询时，可能使用的索引
	key：表示实际使用的索引
	key_len：索引字段的长度
	ref：列与索引的比较
	rows：扫描出的行数（估算的行数）
	filtered：按表条件过滤的行百分比
	Extra：执行情况的描述和说明
gmp具体的调度策略
	g:goroutine协程(用户态协程)
		1、go 通过调度器 P，把可运行的 goroutine 分配到工作线程上
		2、P 的本地队列不超过 256 个，如果队列满了会拿出一半 G，移动到全局队列中
		3、M 线程想运行就从 P 的本地队列获取 G，P 队列为空时就尝试从全局对队列拿一批 G 放到 P 的本地队列中
	P:processor(包含了运行goroutine运行时需要的资源)
		1、环境变量 $GOMAXPROCS 或者 runtime 的方法 GOMAXPROCS () 决定
	M:内核态的协程
		1、go 程序启动时会设置 M 的最大数量，默认 10000，但是内核很难支持这么多线程数，所以这个限制可以忽略
		2、runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了会创建新的 M
	M 何时创建：
		没有足够的 M 来关联 P 并运行其中的可运行的 G。 比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。
	机制
		1.我们通过 go func()来创建一个goroutine；
		2.有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中；
		3.G只能运行在M中，一个M必须持有一个P，M与P是1：1的关系。M会从P的本地队列弹出一个可执行状态的G来执行，如果P的本地队列为空，就会想其他的MP组合偷取一个可执行的G来执行；
		4.一个M调度G执行的过程是一个循环机制；
		5.当M执行某一个G时候如果发生了syscall或则其余阻塞操作，M会阻塞，如果当前有一些G在执行，runtime会把这个线程M从P中摘除(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P；
		6.当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列中。
	调度器策略
		复用线程：避免频繁的创建、销毁线程、而是对线程复用
		1、work stealing 机制
			当本线程无可运行的 G 时，尝试从其它线程绑定的 P 偷取 G，而不是销毁线程
		2、hand off 机制
			当本线程因为 G 阻塞时，该线程释放绑定的 P，把 P 转移给其它空闲的线程执行。
			并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。
			比如：GOMAXPROCS = 核数 / 2，则最多利用了一半的 CPU 核进行并行
B+树细节优势，和哈希索引的区别，是为了解决什么问题？
	1、hash索引进行等值查询更快(一般情况下)，但是却无法进行范围查询。
		因为在hash索引中经过hash函数建立索引之后，索引的顺序与原顺序无法保持一致，不能支持范围查询。
		而B+树的的所有节点皆遵循(左节点小于父节点，右节点大于父节点，多叉树也类似)，天然支持范围。
	2、hash索引不支持使用索引进行排序，原理同上。
	3、hash索引不支持模糊查询以及多列索引的最左前缀匹配。原理也是因为hash函数的不可预测。AAAA和AAAAB的索引没有相关性。
	4、hash索引任何时候都避免不了回表查询数据，而B+树在符合某些条件(聚簇索引，覆盖索引等)的时候可以只通过索引完成查询。
	5、hash索引虽然在等值查询上较快，但是不稳定。性能不可预测，当某个键值存在大量重复的时候，发生hash碰撞，此时效率可能极差。而B+树的查询效率比较稳定，对于所有的查询都是从根节点到叶子节点，且树的高度较低。
es内部实现原理，如何保证数据一致性，如何降低压力
	持久性：通过Replica和TransLog两种机制来共同保障。
	一致性：数据写入成功后，需完成refresh操作之后才可读，由于无法保证Primary和Replica可同时refresh，所以会出现查询不稳定的情况，这里只能实现最终一致性。
	原子性：Add和Delete直接调用Lucene的接口，进行原子操作。update操作通过Delete-Then-Add完成，在Delete操作之前会加Refresh Lock，禁止Refresh操作，等Add操作完成后释放Refresh Lock后才能被Refresh，这样就保证了Delete-Then-Add的原子性。
	隔离性：采用Version和局部锁来保证更新的是特定版本的数据。
	要保证数据写入到ElasticSerach是安全的，高可靠的，需要如下的配置：
		设置wait_for_active_shards参数大于等于2。
		设置TransLog的Flush策略为每个请求都要Flush。
	鱼与熊掌不可兼得，大家需要根据实际场景合理设置参数在可靠性和可用性之间进行折中。
分库分表联表查询有哪些方式
	按时间维度（年/月/日）
		业务跟时间关联度高
		同一时间段内业务数据量分布比较均匀
		适用于报表、统计系统相关的业务
	HASH
		HASH函数的算法是简单取模，若分库和分表使用不同拆分键进行HASH时，则根据分库键的键值直接按分库数取模，如果键值是字符串，则字符串会先被换算成哈希值再进行路由计算。若分库和分表都使用同一个拆分键进行HASH时，则根据拆分键的键值按总的分表数取模
			一个分表键够用
			适合于需要按用户ID或订单ID进行分库分表的场景
			适合于拆分键是数字、字符串类型的场景
	RANGE_HASH
		选取两个拆分键，两个拆分键的后N位需确保一致，根据任一拆分键后N位计算哈希值，然后再按分库数取模，完成路由计算。此路由方式需要自行实现分片算法
			两个拆分键有关联
			查询时有其中一个拆分键值的场景
		如果采取RANGE_HASH函数作为分库分表，则最优方案是以订单号和买家id的后N位做分库分表，后续按订单号维度、买家id维度查询都能满足，卖家维度无法查询。但是前提是订单号后几位和买家id要有关联，涉及到订单号改造的过程
	ShardingSphere
		在拆分工具选择上，这里借助ShardingSphere[官网]，ShardingSphere是一套开源的分布式数据库解决方案组成的生态圈，它们能提供数据分片、分布式事务、分布式治理等功能
	综上
		因为订单一般都是由买家发起生成的，所以我们认为优先处理买家数据和订单号数据比较合理，所以我们先采用RANGE_HASH拆分算法按买家id后N位、订单号后N位维度做分库分表，作为买家表逻辑表。再用HASH拆分函数按商家id冗余一份数据，作为卖家表逻辑表
			买家库、买家表：下单填充买家表数据，用于以订单号、以买家id查询
			卖家库、卖家表：异步冗余一份买家表数据到卖家表，用于根据卖家id查数据
go实现不重启热部署
	使用 fresh 实现热部署
		# 安装 fresh
		$ go get github.com/pilu/fresh
		# 跳转到项目目录,例如项目名为‘myapp’
		$ cd /path/to/myapp
		# 启动
		$ fresh
	使用 gin 实现热部署
		# 安装 fresh
		$ go get github.com/codegangsta/gin
		# 验证gin是否安装成功
		$ gin -h
		# 启动
		$ gin run main.go
tcp如何保证稳定性
	滑动窗口和流速控制
		111[22233]44444
			深绿色(1)代表已经收到 ACK 的段
			浅绿色(2)代表发送了，但是没有收到 ACK 的段
			白色(3)代表没有发送的段
			紫色(4)代表暂时不能发送的段
	如果发送过程中，部分数据没能收到 ACK 会怎样呢？这就可能发生重传。
		11[12111]44444
			如果段4(2)迟迟没有收到ACK。
			这个时候滑动窗口只能右移一个位置，如下图所示：
		111[21114]4444
			在这个过程中，如果后来段4(2)重传成功(接收到ACK)，那么窗口就会继续右移。如果段4(2)发送失败，还是没能收到ACK，那么接收方也会抛弃段5、段6、段7。这样从段4开始之后的数据都需要重发。
		快速重传
		在 TCP 协议中，如果接收方想丢弃某个段，可以选择不发 ACK。发送端超时后，会重发这个 TCP 段。而有时候，接收方希望催促发送方尽快补发某个 TCP 段，这个时候可以使用快速重传能力。
		例如段 1、段 2、段 4 到了，但是段 3 没有到。 接收方可以发送多次段 3 的 ACK。如果发送方收到多个段 3 的 ACK，就会重发段 3。这个机制称为快速重传。这和超时重发不同，是一种催促的机制。
		为了不让发送方误以为段 3 已经收到了，在快速重传的情况下，接收方即便收到发来的段 4，依然会发段 3 的 ACK（不发段 4 的 ACK），直到发送方把段 3 重传。
	注：
		1.在上面所有的图片中，窗口大小是 TCP 段的数量。实际操作中，每个 TCP 段的大小不同，限制数量会让接收方的缓冲区不好操作，因此实际操作中窗口大小单位是字节数。
		2.窗口越大，同时可以发送、接收的数据就越多，支持的吞吐量也就越大。当然，窗口越大，如果数据发生错误，损失也就越大，因为需要重传越多的数据。
http和http2区别
	1.HTTP2使用的是二进制传送，HTTP1.X是文本（字符串）传送。
		二进制传送的单位是帧和流。帧组成了流，同时流还有流ID标示
	2.HTTP2支持多路复用
		因为有流ID，所以通过同一个http请求实现多个http请求传输变成了可能，可以通过流ID来标示究竟是哪个流从而定位到是哪个http请求
	3.HTTP2头部压缩
		HTTP2通过gzip和compress压缩头部然后再发送，同时客户端和服务器端同时维护一张头信息表，所有字段都记录在这张表中，这样后面每次传输只需要传输表里面的索引Id就行，通过索引ID查询表头的值
	4.HTTP2支持服务器推送
		HTTP2支持在未经客户端许可的情况下，主动向客户端推送内容
https的连接过程
	<span class="image featured"><img src="{{ 'assets/images/other/https_connect_step.jpg' | relative_url }}" alt="" /></span>
kafka如何做到高可用
	Replication：副本，是 Kafka 保证数据高可用的方式，Kafka 同一 Partition 的数据可以在多 Broker 上存在多个副本，通常只有主副本对外提供读写服务，当主副本所在 broker 崩溃或发生网络一场，Kafka 会在 Controller 的管理下会重新选择新的 Leader 副本对外提供读写服务。
分布式锁如何实现
	mysql
	redis
	ZooKeeper
		是一个为分布式应用提供一致性服务的开源组件，它内部是一个分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名。基于ZooKeeper实现分布式锁的步骤如下：
		1.创建一个目录mylock；
		2.线程A想获取锁就在mylock目录下创建临时有序节点；
		3.获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；
		4.线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；
		5.线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。
go并发机制
	不是通过共享内存通信，而是通过通信共享内存
	通过使用 goroutine 和 channel，可以编写运行速度更快且易于理解的并发程序
线程协程区别
	线程是进程内的一个执行单元(处理器调度的基本单位)，进程内至少有一个线程，它们共享进程的地址空间，而进程有自己独立的地址空间
	线程与进程均可并发执行
	一个线程可以多个协程，一个进程也可以单独拥有多个协程
	线程进程都是同步机制，而协程则是异步。
	线程是抢占式，而协程是非抢占式的，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力
常用限流算法
	计数限流
		每次请求来的时候看看计数器的值，如果超过阈值要么拒绝。
		非常的简单粗暴，计数器的值要是存内存中就算单机限流算法。存中心存储里，例如 Redis 中，集群机器访问就算分布式限流算法。
		优点就是：简单粗暴，单机在 Java 中可用 Atomic 等原子类、分布式就 Redis incr。
		缺点就是：假设我们允许的阈值是1万，此时计数器的值为0， 当1万个请求在前1秒内一股脑儿的都涌进来，这突发的流量可是顶不住的。缓缓的增加处理和一下子涌入对于程序来说是不一样的。
	固定窗口限流算法
		首先维护一个计数器，将单位时间段当做一个窗口，计数器记录这个窗口接收请求的次数。
		当次数少于限流阀值，就允许访问，并且计数器+1
		当次数大于限流阀值，就拒绝访问。
		当前的时间窗口过去之后，计数器清零。
		假设单位时间是1秒，限流阀值为3。在单位时间1秒内，每来一个请求,计数器就加1，如果计数器累加的次数超过限流阀值3，后续的请求全部拒绝。等到1s结束后，计数器清0，重新开始计数。
	滑动窗口限流
		滑动窗口限流解决固定窗口临界值的问题，可以保证在任意时间窗口内都不会超过阈值。
		相对于固定窗口，滑动窗口除了需要引入计数器之外还需要记录时间窗口内每个请求到达的时间点，因此对内存的占用会比较多。
		规则如下，假设时间窗口为 1 秒：
		记录每次请求的时间
		统计每次请求的时间 至 往前推1秒这个时间窗口内请求数，并且 1 秒前的数据可以删除。
		统计的请求数小于阈值就记录这个请求的时间，并允许通过，反之拒绝。
	令牌桶算法原理：
		有一个令牌管理员，根据限流大小，定速往令牌桶里放令牌。
		如果令牌数量满了，超过令牌桶容量的限制，那就丢弃。
		系统在接受到一个用户请求时，都会先去令牌桶要一个令牌。如果拿到令牌，那么就处理这个请求的业务逻辑；
		如果拿不到令牌，就直接拒绝这个请求。
IO多路复用
	一个进程/线程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程/线程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。
为什么内存操作很快
	因为CPU的速度很快，硬盘跟不上CPU的速度，在运行时无法同步，所以无法直接对硬盘操作
	CPU也不是直接操作内存的，内存的速度虽然比硬盘快，但是也没有CPU快，所以在CPU和内存之间还有 缓存
k8s各种组件
	1、kube-apiserver：集群中所有资源的统一访问入口；
	2、kube-scheduler：将新创建的pod调度到合适的节点上
	3、kube-controller-manager：集群中所有资源对象的自动化控制中心；
	4、etcd：保存集群中的所有资源对象的数据、
	二、工作节点主要包括以下组件：
	1、kubelet：负责pod对应的容器的创建、启停等任务，同时与Master节点密切协作，实现集群管理的基本功能；
	2、kube-proxy：将对service的访问转发到后端的一组pod上；
	3、容器运行时（Container Runtime）：容器运行时是负责运行容器的软件，k8s支持许多容器运行时，常用的是docker。
gomap并发安全问题，如何解决
	map是引用类型，未初始化的map是nil
	因为map变量为 指针类型变量，并发写时，多个协程同时操作一个内存，类似于多线程操作同一个资源会发生竞争关系，共享资源会遭到破坏，因此golang 出于安全的考虑，抛出致命错误：fatal error: concurrent map writes
	在写操作的时候增加锁，删除时候除了加锁外，还需要增加断言避免出现错误
go中的锁
	开箱即用
	var rwm = sync.RWMutex
	写锁定和写解锁
	rwm.Lock()
	rwm.Unlock()
	读锁定和读解锁
	rwm.RLock()
	rwm.RUnlock()
docker底层实现原理
	底层原理就是利用Linux的cgroups和namespace，本质上就是操作系统的一个进程，cgroups主要负责资源分配，namespace主要负责容器间的隔离（包括进程和网络等等）
集群分布式
	单机处理到达瓶颈的时候，你就把单机复制几份，这样就构成了一个“集群”。集群中每台服务器就叫做这个集群的一个“节点”，所有节点构成了一个集群。每个节点都提供相同的服务，那么这样系统的处理能力就相当于提升了好几倍（有几个节点就相当于提升了这么多倍）。
	分布式结构就是将一个完整的系统，按照业务功能，拆分成一个个独立的子系统
	在分布式结构中，每个子系统就被称为“服务”。这些子系统能够独立运行在web容器中，它们之间通过RPC方式通信。
etcd
	使用Go语言开发的一个开源的、高可用的分布式key-value存储系统，可以用于配置共享和服务的注册和发现
	类似项目有zookeeper和consul。
数据库分库分表，啥时候分库啥时候分表
	分表能够解决单表数据量过大带来的查询效率下降的问题，但是，却无法给数据库的并发处理能力带来质的提升。面对高并发的读写访问，当数据库master
	服务器无法承载写操作压力时，不管如何扩展slave服务器，此时都没有意义了
中序遍历二叉树
	func showTree(t treeNode) []int {
		var tmp []int
		if t.leftNode != nil {
			left := showTree(t.leftNode.(treeNode))
			for _,v := range left {
				tmp = append(tmp, v)
			}
		}
		tmp = append(tmp, t.value)
		if t.rightNode != nil {
			right := showTree(t.rightNode.(treeNode))
			for _,v := range right {
				tmp = append(tmp, v)
			}
		}
		return tmp
	}
判断二叉树是否是镜像二叉树
中间件:kafka丢失消息和不重复消费
	consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。由于Kafka consumer默认是自动提交位移的，所以在后台提交位移前一定要保证消息被正常处理了，因此不建议采用很重的处理逻辑，如果处理耗时很长，则建议把逻辑放到另一个线程中去做。为了避免数据丢失，可以采用手动提交offset：（1）enable.auto.commit=false 关闭自动提交位移、（2）在消息被完整处理之后再手动提交位移

	生产者丢失消息是最复杂的情形了。生产者(Producer) 使用 send 方法发送消息实际上是异步的操作，我们可以通过 get()方法获取调用结果，但是这样也让它变为了同步操作，但是一般不推荐这么做！可以采用为其添加回调函数的形式。这个回调函数会在 Producer 收到 ack 时调用，此处就和acks参数配置[1、0、-1]密切相关了
redis底层数据结构实现
	typedef struct redisObject{
	    //类型
	    unsigned type:4;
	    //编码
	    unsigned encoding:4;
	    //对象最后一次被访问的时间
	    unsigned lru:REDIS_LRU_BITS
	    //引用计数
	    int refcount
	    //指向底层实现数据结构的指针
	    void *ptr;
	    ...
	}
对一个链表进行排序
	最佳方法：归并排序
		1.找到中间节点
		2.将中间节点断成左右两半，然后再次递归找到中间节点，再次进行分割，直到最后分割成一个一个的单个元素
		3.然后两两排序，之后四四排序…直到最后将整张链表排成一个有序链表
		这个思想和归并排序一样，归并排序的原理也是将数据分割成小部分，然后每一个小部分进行排序，让局部有序，然后整体有序
给n个数1n，随机n次，将这n个数输出
	洗牌算法
		在整个数组 [0, n-1] 中（包括最后一个元素）随机选出一个元素，将它和最后那个元素 [n-1] 交换，然后再在数组 [0, n-2] 中随机选出一个元素，将它与倒数第二个元素 [n-2] 交换…一直到最后一个元素，就完成了算法
io多路复用，select\poll\epoll的实现和区别
	用来实现多路复用的，即一个线程利用它们即可 hold 住多个 socket,线程不可被任何一个被管理的 Socket 阻塞，且任一个 Socket 来数据之后都得告知 select/poll/epoll 线程
	(注意一下内核态和用户态的交互，用户程序访问不了内核空间。)
	select
		调用 select 会把所有要管理的 socket 的 fd (文件描述符，Linux下皆为文件，简单理解就是通过 fd 能找到这个 socket)传到内核中,遍历所有 socket，看看是否有感兴趣的事件发生。如果没有一个 socket 有事件发生，那么 select 的线程就需要让出 cpu 阻塞等待，这个等待可以是不设置超时时间的死等，也可以是设置 timeout 的有超时时间的等待。
		当 socket 接收到网卡的数据后，就会去它的睡眠队列里遍历 entry，调用 entry 设置的 callback 方法，这个 callback 方法里就能唤醒 select ！
		所以 select 在每个被它管理的 socket 的睡眠队列里都塞入一个与它相关的 entry，这样不论哪个 socket 来数据了，它立马就能被唤醒然后干活！
		但是，select 的实现不太好，因为唤醒的 select 此时只知道来活了，并不知道具体是哪个 socket 来数据了，所以只能傻傻地遍历所有 socket ，看看到底是哪个 scoket 来活了，然后把所有来活的 socket 封装成事件返回
		(因为被管理的 socket fd 需要从用户空间拷贝到内核空间，为了控制拷贝的大小而做了限制，即每个 select 能拷贝的 fds 集合大小只有1024)
	poll
		poll 这玩意相比于 select 主要就是优化了 fds 的结构，不再是 bit 数组了，而是一个叫 pollfd 的玩意，反正就是不用管啥 1024 的限制了。(现在也没人用 poll，就不多说了)
	epoll
		select存在的问题
			1.比如，为什么每次 select 需要把监控的 fds 传输到内核里？不能在内核里维护个？
			2.为什么 socket 只唤醒 select，不能告诉它是哪个 socket 来数据了？
			epoll 主要就是基于上面两点做了优化。
		过程
			1.搞了个叫 epoll_ctl 的方法，这方法就是用来管理维护 epoll 所监控的哪些 socket(这个 socket 集合是用红黑树实现的)
			2.然后和 select 类似，每个 socket 的睡眠队列里都会加个 entry，当每个 socket 来数据之后，同样也会调用 entry 对应的 callback。
			3.与 select 不同的是，引入了一个 ready_list 双向链表，callback 里面会把当前的 socket 加入到 ready_list 然后唤醒 epoll。
			4.这样被唤醒的 epoll 只需要遍历 ready_list 即可
长连接和短链接(怎么实现的、区别以及应用场景)
	短链接
		(建立连接——数据传输——关闭连接…建立连接——数据传输——关闭连接)
		WEB 网站的 http 服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像 WEB 网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源
	长连接
		(建立连接——数据传输…（保持连接）…数据传输——关闭连接)
		1.长连接可以省去较多的 TCP 建立和关闭的操作，减少浪费，节约时间。对于频繁请求资源的客户来说，适合长连接
		2.client 与 server 之间的连接如果一直不关闭的话，会存在一个问题，随着客户端连接越来越多，server 早晚有扛不住的时候，这时候 server 端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致 server 端服务受损；如果条件再允许就可以以客户端机器为颗粒度，限制每个客户端的最大长连接数，这样可以完全避免某个蛋疼的客户端连累后端服务
		3.数据库的连接用长连接，如果用短连接频繁的通信会造成 socket 错误，而且频繁的 socket 创建也是对资源的浪费
		4.客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接
socket与http
	TCP套接字编程，也就是所谓的socket
	HTTP也是基于TCP socket的高层封装，通过Socket传输包协议，完成之后发送FIN结束连接
	通过比较发现http和socket完全是两个不同的概念，http是应用层的，socket是传输层和网络层的，http要基于socket实现。httpclient的默认请求超时时间为60s。
WebSocket
	WebSocket则是一个典型的应用层协议
	WebSocket 是一种在单个 TCP 连接上进行全双工通信的协议。WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。
	过程
		Websocket是基于HTTP协议的，或者说 借用了HTTP的协议来完成一部分握手(会通知服务器使用WebSocket来进行握手)
缓存和数据库一致性的问题
	2、引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」
	3、更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，解决方案是加「分布锁」，但这种方案存在「缓存资源浪费」和「机器性能浪费」的情况
	4、采用「先删除缓存，再更新数据库」方案，在「并发」场景下依旧有不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估
		注「延迟双删」:
			更新完DB后，让它sleep一段时间，再删除Cache。(并不一定非要sleep)
	5、采用「先更新数据库，再删除缓存」方案，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据最终一致
		这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。
	6、采用「先更新数据库，再删除缓存」方案，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率
hash冲突解决办法，有什么弊端
	1.链地址法
		对于相同的哈希值，使用链表进行连接。（HashMap使用此法）
		优点
			处理冲突简单，无堆积现象。即非同义词决不会发生冲突，因此平均查找长度较短；
			适合总数经常变化的情况。（因为拉链法中各链表上的结点空间是动态申请的）
			占空间小。装填因子可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计
			删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。
		缺点
			查询时效率较低。（存储是动态的，查询时跳转需要更多的时间）
			在key-value可以预知，以及没有后续增改操作时候，开放定址法性能优于链地址法。
			不容易序列化
	2.再哈希法
		提供多个哈希函数，如果第一个哈希函数计算出来的key的哈希值冲突了，则使用第二个哈希函数计算key的哈希值。
		优点
			不易产生聚集
		缺点
			增加了计算时间
	3.建立公共溢出区
		将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。
	4.开放定址法
		当关键字key的哈希地址p =H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，若p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中
		优点
			容易序列化
			若可预知数据总数，可以创建完美哈希数列
		缺点
			占空间很大。（开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间）
单链表找到中间节点
	1.先统计链表节点个数 L。如果链表节点个数是奇数则第 L/2+1 个节点 是链表的中间节点；如果链表节点个数是偶数个，则 L/2 和 L/2+1 都是中间节点。
	2.使用快慢指针的方式，快指针 fast 前进两步，慢指针 slow 前进一步，当快指针 fast 到达链表尾部时，慢指针 slow 刚好到达链表的中间。如果链表节点个数是奇数则 slow 是链表的中间节点；如果链表节点个数是偶数则 slow 和 slow->next 都是链表的中间节点。(注意，带头结点的单链表，初始情况下 fast 和 slow 都是从头结点开始的)
给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针
sleep底层实现原理
	挂起进程（或线程）并修改其运行状态
	用sleep()提供的参数来设置一个定时器。
	当时间结束，定时器会触发，内核收到中断后修改进程（或线程）的运行状态。例如线程会被标志为就绪而进入就绪队列等待调度。
	可变定时器(variable timer)一般在硬件层面是通过一个固定的时钟和计数器来实现的，每经过一个时钟周期将计数器递减，当计数器的值为0时产生中断。内核注册一个定时器后可以在一段时间后收到中断。
docker和虚拟机区别
	1.虚拟机包括应⽤，必要的⼆进制和库，以及⼀个完整的⽤户操作系统,docker中宿主机共享硬件资源及操作系统可以实现资源的动态分配
	2.docker隔离性更弱，docker属于进程之间的隔离，虚拟机可实现系统级别隔离
channel和锁对比一下
	channel选择
		channel是线程安全的并且不会有数据冲突，比锁好用多了
		1.对性能要求很高的临界区
		2.视图保护某个结构内部状态
	lock.Mutex选择
		1.转让数据的所有权
		2.协作多个逻辑片段
slice/array/map区别
	array
		可以存储相同类型的元素的固定大小顺序集合。数组的每个元素在内存中都是连续存放的，每个元素都有一个下标，下标从0开始。数组长度可以省略，会自动根据{}中的元素来进行推导。没有初始化的索引，默认值是数组类型的零值。数组用于存储数据集合，但将数组视为同一类型的变量的集合通常更有用。
	slice
		Go数组的一个抽象。可以理解为动态的数组，切片是基于数组实现的，它的底层就是一个数组。对于数组的分割，便可以得到一个切片。eg:array[start:end] 可以得到包括start下标到end（不包括end下标元素） 的子数组
	map
		是一个无序的 k-v 键值对集合。 给定一个键和一个值就可以在Map对象中设置值。设置存储值后，就可以使用其键检索它对应的值了。其中 k 必须是相同类型。k 和 v 的类型可以不同。k 的类型必须支持 == 比较运算符，这样才可以判断它是否存在，并保证唯一
	array 为值类型，这意味着当数组变量被赋值时，将会获得原数组的拷贝。新数组中元素的改变不会影响原数组中元素的值。
	slice、map 为引用类型，赋值的时候是将指针复制给新的变量, 这意味着当元素被改变时，slice、map中元素的值会跟随改变。
向为nil的channel发送数据会怎么样
	会阻塞
	var ch chan int
	ch = make(chan int, 3)
	select {
	case aa := <-ch:
		fmt.Println(aa)
	case ch<-11:
		fmt.Println("有写入")
	}
MVCC原理
	指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。
	在内部实现中，InnoDB通过undo log保存每条数据的多个版本，并且能够找回数据历史版本提供给用户读，每个事务读到的数据版本可能是不一样的。在同一个事务中，用户只能看到该事务创建快照之前已经提交的修改和该事务本身做的修改。
	MVCC只在已提交读（Read Committed）和可重复读（Repeatable Read）两个隔离级别下工作，其他两个隔离级别和MVCC是不兼容的。因为未提交读，总数读取最新的数据行，而不是读取符合当前事务版本的数据行。而串行化（Serializable）则会对读的所有数据多加锁。
	MVCC的实现原理主要是依赖每一行记录中两个隐藏字段，undo log，ReadView
ACID的涵义，MYSQL是如何保证的
	原子性（Atomicity）：指事务不可分割，要么全部成功，要么全部失败，不可能存在部分成功或部分失败的情况。如果执行某一条语句失败后，将会触发之前所有执行过的语句的回滚，因此靠的是undo log。
	一致性（Consistency）：在事务执行前后，数据的完整性没有遭到破坏。一致性是mysql追求的最终目标，需要数据库层面与应用层面同时来维护。需要先满足原子性、隔离性与持久性，同时也需要应用层面做保障，即在应用层面对数据进行检验。
	隔离性（Isolation）：事务之前是隔离的，并发执行的事务之间不存在互相影响，mysql通过锁以及MVCC来保证隔离性。
	持久性（Durability）：事务一旦提交，那么对数据的操作就是永久性的，即使接下来数据库宕机也不会有影响。mysql是通过redo log来实现宕机恢复的，而binlog主要是用来误删恢复与主从复制的。
缓存失效的几种场景，以及解决方案
	1.缓存穿透
		用户不断发请求访问缓存和数据库中都没有的数据。如访问id为-1的数据或id为特别大不存在的数据。此时用户很可能是攻击者，攻击导致数据库压力过大
		解决：
			缓存空结果(加短暂过期时间)、布隆过滤器、mvc拦截器
	2.缓存雪崩
		由于设置缓存key采用相同的过期时间，缓存在某一时刻同时失效，请求全部转发带数据库。数据库压力过重导致雪崩
		解决：
			1、规避雪崩：缓存过期时间随机，防止大量数据过期现象发生
			2、分布式部署：若缓存数据库是分布式部署，将热点数据均匀分布在不同缓存数据库中
			3、设置热点数据永不过期
			4、出现雪崩：降级、熔断
			事前：尽量保证整个Redis集群的高可用性，发现机器宕机尽快补上。选择内存合适的内存淘汰策略
			事中：本地ehcache缓存 + hystrix限流&降级，避免mysql崩溃
			事后：利用redis持久化机制保存的数据尽快恢复缓存
	3.缓存击穿
		与缓存雪崩不同的是
		1、击穿是指并发查询同一条数据，缓存中不存在但数据库中存在的数据（一般是缓存时间到期）。此时由于并发用户特别多，同时没能从缓存中读取到数据，而去数据库中去取，引起数据库压力瞬间增大，造成过大压力
		2、雪崩是指不同数据同时过期，很多的数据都查不到而查询数据库
		解决方案：
			1、设置热点数据永不过期
			2、加互斥锁：业界常用的做法是使用mutex。缓存失效的时候（判断从缓存中取出来的是空值），不是立即取数据库加载，而是先使用缓存工具的某些带成功操作返回值的操作（如redis的setnx和memcache的add）去set一个mutex key，当操作返回成功时，再进行加载load db的操作并回设缓存；否则重试整个get缓存方法
gostruct能不能比较
	1. 不同类型(A struct 与 B struct)不能比较
	2. 同类型(A struct 与 A struct)有特殊字段(如 Slice)不能比较
		1. 指针类型：包括任何类型的指针，例如`*int`、`*string`等。指针类型不可比较是因为指针的值是内存地址，而不是其指向的实际值。两个指针的比较只会比较它们的地址，而不会比较指向的实际值。
		2. 切片类型：切片是一个包含指向底层数组的指针、长度和容量的结构体。切片的比较除了要比较指针的地址，还需要比较长度和容量等属性。因为切片是动态的，它的长度和容量可能会在运行时发生变化，所以无法简单地进行比较。
		3. 函数类型：函数是一种引用类型，它们的值是指向函数体的指针。因为函数指针只是函数体的内存地址，不同的函数可能拥有相同的地址，所以无法直接比较函数类型。
		4. 接口类型：接口是一种抽象类型，它可以包含任何类型的值。由于接口的底层类型可能是任意类型，所以无法比较接口类型。
		这些字段不能直接比较是因为它们的值无法简单地比较，需要比较更多的属性或者底层值。使用相等操作符`==`比较这些字段时，只会对它们的地址指针进行比较，这通常不是我们想要的结果。如果需要比较结构体的字段，可以通过手动比较它们的属性或者自定义比较函数来实现。
select的作用
	是一种go可以处理多个通道之间的机制，看起来和switch语句很相似，但是select其实和IO机制中的select一样，多路复用通道
	(在没有default的情况下会阻塞,case是随机的)
context包的用途
	type Context
    func WithValue(parent Context, key, val interface{}) Context

    func main() {
		type favContextKey string
		f := func(ctx context.Context, k favContextKey) {
			if v := ctx.Value(k); v != nil {
				fmt.Println("found value:", v)
				return
			}
			fmt.Println("key not found:", k)
		}
		k := favContextKey("小米")
		ctx := context.WithValue(context.Background(), k, "小米")
		f(ctx, k)
		f(ctx, favContextKey("小红"))
	}
client如何实现长连接
	TCP协议的KeepAlive机制与HeartBeat心跳包
主协程如何等其余协程完再操作
	Go提供了更简单的方法——使用sync.WaitGroup。WaitGroup，就是用来等待一组操作完成的。WaitGroup内部实现了一个计数器，用来记录未完成的操作个数.
	它提供了三个方法，Add()用来添加计数。Done()用来在操作结束时调用，使计数减一。Wait()用来等待所有的操作结束，即计数变为0，该函数会在计数不为0时等待，在计数为0时立即返回。
		var wg sync.WaitGroup
	    wg.Add(2) // 因为有两个动作，所以增加2个计数
	    go func() {
	        fmt.Println("Goroutine 1")
	        wg.Done() // 操作完成，减少一个计数
	    }()
	    go func() {
	        fmt.Println("Goroutine 2")
	        wg.Done() // 操作完成，减少一个计数
	    }()
	    wg.Wait() // 等待，直到计数为0
map如何顺序读取
	map是无序的,所以如果想要实现顺序读取,需要首先将map的key存放为slice,然后进行排序,最后在按照排序后的key输出map的值


docker容器化技术的核心技术
对k8s的基础概念的了解情况
对k8s有哪些操作呢？
k8syml文件是如何写的？
linux常用操作
查端口用什么命令？
	netstat -ntulp
lsof查不到的话用什么命令？
	获取任何被打开文件的各种信息，只需输入 lsof 就可以生成大量的信息，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。
	lsof访问的是核心文件和各种文件，所以必须以root用户的身份运行才能充分发挥其功能

数组和切片的关系和区别
	数组
		数组是值类型
	切片(底层是包含数组的结构体)
		append操作本质上是对数组扩容
		已建数组实际上无法改变大小，append操作会在底层创建一新的数组newArr(其长度按照扩容的大小)
		slice原来所包含的元素拷贝到新的数组newArr，新增的元素随着添加到newArr
		slice再重新引用到数组newArr
		需注意newArr是在底层维护的，只能通过slice访问
		切片的拷贝，使用copy方法：copy(slice01,slice)，将slice拷贝给slice01。
channel和共享内存有什么优劣势？
	(不要通过共享内存的方式进行通信，而是应该通过通信的方式共享内存)
	1.共享内存的方式进行通信
		func watch(p *int) {
			for true {
				if *p == 1 {
					fmt.Println(a...:"hello")
					break
				}
			}
		}
		func main() {
			i := 0
			go watch(&i)
			time.Sleep(time.Second)
			
			i = 1
			time.Sleep(time.Second)
		}
		// output:
		// hello
	2.通信的方式共享内存
		func watch(c chan int) {​    
			if <-c == 1 {        
				fmt.Println("hello")    
			}
		}
		​func main() {    
			c := make(chan int)
			go watch(c)​    
			time.Sleep(time.Second)​    
			c <- 1​
			time.Sleep(time.Second)
		}
		// output：
		// hello
	channel实质上是一个名为hchan的结构体
go里面interface是什么概念
	由两个struct实现：iface和eface。
	eface
		表示empty interface，不包含任何方法
	iface 表示 non-empty interface，即包含方法的接口。
	iface和eface均由两部分组成：type和value，type表示interface的类型描述，主要提供concrete type相关的信息，value指向interface绑定的具体数据。
相比于java,c++,interface有什么区别吗？
	1.侵入式通过 implements 把实现类与具体接口绑定起来了，因此有了强耦合;
	2.假如修改了接口方法，则实现类方法必须改动；
	3.假如类想再实现一个接口，实现类也必须进行改动；
	4.后续实现此接口的类，必须了解相关的接口；
	5.Go语言非侵入式的方式很好地解决了这几个问题，只要实现了实现了与接口相同的方法，就实现了这个接口。随着代码量的增加，根本不需要的关心实现了哪些接口，不需要刻意去先定义接口再实现接口的固定模式，在原有类新增实现接口时，不需要更改类，做到低侵入式、低耦合开发的好处。
docker怎么看日志
	docker logs --tail=500 [服务名称或者容器名称] 
容器的cpu和内存占比
	docker ps -a
	ps -ef | grep 容器ID
	top -p 进程ID

如果有一个节点不可用了，如何把pod驱逐到其他节点
kubectlapply和create有什么区别
	kubectl create：
		是祈使式命令，明确告诉k8s要创建的资源或者对象
		首先删除集群中现有的资源，然后重新根据yaml文件生成新的资源对象
		yaml文件必须是完整的配置
		yaml文件中的所有字段都会被create
		在没有改动yaml文件时，使用同一个yaml文件执行命令kubectl replace，将不会成功（fail掉），因为缺少相关改动信息。
	kubectl apply
		是声明式命令，apply不告诉k8s具体要干什么，而是kubectl根据yaml文件自动探测要做哪些操作，如果不存在则create，如果存在则对比差异，进行更新。
		根据yaml文件中包含的字段，直接升级集群中的现有资源对象
		yaml文件可以不完整，只写需要修改的字段
		只有要改动的字段才会被apply
		在只改动了yaml文件中的某些声明时，而不是全部改动，你可以使用kubectl apply
	create创建已存在资源会报错：Error from server (AlreadyExists)。
pod内容器是相互隔离的吗
	1.pod是k8s的最小单元，容器包含在pod中，一个pod中有一个pause容器和若干个业务容器，而容器是单独的一个容器，简而言之，pod是一组容器的集合。
	2.pod相当于逻辑主机，每个pod都有自己的ip地址
	3.pod内的容器共享相同的ip和端口
	4.默认情况下，每个容器的文件系统与其他容器完全隔离
跳表和二叉检索树优劣
	首先创建跳表节点，有两个变量，一个value是该节点的值，一个该节点对应层上下一个节点
	初始化跳表，跳表head节点值都为null，maxLevel记录最大层数
	跳表是一个随机化的数据结构，实质就是一种可以进行二分查找的有序链表。通过增加多级索引实现查找、插入、删除的平均复杂性均为O(logN)。
写个二分查找
怎么理解“不要用共享内存来通信，而是用通信来共享内存”
	共享内存
		多个对象同时访问同一块数据，几乎一定会产生数据冲突。
		为了对抗数据冲突，人们发明了很多机制。比如加锁、信号量、原子锁、巧妙的多线程算法等等。但是这些算法看起来很高级，实际上要么会影响并发性能、要么对使用场景有要求、要么很烧脑很难证明正确性。
	通信
		先提供一个或多个高性能队列，线程/进程/微服务之间需要访问别人时，不能直接读写别人的数据，而要通过队列提出请求，然后在对方处理请求时再做相应处理。
redis内存操作很快？有没有IO读写
	内核态进程可以执行任意命令，调用系统的一切资源，而用户态进程只能执行简单的运算，不能直接调用系统资源，所以用户态进程必须通过系统接口（System Call），才能向内核发出指令，完成调用系统资源之类的操作。
redis的数据结构了解哪些？深入说下内部实现
扩展类型说下
	geo
		数据在Redis中的存储方式，可以看到是以zset格式进行存储的，因此geo是zset的一个扩展
		# 语法格式：
			GEOADD key longitude latitude member [longitude latitude member ...]
		# 测试：
			> GEOADD locations 116.419217 39.921133 beijing
			> GEOADD locations 120.369557 36.094406 qingdao
		也可用zrange返回所有的位置元素而不带经纬度信息：
			> ZRANGE locations 0 -1
			qingdao
			beijing
	Bitmap
		也被称为位图，是以 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。其中每一个bit都只能是0或1，所以通常用来表示一个对应于数组下标的数据是否存在。
		# 语法格式：
			对key所存储的字符串值，设置或清除指定偏移量上的位（bit）
			GETBIT key offset 
			SETBIT key 128(offset) 1(value)
		通过直接操作bit，将string类型的abc变成了bbc
			> set key2 abc
			> setbit key2 6 1
			> setbit key2 7 0
			> get key2
			bbc
	HyperLogLog
		基数统计的数据集合类型,是一套不怎么精确但是够用的去重方案，会有误差，官方给出的误差数据是0.81%，这个精确度，统计UV够用了
		# 语法格式：
			127.0.0.1:6379> pfadd uv u1 u2 u3 
			(integer) 1
			127.0.0.1:6379> pfcount uv
			(integer) 3
如何实现一个线程安全的map
	并发读写时会发生panic
	1. 加锁
		type RWMap struct { // 一个读写锁保护的线程安全的map
		    sync.RWMutex // 读写锁保护下面的map字段
		    m map[int]int
		}
		// 新建一个RWMap
		func NewRWMap(n int) *RWMap {
		    return &RWMap{
		        m: make(map[int]int, n),
		    }
		}
		func (m *RWMap) Get(k int) (int, bool) { //从map中读取一个值
		    m.RLock()
		    defer m.RUnlock()
		    v, existed := m.m[k] // 在锁的保护下从map中读取
		    return v, existed
		}
	2. 使用指定map
		使用并发安全的数据结构 `sync.Map`，它是 Go 标准库提供的专门用于并发安全的 map
		func main() {
		var m sync.Map

		go func() {
			for i := 0; i < 1000; i++ {
				m.Store(fmt.Sprintf("key%d", i), i)
			}
		}()

		go func() {
			for i := 0; i < 1000; i++ {
				m.Delete(fmt.Sprintf("key%d", i))
			}
		}()
创建一个数组底层扩容
	扩容+数组复制
make一个slice参数怎么写？
	var sl []int = make([]int, 0, 4)
链表和数组的区别，以及各种操作上的复杂度
	PHP 数组的底层实现是散列表
谈下对散列表的理解，深入
	key - value 之间存在一个映射函数，可以根据 key 通过映射函数得到的散列值直接索引到对应的 value 值，无需通过关键字比较，在理想情况下，不考虑散列冲突，散列表的查找效率是非常高的，时间复杂度是 O(1)
如果要从redis里面删除大量的数据要怎么做？
	脚本程序执行 SCAN 命令，这样就不必担心重复执行的效率问题了。针对 DEL 可能造成的阻塞问题，可以使用 EXPIRE 命令替换
	SCAN 命令就是通过游标的方式分步从数据库获取数据，每次以游标方式进行遍历（游标从上一次遍历结果中返回，初始游标为0），结果会返回一个新游标和匹配的键集合（键的数量不不确定，与 COUNT 正相关），如果返回游标为0则视为遍历结束（不以遍历结果为空作为结束标识）。可以使用 MATCH 匹配模式，COUNT 限制返回的键的个数

redis的setnx底层怎么实现的？
	$ok = $redis->set($key, $random, array('nx', 'ex' => $ttl));
	if ($ok) {
	    $cache->update();

	    if ($redis->get($key) == $random) {
	        $redis->del($key);
	    }
	}
	+协程延期过期时间
说下websocket是哪一层协议？
	WebSocket同HTTP一样也是应用层的协议，但是它是一种双向通信协议，是建立在TCP之上的
WebSocket与Socket的关系
	1. 连接方式：WebSocket是一种基于TCP的协议，可以使用HTTP或HTTPS协议的端口进行连接；而Socket是一种用于在应用层和传输层之间建立连接的一种技术，可以使用任意端口进行连接。
	2. 通信方式：WebSocket支持双向通信，客户端和服务器可以同时发送和接收消息；而Socket也是支持双向通信的，但需要客户端和服务器分别建立一条连接。
	3. 数据格式：WebSocket使用消息的方式进行数据传输，可以使用文本、二进制等不同格式；而Socket可以传输任意类型的数据，包括文本、二进制、图片、音频等。
	4. 协议和API：WebSocket使用的是一种自定义的协议，使用WebSocket API进行通信；而Socket没有特定的协议，可以使用不同的协议进行通信，如TCP、UDP等。
	关系：
	WebSocket是在Socket的基础上发展起来的，WebSocket的底层实现依赖于Socket技术。WebSocket在建立连接时会使用HTTP协议进行握手，然后将连接升级为WebSocket协议，之后双方使用Socket进行数据传输。因此，WebSocket可以看作是在Socket的基础上提供了更高层次的应用协议，更加方便和易于使用。
forrange坑输出
	错误
		func main() {
			arr1 := []int{1, 2, 3}
			arr2 := make([]*int, len(arr1))
			for i, v := range arr1 {
				arr2[i] = &v
			}
			for _, v := range arr2 {
				fmt.Println(*v)
			}
		}
	然而真正的结果是
		3
		3
		3
	改进
		func main() {
			arr1 := []int{1, 2, 3}
			arr2 := make([]*int, len(arr1))
			for i := range arr1 {
				arr2[i] = &arr1[i]
			}
			for _, v := range arr2 {
				fmt.Println(*v)
			}
		}
消息重试，消息幂等问题
	数据库唯一索引/redis的set中去
能对比一下websocket、长连接、EventSource的优缺点吗
算法题：n*n的矩阵，按圈顺时针打印这个矩阵
切片的底层实现
	切片本身并不是动态数组或者数组指针。它内部实现的数据结构通过指针引用底层数组，设定相关属性将数据读写操作限定在指定的区域内。切片本身是一个只读对象，其工作机制类似数组指针的一种封装。
dockerfilecmd和entrypoint有什么区别
	CMD 指令的目的是：为容器提供默认的执行命令,其中指令有三种使用方式
		一种是为 ENTRYPOINT 提供默认的参数
		exec 模式和 shell 模式
写个channel相关的题，并发模型，爬虫url，控制并发量
信令用wss还是ws？
	与http,https的区别一样
wss是基于tcp的，tcp有个半连接队列，有没有遇到发了信令但是服务器没收到的情况？
k8s有几种service类型
	ClusterIP
		这是K8S默认的服务类型，只能在K8S中进行服务通信。在ClientIP中，K8S会在Service创建完毕后提供一个内部IP作为ClientIP属性，K8S内部服务可以通过ClientIP或者ServiceName来访问该服务。
	NodePort
		是Service type是Nodeport的实现，NodePort通过配置nodePort属性，外部用户可以通过NodeIP:NodePort的方式单独访问每个Node上的服务。
	LoadBalancer
		是可以实现集群外部访问服务的另外一种解决方案。不过并不是所有的k8s集群都会支持，大多是在公有云托管集群中会支持该类型。负载均衡器是异步创建的，关于被提供的负载均衡器的信息将会通过Service的status.loadBalancer字段被发布出去。
	ExternalName
		设置Service的type为ExternalName。这样做的好处就是内部服务访问外部服务的时候是通过别名来访问的，屏蔽了外部服务的真实信息，外部服务对内部服务透明，外部服务的修改基本上不会影响到内部服务的访问，做到了内部服务和外部服务解耦合。
go怎么实现封装继承多态
	继承
		通过相应的结构体之间的组合来实现类似的继承效果
	封装
		Go通过首字母是否大写判断：首字母大写为public，首字母小写为private；Go中只有public和private两种。
	多态
		通过接口（interface）实现。定义一个interface类型，该类型说明了它有哪些方法。struct实现了某个interface中的所有方法，那么我们就认为，这个struct实现了这个类。
		使用时，在函数中，将该interface类型作为函数的形参，任意一个实现了interface类型的实参都能作为该interface的实例对象。Go中没有implements关键字，与Java的实现多态相比，Go的组合更加灵活。
SSL/TLS四次挥手
	1.客户端请求建立SSL链接，并向服务端发送一个随机数–Client random和客户端支持的加密方法，比如RSA公钥加密，此时是明文传输。
	2.服务端回复一种客户端支持的加密方法、一个随机数–Server random、授信的服务器证书和非对称加密的公钥。
	3.客户端收到服务端的回复后利用服务端的公钥，加上新的随机数–Premaster secret 通过服务端下发的公钥及加密方法进行加密，发送给服务器。
	4.服务端收到客户端的回复，利用已知的加解密方式进行解密，同时利用Client random、Server random和Premaster secret通过一定的算法生成HTTP链接数据传输的对称加密key – session key。
		1.Change Cipher Spec是服务器向客户端通知，后面发送的消息都会使用协商出来的密钥进行加密。
		2.Encrypted Handshake Message与第三次握手类似，是服务器发给客户端的用来确定协商的密钥是一致的，也是一条Server Finish消息。
defer与panic的顺序
	defer遇到panic会先调用，而后执行panic
go中声明常量
	const (
		AA = 33
		BB = AA * 6
	)
这道题目考的是结构体的比较，有几个需要注意的地方：
	sn1 := struct {
        age  int
        name string
    }{age: 11, name: "qq"}
    sn2 := struct {
        age  int
        name string
    }{age: 11, name: "qq"}

    if sn1 == sn2 {
        fmt.Println("sn1 == sn2")
    }
    sn3:= struct {
        name string
        age  int
    }{age:11,name:"qq"}
	结构体只能比较是否相等，但是不能比较大小。
	相同类型的结构体才能够进行比较，结构体是否相同不但与属性类型有关，还与属性顺序相关，sn3 与 sn1 就是不同的结构体；
type声明
	type MyInt1 int
		是定义了一个新的数据类型`MyInt1`，它底层的类型是`int`。这意味着`MyInt1`和`int`是不同的类型，并且不能直接进行类型转换。例如，`MyInt1`类型的变量不能直接赋值给`int`类型的变量，需要显式地进行类型转换。
	type MyInt2 = int
		是定义了一个类型别名`MyInt2`，它和`int`是同一个类型。这意味着`MyInt2`可以被视为`int`的别名，可以直接进行类型转换，也可以直接将`MyInt2`类型的变量赋值给`int`类型的变量。
iota
	const (
		x = iota
		_
		y
		z = "zz"
		k
		p = iota
	)
	fmt.Println(x,y,z,k,p)输出：0 2 zz zz 5
类型断言
	类型选择的语法形如：i.(type)，其中 i 是接口，type 是固定关键字，需要注意的是，只有接口类型才可以使用类型选择。
在go语言中，nil可以代表下面这些类型的零值：
	指针类型（包括unsafe中的）
	map类型
	slice类型
	function类型
	channel类型
	interface类型
	在Go语言中，如果你声明了一个变量但是没有对它进行赋值操作，那么这个变量就会有一个类型的默认零值。这是每种类型对应的零值：
	type People interface {
	    Show()
	}

	type Student struct{}

	func (stu *Student) Show() {

	}

	func main() {

	    var s *Student
	    if s == nil {
	        fmt.Println("s is nil")
	    } else {
	        fmt.Println("s is not nil")
	    }
	    var p People = s
	    if p == nil {
	        fmt.Println("p is nil")
	    } else {
	        fmt.Println("p is not nil")
	    }
	}
	s is nil 和 p is not nil。这道题会不会有点诧异，我们分配给变量 p 的值明明是 nil，然而 p 却不是 nil。记住一点，当且仅当动态值和动态类型都为 nil 时，接口类型值才为 nil。上面的代码，给变量 p 赋值之后，p 的动态值是 nil，但是动态类型却是 *Student，是一个 nil 指针，所以相等条件不成立
多重赋值分为两个步骤，有先后顺序：
	func main() {
	    i := 1
	    s := []string{"A", "B", "C"}
	    i, s[i-1] = 2, "Z"
	    fmt.Printf("s: %v \n", s)
	}
	s: [Z,B,C]
	计算等号左边的索引表达式和取址表达式，接着计算等号右边的表达式；
	赋值；
输出顺序
	func F(n int) func() int {
	    return func() int {
	        n++
	        return n
	    }
	}

	func main() {
	    f := F(5)
	    defer func() {
	        fmt.Println(f())
	    }()
	    defer fmt.Println(f())
	    i := f()
	    fmt.Println(i)
	}
	参考答案及解析：768。知识点：匿名函数、defer()。defer() 后面的函数如果带参数，会优先计算参数，并将结果存储在栈中，到真正执行 defer() 的时候取出。
recover()函数使用
	recover() 必须在 defer() 函数中直接调用才有效。
goto
	goto 不能跳转到其他函数或者内层代码
String()
	String()的调用区分是指针方法，还是值方法,不同是不会调用的
	func (o Orange) String() string {
	}
	func (o *Orange) String() string {
	}
相同声明
	var f = func(i int) {
	    print("x")
	}

	func main() {
	    f := func(i int) {
	        print(i)
	        if i > 0 {
	            f(i - 1)
	        }
	    }
	    f(10)
	}
	这道题一眼看上去会输出 109876543210，其实这是错误的答案，这里不是递归。假设 main() 函数里为 f2()，外面的为 f1()，当声明 f2() 时，调用的是已经完成声明的 f1()
	看下面这段代码你应该会更容易理解一点：
	var x = 23

	func main() {
	    x := 2*x - 4
	    println(x)    // 输出:42
	}
短变量声明语句中至少要声明一个新的变量；
由于append后，aa的地址发生了改变，此时aa和a指向的已经不是同一块地址，因此aa的改变不会影响a
类型转换
	// 不能通过编译
	type T int
	func F(t T) {}
	func main() {
	    var q int
	    F(q)
	}
	// 可以通过编译
	type T []int
	func F(t T) {}
	func main() {
	    var q []int
	    F(q)
	}
	不同类型的值是不能相互赋值的，即使底层类型一样，所以第一题编译不通过；
	对于底层类型相同的变量可以相互赋值还有一个重要的条件，即至少有一个不是有名类型（named type）
	Named Type 有两类：
		内置类型，比如 int, int64, float, string, bool 等；
		使用关键字 type 声明的类型；
	Unnamed Type 是基于已有的 Named Type 组合一起的类型，例如：struct{}、[]string、interface{}、map[string]bool 等
除 init() 函数之外，一个包内不允许有其他同名函数。
init() 函数不能被其他函数调用，包括 main() 函数。
当使用 type 声明一个新类型，它不会继承原有类型的方法集。
map 属于引用类型，并发读写时多个协程是通过指针访问同一个地址，即访问共享变量，此时同时读写资源存在竞争关系，会报错 “fatal error: concurrent map read and map write”。
加锁后复制变量，会将锁的状态也复制，所以 mu1 其实是已经加锁状态，再加锁会死锁。
go中左值与右值
	type Foo struct {
	    name string
	}

	func (f *Foo) PointerMethod() {
	    fmt.Println("pointer method on", f.name)
	}

	func (f Foo) ValueMethod() {
	    fmt.Println("value method on", f.name)
	}

	func NewFoo() Foo { // 返回一个右值
	    return Foo{name: "right value struct"}
	}
	func main() {
	    f1 := Foo{name: "value struct"}
		f1.PointerMethod() // 编译器会自动插入取地址符，变为 (&f1).PointerMethod()
	    f1.ValueMethod()

	    f2 := &Foo{name: "pointer struct"}
	    f2.PointerMethod() 
	    f2.ValueMethod() // 编译器会自动解引用，变为 (*f2).PointerMethod()

	    NewFoo().ValueMethod()
	    NewFoo().PointerMethod() // Error!!! ./pointer_method.go:34:10: cannot call pointer method on NewFoo()  ./pointer_method.go:34:10: cannot take the address of NewFoo()
	}
	看来编译器首先试着给 NewFoo()返回的右值调用 pointer method，出错；然后试图给其插入取地址符，未果，就只能报错了。
	至于左值和右值的区别，大家感兴趣可以自行搜索一下。大致来说，最重要区别就是是否可以被寻址，可以被寻址的是左值，既可以出现在赋值号左边也可以出现在右边；不可以被寻址的即为右值，比如函数返回值、字面值、常量值等等，只能出现在赋值号右边。
slice中的len与cap
	基于数组（切片）可以使用操作符 [i,j] 创建新的切片，从索引 i，到索引 j 结束，截取已有数组（切片）的任意部分，返回新的切片，新切片的值包含原数组（切片）的 i 索引的值，但是不包含 j 索引的值。i、j 都是可选的，i 如果省略，默认是 0，j 如果省略，默认是原数组（切片）的长度。i、j 都不能超过这个长度值
	假如底层数组的大小为 k，截取之后获得的切片的长度和容量的计算方法：长度：j-i，容量：k-i。
	截取操作符还可以有第三个参数，形如 [i,j,k]，第三个参数 k 用来限制新切片的容量，但不能超过原数组（切片）的底层数组大小。截取获得的切片的长度和容量分别是：j-i、k-i。
go中的context
	// context包的主要内容,详细可以看源文件
	type Context interface {
		Deadline() (deadline time.Time, ok bool)
		Done() <-chan struct{}
		Err() error
		Value(key interface{}) interface{}
	}
	type emptyCtx int
	func (*emptyCtx) Deadline() (deadline time.Time, ok bool) {
		return
	}
	func (*emptyCtx) Done() <-chan struct{} {
		return nil
	}
	func (*emptyCtx) Err() error {
		return nil
	}
	func (*emptyCtx) Value(key interface{}) interface{} {
		return nil
	}
	func (e *emptyCtx) String() string {
		switch e {
		case background:
			return "context.Background"
		case todo:
			return "context.TODO"
		}
		return "unknown empty Context"
	}
	var (
		background = new(emptyCtx)
		todo       = new(emptyCtx)
	)
	func Background() Context {
		return background
	}
	func TODO() Context {
		return todo
	}
	type CancelFunc func()
	func WithCancel(parent Context) (ctx Context, cancel CancelFunc) {
		if parent == nil {
			panic("cannot create context from nil parent")
		}
		c := newCancelCtx(parent)
		propagateCancel(parent, &c)
		return &c, func() { c.cancel(true, Canceled) }
	}
	...
	可以看出:
		1.context包初始化两个方法:
			Background() // 一般是所有 Context 的基础，所有 Context 的源头都应该是它, 常用语类似树形结构的根节点初始化
			TODO() // TODO 方法一般用于当传入的方法不确定是哪种类型的 Context 时，为了避免 Context 的参数为nil而初始化的 Context。
		2.四个抽象方法:
			Deadline() (deadline time.Time, ok bool)
			Done() <-chan struct{}
			Err() error
			Value(key interface{}) interface{}
		3.派生出来的方法
			func WithCancel(parent Context) (ctx Context, cancel CancelFunc){} // 基于 ctx 构造的子 context 都会被取消。不同点在于 WithCancel 必需要手动调用 cancel 方法
			func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) {} // WithDeadline 可以设置一个时间点
			func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) {} // WithTimeout 是设置调用的持续时间，到指定时间后，会调用 cancel 做取消操作。
			func WithValue(parent Context, key, val interface{}) Context {} // 用来创建传递 traceId， token 等重要数据的 Context。
	例子:	
		1.在做数据库查询时，需要对数据的查询做超时控制
			ctx = context.WithTimeout(context.Background(), time.Second)
			rows, err := pool.QueryContext(ctx, "select * from products where id = ?", 100)
Go值接收者和指针接收者的区别
	值类型既可以调用值接收者的方法，也可以调用指针接收者的方法；指针类型既可以调用指针接收者的方法，也可以调用值接收者的方法。
	函数和方法		值接收者														指针接收者
	值类型调用者		方法会使用调用者的一个副本，类似于“传值”						使用值的引用来调用方法，上例中，p1.GetAge() 实际上是 (&p1).GetAge().
	指针类型调用者	指针被解引用为值，上例中，p2.GetAge()实际上是 (*p1).GetAge()	实际上也是“传值”，方法里的操作会影响到调用者，类似于指针传参，拷贝了一份指针
</pre>