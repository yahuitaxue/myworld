---
title: Redis实践
author: Yahui
layout: nosql
category: NoSQL
---

书名：《Redis实践》

<pre style="text-align: left;">
<span class="image featured"><img src="{{ 'assets/images/other/nosqlall.jpg' | relative_url }}" alt="" /></span>
<span class="image featured"><img src="{{ 'assets/images/other/redistype.jpg' | relative_url }}" alt="" /></span>
(在Linux中安装redis后可以使用redis-cli来使用)
Redis在PHP中的应用
	初始化：
		//连接本地的 Redis 服务
		$redis = new Redis();
		$redis->connect('127.0.0.1', 6379);
		echo "Connection to server successfully";
		     //查看服务是否运行
		echo "Server is running: " . $redis->ping();
	字符串类型(String O(1))：
		使用场景：
			缓存功能：字符串最经典的使用场景，redis最为缓存层，Mysql作为储存层，绝大部分请求数据都是redis中获取，由于redis具有支撑高并发特性，所以缓存通常能起到加速读写和降低 后端压力的作用。
			计数器：许多运用都会使用redis作为计数的基础工具，他可以实现快速计数、查询缓存的功能，同时数据可以一步落地到其他的数据源。如：视频播放数系统就是使用redis作为视频播放数计数的基础组件。
			共享session：出于负载均衡的考虑，分布式服务会将用户信息的访问均衡到不同服务器上，用户刷新一次访问可能会需要重新登录，为避免这个问题可以用redis将用户session集中管理，在这种模式下只要保证redis的高可用和扩展性的，每次获取用户更新或查询登录信息都直接从redis中集中获取。
			限速：处于安全考虑，每次进行登录时让用户输入手机验证码，为了短信接口不被频繁访问，会限制用户每分钟获取验证码的频率。
			还有一种用得比较多的是string的incr/decr操作，即自减/自增操作。

			$redis -> set('key','value');
			$redis -> get('key');
			$redis -> del('key');
			$redis->set('key','TK');
			$redis->set('number','1');
			$redis->setex('key',5,'TK'); //设置有效期为5秒的键值
			$redis->psetex('key',5000,'TK'); //设置有效期为5000毫秒(同5秒)的键值
			$redis->setnx('key','XK'); //若键值存在返回false 不存在返回true
			$redis->delete('key'); 删除键值 可以传入数组 array('key1','key2')删除多个键
			$redis->getSet('key','XK'); //将键key的值设置为XK， 并返回这个键值原来的值TK
			$ret = $redis->multi()  //批量事务处理,不保证处理数据的原子性
			    ->set('key1', 'val1')
		        ->get('key1')
		        ->setnx('key', 'val2')
		        ->get('key2')
		        ->exec();
			$redis->watch('key');   // 监控键key 是否被其他客户端修改如果KEY在调用watch()和exec()之间被修改，exec失败
			function f($redis, $chan, $msg) {  //频道订阅
			    switch($chan) {
			        case 'chan-1':
			            echo $msg;
			            break;
			        case 'chan-2':
			            echo $msg;
			            break;
			        case 'chan-2':
			            echo $msg;
			            break;
			    }
			}
			$redis->subscribe(array('chan-1', 'chan-2', 'chan-3'), 'f'); // subscribe to 3 chans
			$redis->publish('chan-1', 'hello, world!'); // send message. 
			$redis->exists('key'); //验证键是否存在，存在返回true
			$redis->incr('number'); //键值加1
			$redis->incrby('number',-10); //键值加减10
			$redis->incrByFloat('number', +/- 1.5); //键值加减小数
			$redis->decr('number'); // 键值减1
			$redis->decrBy('number',10); // 键值减10
			$mget = $redis->mget(array('number','key')); // 批量获取键值,返回一个数组
			$redis->mset(array('key0' => 'value0', 'key1' => 'value1')); // 批量设置键值
			$redis->msetnx(array('key0' => 'value0', 'key1' => 'value1')); // 批量设置键值，类似将setnx()方法批量操作
			$redis->append('key', '-Smudge'); //原键值TK，将值追加到键值后面，键值为TK-Smudge
			$redis->getRange('key', 0, 5); // 键值截取从0位置开始到5位置结束
			$redis->getRange('key', -6, -1); // 字符串截取从-6(倒数第6位置)开始到-1(倒数第1位置)结束
			$redis->setRange('key', 0, 'Smudge'); // 键值中替换字符串，0表示从0位置开始有多少个字符替换多少位置，其中汉字占2个位置
			$redis->strlen('key'); //键值长度
			$redis->getBit('key');
			$redis->setBit('key');
	队列类型(List O(N))：(l与r同理)(队列可以存储相同的字符串)
		使用场景：
			消息队列： redis的lpush+brpop命令组合即可实现阻塞队列，生产者客户端是用lupsh从列表左侧插入元素，多个消费者客户端使用brpop命令阻塞时的“抢”列表尾部的元素，多个客户端保证了消费的负载均衡和高可用性
			lpush+lpop=Stack(栈) 
			lpush+rpop=Queue（队列） 
			lpush+ltrim=Capped Collection（有限集合） 
			lpush+brpop=Message Queue（消息队列）

			$redis -> lpush('name','value');
			$redis -> lpop('name');
			$redis -> keys("*");// 获取所有队列的名称
			$redis -> llen('name');// 这个没有r
			$redis -> lindex('name',索引位置);// 同样没有r
			$redis -> lrange('name',起始位置,终止位置);// 同样没有r
			$redis -> lrem('name','value',count);// 删除name中count个值为value的
			$redis -> del('name');
			$redis->delete('list-key'); // 删除链表
			$redis->lPush('list-key', 'A'); //插入链表头部/左侧，返回链表长度
			$redis->rPush('list-key', 'B'); //插入链表尾部/右侧，返回链表长度
			$redis->lPushx('list-key', 'C'); // 插入链表头部/左侧,链表不存在返回0，存在即插入成功，返回当前链表长度
			$redis->rPushx('list-key', 'C'); // 插入链表尾部/右侧,链表不存在返回0，存在即插入成功，返回当前链表长度
			$redis->lPop('list-key'); //返回LIST顶部（左侧）的VALUE ,后入先出(栈)
			$redis->rPop('list-key'); //返回LIST尾部（右侧）的VALUE ,先入先出（队列）
			$redis->blPop();
			$redis->brPop();
			$redis->lSize('list-key'); // 如果是链表则返回链表长度，空链表返回0若不是链表或者不为空，则返回false ,判断非链表 " === false "                          
			$redis->lGet('list-key',-1); // 通过索引获取链表元素 0获取左侧一个  -1获取最后一个
			$redis->lSet('list-key', 0, 'X'); //0位置元素替换为 X
			$redis->lRange('list-key', 0, 3); //链表截取 从0开始 3位置结束 ，结束位置为-1 获取开始位置之后的全部
			$redis->lTrim('list-key', 0, 1); // 截取链表(不可逆) 从0索引开始 1索引结束 
			$redis->lRem('list-key', 'C', 2); //链表从左开始删除元素2个C
			$redis->lInsert('list-key', Redis::BEFORE, 'C', 'X'); // 在C元素前面插入X  , Redis::AfTER(表示后面插入) 链表不存在则插入失败 返回0 若元素不存在返回-1
			$redis->rpoplpush('list-key', 'list-key2'); //从源LIST的最后弹出一个元素并且把这个元素从目标LIST的顶部（左侧）压入目标LIST。 
			$redis->brpoplpush(); //rpoplpush的阻塞版本，这个版本有第三个参数用于设置阻塞时间即如果源LIST为空，那么可以阻塞监听timeout的时间，如果有元素了则执行操作。
	散列类型(Hash O(1) 成员各不相同)：
		使用场景：
			哈希结构相对于字符串序列化缓存信息更加直观，并且在更新操作上更加便捷。所以常常用于**用户信息**等管理，但是哈希类型和关系型数据库有所不同，哈希类型是稀疏的，而关系型数据库是完全结构化的，关系型数据库可以做复杂的关系查询，而redis去模拟关系型复杂查询开发困难，维护成本高。

			$redis -> hset('name','key','value');
			$redis -> hget('name','key');
			$redis -> hgetall('name');
			$redis -> hdel('name','key');
			$redis -> del('name');
			$redis->hSet('h', 'name', 'TK'); // 在h表中 添加name字段 value为TK
			$redis->hSetNx('h', 'name', '1TK'); // 在h表中 添加name字段 value为TK 如果字段name的value存在返回false 否则返回 true
			$redis->hGet('h', 'name'); // 获取h表中name字段value
			$redis->hLen('h'); // 获取h表长度即字段的个数
			$redis->hDel('h','email'); // 删除h表中email 字段
			$redis->hKeys('h'); // 获取h表中所有字段
			$redis->hVals('h'); // 获取h表中所有字段value
			$redis->hGetAll('h'); // 获取h表中所有字段和value 返回一个关联数组(字段为键值)
			$redis->hExists('h', 'email'); //判断email 字段是否存在与表h 不存在返回false
			$redis->hSet('h', 'age', 28);
			$redis->hIncrBy('h', 'age', -2); // 设置h表中age字段value加(-2) 如果value是个非数值 则返回false 否则，返回操作后的value
			$redis->hIncrByFloat('h', 'age', -0.33); // 设置h表中age字段value加(-2.6) 如果value是个非数值 则返回false 否则返回操作后的value(小数点保留15位)
			$redis->hMset('h', array('score' => '80', 'salary' => 2000)); // 表h 批量设置字段和value全选复制放进笔记
			$redis->hMGet('h', array('score','salary')); // 表h 批量获取字段的value
			(如果散列包含的值非常大，那么可以先使用HKEYS取出散列包含的所有键，然后再使用HGET一个个的取出键的值，从而避免一次获取多个大体积的值导致服务器阻塞)
	集合类型(Set O(N) 成员各不相同)：
		使用场景：
			标签（tag）：集合类型比较典型的使用场景，如一个用户对娱乐、体育比较感兴趣，另一个可能对新闻感兴趣，这些兴趣就是标签（标签的名字不可以重复，顺序是可以无序的。）有了这些数据就可以得到同一标签的人，以及用户的共同爱好的标签，这些数据对于用户体验以及曾强用户粘度比较重要。（用户和标签的关系维护应该放在一个事物内执行，防止部分命令失败造成数据不一致）
			sadd=tagging（标签）
			spop/srandmember=random item（生成随机数，比如抽奖）
			sadd+sinter=social Graph(社交需求)

			$redis -> sadd('name','value');
			$redis -> smembers('name');// 统计name的所有值
			$redis -> sismember('name','value');// 检测name中是否存在值1
			$redis -> srem('name','value',count);// 删除name中值为value的
			$redis->sMembers('key'); //获取容器key中所有元素
			$redis->sAdd('key' , 'TK'); // (从左侧插入,最后插入的元素在0位置),集合中已经存在TK 则返回false不存在添加成功 返回true
			$redis->sRem('key' , 'TK'); // 移除容器中的TK
			$redis->sMove('key','key1','TK'); //将容易key中的元素TK 移动到容器key1  操作成功返回TRUE
			$redis->sIsMember('key','TK'); //检查VALUE是否是SET容器中的成员
			$redis->sCard('key'); //返回SET容器的成员数
			$redis->sPop('key'); //随机返回容器中一个元素，并移除该元素
			$redis->sRandMember('key');//随机返回容器中一个元素，不移除该元素
			$redis->sInter('key','key1'); // 返回两个集合的交集 没有交集返回一个空数组，若参数只有一个集合，则返回集合对应的完整的数组
			$redis->sInterStore('store','key','key1'); //将集合key和集合key1的交集 存入容器store 成功返回1
			$redis->sUnion('key','key1'); //集合key和集合key1的并集  注意即使多个集合有相同元素 只保留一个
			$redis->sUnionStore('store','key','key1'); //集合key和集合key1的并集保存在集合store中,  注意即使多个集合有相同元素 只保留一个
			$redis->sDiff('key','key1','key2'); //返回数组，该数组元素是存在于key集合而不存在于集合key1 key2
	有序集合类型(Sorted Set O(log(N)))
		使用场景：
			排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。

			$redis->zAdd('name',分数值1,'value1',分数值2,'value2');
		    $redis -> zrange('name',0,-1);从小到大取出数据
		   	$redis -> zRevRange('name',0,-1,true);以值为下标，分数为值从大到小取出数据
		    $redis -> zrem($key1,'k1'); // 删除k1
		    $redis -> zRangeByLex($key1,'[k1','[k2')); // 根据value取出value介于k1到k2的值
		    $redis -> zRevRangeByScore($key1,500,0,array('withscores' => true))); // 根据分数值取出0~500之间，由于加上Rev是从大到小，所以分数也需要从大到小
			$redis->zAdd('tkey', 1, 'A'); //  插入集合tkey中，A元素关联一个分数，插入成功返回1同时集合元素不可以重复, 如果元素已经存在返回 0
			$redis->zRange('tkey',0,-1); // 获取集合元素，从0位置 到 -1 位置
			$redis->zRange('tkey',0,-1, true); // 获取集合元素，从0位置 到 -1 位置, 返回一个关联数组 带分数array([A] => 0.01,[B] => 0.02,[D] => 0.03) 其中小数来自zAdd方法第二个参数
			$redis->zDelete('tkey', 'B'); // 移除集合tkey中元素B  成功返回1 失败返回 0
			$redis->zRevRange('tkey', 0, -1); // 获取集合元素，从0位置 到 -1 位置，数组按照score降序处理
			$redis->zRevRange('tkey', 0, -1,true); // 获取集合元素，从0位置 到 -1 位置，数组按照score降序处理 返回score关联数组
			$redis->zRangeByScore('tkey', 0, 0.2,array('withscores' => true)); //获取几个tkey中score在区间[0,0.2]元素 ,score由低到高排序,元素具有相同的score，那么会按照字典顺序排列 , withscores 控制返回关联数组
			$redis->zRangeByScore('tkey', 0.1, 0.36, array('withscores' => TRUE, 'limit' => array(0, 1))); //其中limit中 0和1 表示取符合条件集合中 从0位置开始，向后扫描1个 返回关联数组
			$redis->zCount('tkey', 2, 10); // 获取tkey中score在区间[2, 10]元素的个数
			$redis->zRemRangeByScore('tkey', 1, 3); // 移除tkey中score在区间[1, 3](含边界)的元素
			$redis->zRemRangeByRank('tkey', 0, 1); //默认元素score是递增的，移除tkey中元素 从0开始到-1位置结束
			$redis->zSize('tkey');  //返回存储在key对应的有序集合中的元素的个数
			$redis->zScore('tkey', 'A'); // 返回集合tkey中元素A的score值
			$redis->zRank('tkey', 'A'); // 返回集合tkey中元素A的索引值z集合中元素按照score从低到高进行排列 ，即最低的score index索引为0
			$redis->zIncrBy('tkey', 2.5, 'A'); // 将集合tkey中元素A的score值 加 2.5
			$redis->zUnion('union', array('tkey', 'tkey1')); // 将集合tkey和集合tkey1元素合并于集合union , 并且新集合中元素不能重复返回新集合的元素个数， 如果元素A在tkey和tkey1都存在，则合并后的元素A的score相加
			$redis->zUnion('ko2', array('k1', 'k2'), array(5, 2)); // 集合k1和集合k2并集于k02 ，array(5,1)中元素的个数与子集合对应，然后 5 对应k1 k1每个元素score都要乘以5 ，同理1对应k2，k2每个元素score乘以1 然后元素按照递增排序，默认相同的元素score(SUM)相加
			$redis->zUnion('ko2', array('k1', 'k2'), array(10, 2),'MAX'); // 各个子集乘以因子之后，元素按照递增排序，相同的元素的score取最大值(MAX)也可以设置MIN 取最小值
			$redis->zInter('ko1', array('k1', 'k2')); // 集合k1和集合k2取交集于k01 ，且按照score值递增排序如果集合元素相同，则新集合中的元素的score值相加
			$redis->zInter('ko1', array('k1', 'k2'), array(5, 1)); //集合k1和集合k2取交集于k01 ，array(5,1)中元素的个数与子集合对应，然后 5 对应k1 k1每个元素score都要乘以5 ，同理1对应k2，k2每个元素score乘以1，然后元素score按照递增排序，默认相同的元素score(SUM)相加
			$redis->zInter('ko1', array('k1', 'k2'), array(5, 1),'MAX'); // 各个子集乘以因子之后，元素score按照递增排序，相同的元素score取最大值(MAX)也可以设置MIN 取最小值
		
实例：
	将整个购物车存储到cookie里面，最大优点就是无需对数据库进行写入就可以实现购物车功能，缺点就是程序需要重新解析验证cookie，确保格式正确。另外一个缺点就是浏览器每次发送请求都会连cookie一起发送，如果购物车体积比较大，那么发送和处理的速度会有所降低。

数据持久化
	一种叫快照，可以将存在于某一时刻的所有数据写入硬盘里面。
	一种叫追加文件(AOF)，在执行写命令时，将被执行的写命令复制到硬盘里。	
	将内存中的数据存到硬盘主要原因是为了在之后重用数据，或是为了防止系统故障而将数据备份到一个远程位置。
	redis配置文件,redis.conf
		(快照持久化选项)
			#   900秒（15分钟）内有1个更改
		save 900 1
			#   300秒（5分钟）内有10个更改
		save 300 10
			#   60秒内有10000个更改
		save 60 10000
			# 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大默认是yes
		rdbcompression yes
			# 如果启用如上的快照（RDB），在一个存盘点之后，可能磁盘会坏掉或者权限问题，redis将依然能正常工作
		stop-writes-on-bgsave-error yes
			# 指定本地数据库文件名，默认值为dump.rdb
		dbfilename dump.rdb

		(AOF持久化选项)
			# 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失
		appendonly no
			# 指定更新日志条件，共有3个可选值：
			# no:表示等操作系统进行数据缓存同步到磁盘（快）
			# always:表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）
			# everysec:表示每秒同步一次（折衷，默认值），当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度适应硬盘的最大写入速度
		appendfsync everysec
			# 如果 no-appendfsync-on-rewrite=yes, 这个时候主线程的 set 操作会被阻塞掉, 由于没有新的值写入 redis, 所有就没有这个时候数据丢失的可能. 一旦 tmp.aof 重写成功, 就不会有数据丢失.
			# 如果 no-appendfsync-on-rewrite=no, 这个时候主线程的 set 操作不会阻塞, 就会有新值写入 redis, 但是这部分记录不会同步到硬盘上, 就会有数据丢失的问题可能. 一旦 tmp.aof 重写成功就发生故障, 就会产生数据丢失.
		no-appendfsync-on-rewrite no
			# aof文件增长比例，指当前aof文件比上次重写的增长比例大小。aof重写即在aof文件在一定大小之后，重新将整个内存写到aof文件当中，以反映最新的状态(相当于bgsave)。这样就避免了，aof文件过大而实际内存数据小的问题(频繁修改数据问题).
		auto-aof-rewrite-percentage 100
			# aof文件重写最小的文件大小，即最开始aof文件必须要达到这个文件时才触发，后面的每次重写就不会根据这个变量了(根据上一次重写完成之后的大小).此变量仅初始化启动redis有效.如果是redis恢复时，则lastSize等于初始aof文件大小.
		auto-aof-rewrite-min-size 64mb
	
			# 工作目录，注意，这里只能指定一个目录
		dir /var/lib/redis

			我们的这个Redis示例使用AOF进行持久化(appendonly)，appendfsync策略采用的是everysec刷盘。但是AOF随着时间推移，文件会越来越大，因此，Redis还有一个rewrite策略，实现AOF文件的减肥，但是结果的幂等的。我们no-appendfsync-on-rewrite的策略是 no. 这就会导致在进行rewrite操作时，appendfsync会被阻塞。如果当前AOF文件很大，那么相应的rewrite时间会变长，appendfsync被阻塞的时间也会更长。

			将no-appendfsync-on-rewrite设置为yes. 这样可以避免与appendfsync争用文件句柄，但是在rewrite期间的AOF有丢失的风险。
			给当前Redis实例添加slave节点，当前节点设置为master, 然后master节点关闭AOF，slave节点开启AOF。这样的方式的风险是如果master挂掉，尚没有同步到salve的数据会丢失。
			我们采取了折中的方式：在master节点设置将no-appendfsync-on-rewrite设置为yes，同时添加slave节点。

	快照持久化：只适用于哪些及时丢失一部分数据也不会造成问题的程序：系统发生崩溃，用户将丢失最近一次生成快照之后更改的所有数据。
		应用场景：
			1、个人开发。
			2、对日志进行聚合计算：即在将日志处理进度记录到redis中，程序崩溃后，可以根据进度记录继续执行那个之前未完成的处理工作。
			3、大数据：当redis数据量只有几个GB的时候，快照没有问题，但是如果redis内存占用量达到数十个GB那么执行BGSAVE可能会导致系统长时间停顿。
			为了防止Redis创建子进程出现停顿，我们可以考虑关闭自动保存，通过手动发送BGSAVE或者SAVE来进行持久化。虽然SAVE会一直阻塞Redis直到快照生成完毕，但是他不需要创建子进程，不会抢夺资源，所以SAVE创建快照速度会比BGSAVE创建快照的速度要快。
	AOF持久化：
		关键点：
			AOF持久化非常灵活地满足不同应用长须对数据安全的要求，但是AOF持久化也有缺陷，就是AOF文件的体积大小。
		注意：
			为了解决AOF文件体积不断增大的问题，用户可以向Redis发送BGREWRITEAOF命令，会通过移除AOF文件的冗余命令来重写AOF文件，是AOF文件体积尽肯能的小。但是这个命令与BGSAVE类似，创建一个子进程来对AOF文件进行重写。
		方法：
			AOF可以通过设置auto-aof-rewrite-percentage选项和auto-aof-rewrite-min-size选项来自动执行BGREWRITEAOF。举个例子，两个值设置为100和64mb，那么当AOF文件大于64MB并且AOF文件的体积比上一次重写之后的体积打了至少一倍(100%)的时候，Redis将执行BGREWRITEAOF命令，如果AOF重写执行的过于频繁的话，可以考虑第一个在100以上，这种方法可以让Redis在AOF文件的体积变得更大之后才执行重写操作。
	注：
		无论是AOF持久化还是快照持久化，将数据持久化到硬盘上是非常有必要的，但是除了进行持久化之外，用户还需对持久化所得的文件进行备份，这样才能尽量避免数据丢失事故发生。
	复制：
		<span class="image featured"><img src="{{ 'assets/images/other/rediscopy.jpg' | relative_url }}" alt="" /></span>
		(实际中，最好让主服务器使用50%~65%的内存，留下30%~45%的内存用于执行BGSAVE命令)

		Redis Master/Slave 主从配置
			这里我们配置 1台Master +1台Slave 为例子,其中:

		　　　　Master IP：***.***.***.***    Port：6379
		　　　　Slave IP：***.***.***.***     Port：6379

			注意：
				两台机器的IP地址要在同一网段内，否则无法实现集群。两台机器上均按照以上步骤安装并配置好redis服务。在Slave机器上修改配置文件，使其成为Master的从机。命令及配置如下：

		　　　　	#vi /usr/local/webserver/redis/conf/redis.conf
		　　　　	slaveof  ***.***.***.***  6379
		注：Redis不支持主主复制，被互相设置为主服务器的两个Redis只会支持的占用大量处理器资源并且连续不断的尝试与对方进行通信，而客户端的请求可能会得到不一致的数据或者得不到数据。
		<span class="image featured"><img src="{{ 'assets/images/other/redistree.jpg' | relative_url }}" alt="" /></span>

系统故障：
	1、验证快照或者AOF文件
		Redis提供了两个命令行程序，他们可以在系统故障发生后，检查AOF文件和快照文件的状态，并在有需要的情况下对文件进行修复。
			redis-check-aof
			Usage: redis-check-aof [--fix] "file.aof"
			redis-check-dump
			Usage: redis-check-dump "dump.rdb"
		如果运行程序是给定了--fix参数，那么程序将对AOF文件进行修复，程序修复AOF文件的方法非常简单，他会扫描给定的AOF文件，寻找不正确或不完整的命令，当发现第一个出错命令的时候，程序会删除出错的命令及之后的所有命令。遗憾的是目前没有办法可以修复出错的快照文件，因为快照文件本身经过了压缩，而在快照文件中间的错误有可能导致快照文件的剩余部分无法被读取。因此最好为重要的快照文件保留多个备份，并在进行数据恢复时，通过计算快照文件的SHA1和SHA256散列值来对内容进行验证。
	2、更换故障主服务器
		A(主发生故障),B(从),C(备用主)：
			首先向机器B发送一个SAVE命令，让他创建一个新的的快照文件。
			接着将这个快照文件发送给机器C，并在机器C上启动Redis。
			最后将机器B成为机器C的从服务器。
		<span class="image featured"><img src="{{ 'assets/images/other/redisbroken.jpg' | relative_url }}" alt="" /></span>

Redis事务
	以特殊命令MULTI为开始，之后跟着用户传入的过个命令，最后以EXEC为结束。但是由于着用简单的事务在EXEC命令被调用之前不会执行任何实际操作，所以用户将没办法根据读取到的数据来做决定。用户可以使用WATCH命令对键进行监视之后，直到用户执行EXEC命令的这段时间里面，如果有其他客户端抢险对任何监视的键进行了替换、更新或删除等操作，那么当用户尝试执行EXRC的时候，事务将失败并返回一个错误。通过使用WATCH、MULTI/EXEC、UNWATCH/DISCARD等命令，程序可以在执行某些重要操作的时候，通过确保自己正在使用的数据没有发生变化来避免数据出错。
		什么是DISCARD？UNWATCH命令可以在WATCH命令执行之后、MULTI命令执行之前对连接进行重置；同样的DISCARD命令也可以在MULTI命令执行之后EXEC命令执行之前对连接进行重置。这也就是说，用户在使用WATCH监视一个或多个键，接着使用MULTI开始一个新事务、并将多个命令入队到事务队列之后，仍然可以通过发送DISCARD命令来取消WATCH命令清空所有已入队命令。

	Redis只会在数据已经被其他客户端抢先修改了的情况下，通知执行了WATCH命令的客户端，这种做法称为乐观锁，而关系数据库实际执行的加锁操作称为悲观锁，乐观锁在实际使用中同样非常有效，因为客户端永远不必花时间去等待第一个取得锁的客户端--他们只需要在自己的事务执行失败的时候进行重试就可以了。

非事务性流水线：
	在需要执行大量命令的情况下，及时命令实际上并需要放在事务里面执行，但是为了通过一次发送所有命令来减少通信次数并降低延迟至，用户也可能会将命令包裹在MULTI和EXEC里面执行。但是MULTI和EXEC也会消耗资源，所以可以使用流水线(管道)：
		// 使用管道执行命令
		$redis = new \Redis();
	    $redis->connect('192.168.1.9', 6379);
	    $redis->auth('*****');//密码验证
	    $redis->select(0);//选择库
	    $redis->pipeline();//开启管道
	    foreach ($arr as $key => $value) {
	        $redis->hsetNx('helloworld', (string)$key, $value);
	    }
	    $redis->exec();

		// 通过管道读取，返回一个数组
	    $redis = new \Redis();
	    $redis->connect('192.168.1.9', 6379);
	    $redis->auth('******');
	    $redis->select(0);
	    $redis->pipeline();//开启管道

	    $redis->set('str1', 'h');
	    $redis->set('str2', 'e');
	    $redis->set('str3', 'l');
	    $redis->set('str4', 'l');
	pipeline()传入True或不传参数，那么客户端将使用MULTI和EXEC包裹起用户要执行的所有命令，如果参数为False，那么客户端同样会像执行事务那样收集起用户要执行的所有命令，只是不用MULTI和EXEC包裹起来。如果用户需要向Redis发送多个命令，并且对于这些命令来说，一个命令的执行结果并不会影响另一个命令的输入，并且不需要事务的话，可以传入False参数。
<span class="image featured"><img src="{{ 'assets/images/other/redispipiline.jpg' | relative_url }}" alt="" /></span>
	(经过测试高延迟网络使用流水线时的速度比不使用流水线时的速度快5倍左右)

可以使用redis-benchmark命令对redis进行压测
<span class="image featured"><img src="{{ 'assets/images/other/redisbenchmark.jpg' | relative_url }}" alt="" /></span>

使用Redis构建应用程序组件
	1、自动补全：
		1、如果指定的联系人已经存在于最近联系人列表中，那么从列表中移除他
		2、将指定的联系人添加到最近联系人列表的最前面
		3、如果添加操作完成之后，最近联系人列表包含的联系人数超过了100个，那么对列表进行修剪，只保留列表前的100个联系人
		(这种自动补全，后期还是需要程序进行前缀匹配)
		<span class="image featured"><img src="{{ 'assets/images/other/redisadd_update_contact.jpg' | relative_url }}" alt="" /></span>
	2、通讯录自动补全
		对包含非常多元素的列表进行自动补全，我们必须直接在Redis内部完成查找匹配元素的工作---就用到分值是0的有序集合，如果分值是一样的，那么有序集合将根据成员字符串二进制顺序进行排序。

分布式锁
	乐观锁：
		使用WATCH来构建基本乐观锁
			header("content-type:text/html;charset=utf-8"); 
			$redis = new redis(); 
			$result = $redis->connect('10.10.10.119', 6379); 
			$mywatchkey = $redis->get("mywatchkey"); 
			$rob_total = 100;  //抢购数量 
			if($mywatchkey<$rob_total){ 
				$redis->watch("mywatchkey"); 
				$redis->multi(); 
				//设置延迟，方便测试效果。 
				sleep(5); 
				//插入抢购数据 
				$redis->hSet("mywatchlist","user_id_".mt_rand(1, 9999),time()); 
				$redis->set("mywatchkey",$mywatchkey+1); 
				$rob_result = $redis->exec(); 
				if($rob_result){ 
				$mywatchlist = $redis->hGetAll("mywatchlist"); 
				echo "抢购成功！<br/>"; 
				echo "剩余数量：".($rob_total-$mywaftchkey-1)."<br/>"; 
				echo "用户列表：\<pre\>"; 
				var_dump($mywatchlist); 
				}else{ 
					echo "手气不好，再抢购！";exit; 
			  	}
			} 

	使用Redis构件锁：
		SETNX命令天生就是和用来实现锁的获取功能，这个命令只会在键不存在的情况下为键设置值，而锁要做的就是将一个随机生成的128位UUID设置为键的值。
		<span class="image featured"><img src="{{ 'assets/images/other/redisachievelock.jpg' | relative_url }}" alt="" /></span>

基于搜索的应用程序
	生成反向索引：
		<span class="image featured"><img src="{{ 'assets/images/other/redisrnindex.jpg' | relative_url }}" alt="" /></span>
		在索引里查找一个单词是非常容易的，程序之需获取单词集合里面的所有文档就可以了。但是要根据两个或多个单词查找文档的话，需要把给定单词集合里面的所有文档都找出来，然后再从中找到哪些在所有单词集合里面都出现了的文档。(SINTER命令和SINTERSTORE命令)
		<span class="image featured"><img src="{{ 'assets/images/other/redisrealindex.jpg' | relative_url }}" alt="" /></span>

构件简单的社交网站
	用户和状态
		用户信息：
			使用Redis的散列来存储用户信息。
			<span class="image featured"><img src="{{ 'assets/images/other/rediswebuser.jpg' | relative_url }}" alt="" /></span>
		状态消息：
			同样使用散列结构来存储状态消息。
			<span class="image featured"><img src="{{ 'assets/images/other/rediswebinfo.jpg' | relative_url }}" alt="" /></span>
		主页时间线：
			<span class="image featured"><img src="{{ 'assets/images/other/rediswebpagecut.jpg' | relative_url }}" alt="" /></span>
		更新关注者列表：
			<span class="image featured"><img src="{{ 'assets/images/other/rediswebupdate.jpg' | relative_url }}" alt="" /></span>
		取消关注：
			<span class="image featured"><img src="{{ 'assets/images/other/rediswebdel.jpg' | relative_url }}" alt="" /></span>
		消息发布：
			<span class="image featured"><img src="{{ 'assets/images/other/rediswebupindex.jpg' | relative_url }}" alt="" /></span>
		消息删除：
			<span class="image featured"><img src="{{ 'assets/images/other/rediswebdelindex.jpg' | relative_url }}" alt="" /></span>

Redis降低内存占用
	不同结构关于使用压缩列表表示的配置选项：
		// 散列结构使用压缩列表表示的限制条件
		hash-max-ziplist-entries 512
		hash-max-ziplist-value 64

		// 列表结构压缩列表表示的限制条件
		list-max-ziplist-entries 512
		list-max-ziplist-value 64

		// 有序结合使用压缩列表表示的限制条件
		zset-max-ziplist-entries 128
		zset-max-ziplist-value 64

		// 集合使用整数集合表示的限制条件
		set-max-intset-entries 512

Redis扩展
	slaveof "masterip" "masterport"命令把它配置为从服务器，当一个从服务器连接至主服务器的时候，从服务器原本存储的所有数据将被清空。最后可以通过向从服务器发送 slaveof no one命令可以让这个从服务器断开与主服务器的连接。
	<span class="image featured"><img src="{{ 'assets/images/other/redisresync.jpg' | relative_url }}" alt="" /></span>
	
	内存容量：
		1、对自己编写的所有方法进行检查，尽可能减少程序需要读取的数据量。
		2、将无关的功能迁移至其他服务器。
		3、对Redis进行写入之前，尝试在本地内存中将要写入的数据进行聚合计算，这一做法可以应用于所有分析方法和统计计算方法。
		4、使用锁去替换可能会给速度带来限制的 WATCH/MULTI/EXEC事务。
		5、在使用AOF持久化的情况下，机器的硬盘必须将程序写入的所有数据都存储起来，这需要花费一定的时间。
		
缓存系统问流程
    请求到达之后，业务线程首先访问缓存，如果缓存命中则返回
    如果未命中则继续请求磁盘数据库系统，获取数据返回
    从磁盘获取数据后将结果回写到缓存系统且增加老化时间，为下次请求做准备
    <span class="image featured"><img src="{{ 'assets/images/other/redismodel.jpg' | relative_url }}" alt="" /></span>
    以上是高并发系统中缓存和磁盘数据库系统、客户端请求之间的交互过程，后续的问题分析，也是基于此过程展开的。
    1.缓存雪崩(Cache Avalanche)问题
        缓存雪崩定义:
            所谓雪崩就是原来有所支撑的冰雪，某一瞬间失去依托，瞬间涌下来。在高并发系统，如果缓存系统故障，大量的请求无法从缓存完成数据请求，就全量汹涌冲向磁盘数据库系统，导致数据库被打死，整个系统彻底崩溃。
        缓存雪崩解决方案:
            造成缓存雪崩的主要原因是缓存系统不够高可用，因此提高缓存系统的稳定性和可用性十分必要，比如对于使用Redis作为缓存的系统而言可以使用哨兵机制、集群化、持久化等来提高缓存系统的HA。
            除了保证缓存系统的HA之外，服务本身也需要支持降级，可以借助比如Hystrix来实现服务的熔断、降级、限流来降低出现雪崩时的故障程度。
    2.缓存穿透(Cache Penetration)问题
        缓存穿透定义:
            请求过来了,转了一圈,一无所获,就像穿过透明地带一样。在高并发系统中缓存穿透，如果一个req需要请求的数据在缓存中没有，这时业务线程就会访问磁盘数据库系统，然而磁盘数据库也没有这个数据，无奈业务线程只能白白处理一圈。如果某时段有大量恶意的不存在的key的集中请求，那么服务将一直处理这些根本不存在的请求，导致正常请求无法被处理，从而出现问题。
        缓存穿透解决方案(有效甄别是否存在这个key再决定是否读取很重要)常见的做法有：
            1.把不存在的key写一下null，这样再来就相当于命中了，其实这种方法局限性很大，今天是5斤龙虾，明天改成6斤的螃蟹，缓存系统和数据库中存储大量无用key本身是无意义的.(所以一般不建议)
            2.转换为查找问题，类似于在海量数据中查找某个key是否存在，考虑空间复杂度和时间复杂度，一般选用布隆过滤器来实现。(布隆过滤器是个好东西，有非常多的用途，包括：垃圾邮件识别、搜索蜘蛛爬虫url去重等，主要借助K个哈希函数和一个超大的bit数组来降低哈希冲突本身带来的误判，从而提高识别准确性。)
        注:布隆过滤器也存在一定的误判，假如判断存在可能不一定存在，但是假如判断不存在就一定不存在，因此刚好用在解决缓存穿透的key查找场景，事实上很多系统都是基于布隆过滤器来解决缓存穿透问题的。
        布隆过滤器
            概念:
                可以理解为一个不怎么精确的set结构，当你使用它的 contains 方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。
                当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。打个比方，当它说不认识你时，肯定就不认识；当它说见过你时，可能根本就没见过面，不过因为你的脸跟它认识的人中某脸比较相似 (某些熟脸的系数组合)，所以误判以前见过你。
                套在上面的使用场景中，布隆过滤器能准确过滤掉那些已经看过的内容，那些没有看过的新内容，它也会过滤掉极小一部分 (误判)，但是绝大多数新内容它都能准确识别。这样就可以完全保证推荐给用户的内容都是无重复的。
            Redis中的使用
            　　Redis 官方提供的布隆过滤器到了 Redis 4.0 提供了插件功能之后才正式登场。布隆过滤器作为一个插件加载到 Redis Server 中，给 Redis 提供了强大的布隆去重功能。
                布隆过滤器有二个基本指令，bf.add 添加元素，bf.exists 查询元素是否存在，它的用法和 set 集合的 sadd 和 sismember 差不多。注意 bf.add 只能一次添加一个元素，如果想要一次添加多个，就需要用到 bf.madd 指令。同样如果需要一次查询多个元素是否存在，就需要用到 bf.mexists 指令。
            　　Redis 其实还提供了自定义参数的布隆过滤器，需要我们在 add 之前使用bf.reserve指令显式创建。如果对应的 key 已经存在，bf.reserve会报错。bf.reserve有三个参数，分别是 key, error_rate和initial_size。错误率越低，需要的空间越大。initial_size参数表示预计放入的元素数量，当实际数量超出这个数值时，误判率会上升。
                所以需要提前设置一个较大的数值避免超出导致误判率升高。如果不使用 bf.reserve，默认的error_rate是 0.01，默认的initial_size是 100。
            注意事项:
                布隆过滤器的initial_size估计的过大，会浪费存储空间，估计的过小，就会影响准确率，用户在使用之前一定要尽可能地精确估计好元素数量，还需要加上一定的冗余空间以避免实际元素可能会意外高出估计值很多。
            布隆过滤器的error_rate越小，需要的存储空间就越大，对于不需要过于精确的场合，error_rate设置稍大一点也无伤大雅。比如在新闻去重上而言，误判率高一点只会让小部分文章不能让合适的人看到，文章的整体阅读量不会因为这点误判率就带来巨大的改变。
            原理:
                每个布隆过滤器对应到 Redis 的数据结构里面就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。
                向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就完成了 add 操作。
                向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个 key 不存在。如果都是 1，这并不能说明这个 key 就一定存在，只是极有可能存在，因为这些位被置为 1 可能是因为其它的 key 存在所致。如果这个位数组比较稀疏，判断正确的概率就会很大，如果这个位数组比较拥挤，判断正确的概率就会降低。具体的概率计算公式比较复杂，感兴趣可以阅读扩展阅读，非常烧脑，不建议读者细看。
                使用时不要让实际元素远大于初始化大小，当实际元素开始超出初始化大小时，应该对布隆过滤器进行重建，重新分配一个 size 更大的过滤器，再将所有的历史元素批量 add 进去 (这就要求我们在其它的存储器中记录所有的历史元素)。因为 error_rate 不会因为数量超出就急剧增加，这就给我们重建过滤器提供了较为宽松的时间。
            其它应用:
                在爬虫系统中，我们需要对 URL 进行去重，已经爬过的网页就可以不用爬了。但是 URL 太多了，几千万几个亿，如果用一个集合装下这些 URL 地址那是非常浪费空间的。这时候就可以考虑使用布隆过滤器。它可以大幅降低去重存储消耗，只不过也会使得爬虫系统错过少量的页面。
                布隆过滤器在 NoSQL 数据库领域使用非常广泛，我们平时用到的 HBase、Cassandra 还有 LevelDB、RocksDB 内部都有布隆过滤器结构，布隆过滤器可以显著降低数据库的 IO 请求数量。当用户来查询某个 row 时，可以先通过内存中的布隆过滤器过滤掉大量不存在的 row 请求，然后再去磁盘进行查询。
                邮箱系统的垃圾邮件过滤功能也普遍用到了布隆过滤器，因为用了这个过滤器，所以平时也会遇到某些正常的邮件被放进了垃圾邮件目录中，这个就是误判所致，概率很低。
    3.缓存击穿(Hotspot Invalid)问题
        缓存击穿定义:
            由于缓存系统中的热点数据都有过期时间，如果没有过期时间就造成了主存和缓存的数据不一致，因此过期时间一般都不会太长。
    设想某时刻一批热点数据同时在缓存系统中过期失效，那么这部分数据就都将请求磁盘数据库系统。有点像微小规模的雪崩，但是对数据库的压力就很小了，只不过会影响并发性能，然而在多线程场景中缓存击穿却是经常发生的，相反缓存穿透和雪崩频率不如缓存击穿，因此研究击穿的现实意义更大一些。
        缓存击穿解决方案:
            1.在设置热点数据过期时间时尽量分散，比如设置100ms的基础值，在此基础上正负浮动10ms，从而降低相同时刻出现CacheMiss的key的数量。
            2.另外一种做法是多线程加锁，其中第一个线程发现CacheMiss之后进行加锁，再从数据库获取内容之后写到缓存中，其他线程获取锁失败则阻塞数ms之后再进行缓存读取，这样可以降低访问数据数据库的线程数，需要注意在单机和集群需要使用不同的锁，集群环境使用分布式锁来实现，但是由于锁的存在也会影响并发效率。一种方法是在业务层对使用的热点数据查看是否即将过期，如果即将过期则去数据库获取最新数据进行更新并延长该热点key在缓存系统中的时间，从而避免后面的过期CacheMiss，相当于把事情提前解决了。
    注:
        缓存击穿的解决方法都有一定的权衡，实际中根据自己的需求来解决。缓存击穿的影响一般来说并不会太大，或许在你的服务跑了很久之后你才意识到会有缓存击穿问题。
        不要一味追求缓存命中率，缓存和主数据库的数据一致性是需要重点考虑的。总起来说，如何在保证数据正确性的前提下提高缓存命中率就是核心问题。
        
(一文把Redis主从复制、哨兵、Cluster三种模式摸透)
    以下文章来源于非科班的科班 ，作者黎杜
    
    Redis作为缓存的高效中间件，在我们日常的开发中被频繁的使用，今天就来说一说Redis的四种模式，分别是「单机版、主从复制、哨兵、以及集群模式」。
    可能，在一般公司的程序员使用单机版基本都能解决问题，在Redis的官网给出的数据是10W QPS，这对于应付一般的公司绰绰有余了，再不行就来个主从模式，实现读写分离，性能又大大提高。
    之前对于Redis方面也是写了比较多的文章，如：「Redis的基本数据类型和底层的实现原理、事务、持久化、分布式锁、订阅预发布」等，可以说是比较全面的教程了，这篇讲完基本就全了，我会把文章系统的整理成pdf，分享给大家。
    单机
        单机版的Redis就比较简单了，基本90%的程序员都是用过，官网推荐操作Redis的第三方依赖库是Jedis，在SpringBoot项目中，引入下面依赖就可以直接使用了：
            <dependency>
                <groupId>redis.clients</groupId>
                <artifactId>jedis</artifactId>
                <version>${jedis.version}</version>
            </dependency>
        优点
            单机版的Redis也有很多优点，比如实现实现简单、维护简单、部署简单、维护成本非常低，不需要其它额外的开支。
        缺点
            但是，因为是单机版的Redis所以也存在很多的问题，比如最明显的单点故障问题，一个Redis挂了，所有的请求就会直接打在了DB上。
            并且一个Redis抗并发数量也是有限的，同时要兼顾读写两种请求，只要访问量一上来，Redis就受不了了，另一方面单机版的Redis数据量存储也是有限的，数据量一大，再重启Redis的时候，就会非常的慢，所以局限性也是比较大的。
        实操搭建
            单机版的搭建教程，在网上有非常多的全面的教程，基本就是傻瓜式操作，特别是在本地搭建的话，基本使用yum快捷方便，几句命令就搞定了，这里推荐一个搭建教程：https://www.cnblogs.com/zuidongfeng/p/8032505.html。
            上面这个教程讲的非常的详细，环境的搭建本来是运维的工作，但是作为程序员尝试自己去搭建环境还是有必要的，而且搭建环境这种东西，基本就是一劳永逸，搭建一次，可能下次换电脑或者重装虚拟机才会再次搭建。
        常用的redis.conf的配置：
            daemonize yes  // 设置后台启动，一般设置yes
            pidfile /var/run/redis.pid // edis以守护进程方式运行时,redis默认会把pid写入/var/run/redis.pid文件
            port 6379 // 默认端口为6379
            bind 127.0.0.1 //主机地址，设置0.0.0.0表示都可以访问。127.0.0.1表示只允许本机访问
            timeout 900  // 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能
            logfile stdout // 日志记录方式，默认为标准输出
            logfile "./redis7001.log"  # 指明日志文件名
            databases 16 // 设置数据库的数量，默认数据库为0
            save  //有多少次更新操作，就将数据同步到数据文件
            Redis默认配置文件中提供了三个条件：
            save 900 1 //900秒（15分钟）内有1个更改
            save 300 10 //300秒（5分钟）内有10个更改
            save 60 10000  // 60秒内有10000个更改
            rdbcompression yes // 指定存储至本地数据库时是否压缩数据
            dbfilename dump.rdb //指定本地数据库文件名
            dir ./    //指定本地数据库存放目录
            slaveof  // 主从同步设置，设置主数据库的ip和端口
            # 如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACK
            tcp-keepalive 60
            # 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作
            # 这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难
            stop-writes-on-bgsave-error yes
            # 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作。
            stop-writes-on-bgsave-error yes
            # 当导出到 .rdb 数据库时是否用LZF压缩字符串对象
            rdbcompression yes
            # 版本5的RDB有一个CRC64算法的校验和放在了文件的最后。这将使文件格式更加可靠。
            rdbchecksum yes
            # 持久化数据库的文件名
            dbfilename dump-master.rdb
            # 工作目录
            dir /usr/local/redis-4.0.8/redis_master/
            # slav服务连接master的密码
            masterauth testmaster123
            # 当一个slave失去和master的连接，或者同步正在进行中，slave的行为可以有两种：
            #1) 如果 slave-serve-stale-data 设置为 "yes" (默认值)，slave会继续响应客户端请求，可能是正常数据，或者是过时了的数据，也可能是还没获得值的空数据。
            # 2) 如果 slave-serve-stale-data 设置为 "no"，slave会回复"正在从master同步
            # （SYNC with master in progress）"来处理各种请求，除了 INFO 和 SLAVEOF 命令。
            slave-serve-stale-data yes
            # 配置是否仅读
            slave-read-only yes
            # 如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒
            # 如果你选择了 "no" 数据传输到salve的延迟将会减少但要使用更多的带宽
            repl-disable-tcp-nodelay no
            # slave的优先级，优先级数字小的salve会优先考虑提升为master
            slave-priority 100
            # 密码验证
            requirepass testmaster123
            # redis实例最大占用内存，一旦内存使用达到上限，Redis会根据选定的回收策略（参见：
            # maxmemmory-policy）删除key
            maxmemory 3gb
            # 最大内存策略：如果达到内存限制了，Redis如何选择删除key。
            # volatile-lru -> 根据LRU算法删除带有过期时间的key。
            # allkeys-lru -> 根据LRU算法删除任何key。
            # volatile-random -> 根据过期设置来随机删除key, 具备过期时间的key。 
            # allkeys->random -> 无差别随机删, 任何一个key。 
            # volatile-ttl -> 根据最近过期时间来删除（辅以TTL）, 这是对于有过期时间的key 
            # noeviction -> 谁也不删，直接在写操作时返回错误。
            maxmemory-policy volatile-lru
            # AOF开启
            appendonly no
            # aof文件名
            appendfilename "appendonly.aof"
            # fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。
            # 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。
            # Redis支持三种不同的模式：
            # no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。
            # always：每次写操作都立刻写入到aof文件。慢，但是最安全。
            # everysec：每秒写一次。折中方案。 
            appendfsync everysec
            # 如果AOF的同步策略设置成 "always" 或者 "everysec"，并且后台的存储进程（后台存储或写入AOF
            # 日志）会产生很多磁盘I/O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。
            # 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。
            # 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止主进程进行fsync()。
            # 这就意味着如果有子进程在进行保存操作，那么Redis就处于"不可同步"的状态。
            # 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定）
            # 如果你有延时问题把这个设置成"yes"，否则就保持"no"，这是保存持久数据的最安全的方式。
            no-appendfsync-on-rewrite yes
            # 自动重写AOF文件
            auto-aof-rewrite-percentage 100
            auto-aof-rewrite-min-size 64mb
            # AOF文件可能在尾部是不完整的（这跟system关闭有问题，尤其是mount ext4文件系统时
            # 没有加上data=ordered选项。只会发生在os死时，redis自己死不会不完整）。
            # 那redis重启时load进内存的时候就有问题了。
            # 发生的时候，可以选择redis启动报错，并且通知用户和写日志，或者load尽量多正常的数据。
            # 如果aof-load-truncated是yes，会自动发布一个log给客户端然后load（默认）。
            # 如果是no，用户必须手动redis-check-aof修复AOF文件才可以。
            # 注意，如果在读取的过程中，发现这个aof是损坏的，服务器也是会退出的，
            # 这个选项仅仅用于当服务器尝试读取更多的数据但又找不到相应的数据时。
            aof-load-truncated yes
            # Lua 脚本的最大执行时间，毫秒为单位
            lua-time-limit 5000
            # Redis慢查询日志可以记录超过指定时间的查询
            slowlog-log-slower-than 10000
            # 这个长度没有限制。只是要主要会消耗内存。你可以通过 SLOWLOG RESET 来回收内存。
            slowlog-max-len 128
            # 客户端的输出缓冲区的限制，可用于强制断开那些因为某种原因从服务器读取数据的速度不够快的客户端
            client-output-buffer-limit normal 0 0 0
            client-output-buffer-limit slave 256mb 64mb 60
            client-output-buffer-limit pubsub 32mb 8mb 60
            # 当一个子进程重写AOF文件时，文件每生成32M数据会被同步
            aof-rewrite-incremental-fsync yes
    由于，单机版的Redis在并发量比较大的时候，并且需要较高性能和可靠性的时候，单机版基本就不适合了，于是就出现了「主从模式」。
    
    主从模式原理:主从的原理还算是比较简单的，一主多从，「主数据库（master）可以读也可以写（read/write），从数据库仅读（only read）」。但是，主从模式一般实现「读写分离」，「主数据库仅写（only write）」，减轻主数据库的压力：
        当开启主从模式的时候，他的具体工作机制如下：
            1.当slave启动后会向master发送SYNC命令，master节点收到从数据库的命令后通过bgsave保存快照（「RDB持久化」），并且期间的执行的些命令会被缓存起来。
            2.然后master会将保存的快照发送给slave，并且继续缓存期间的写命令。
            3.slave收到主数据库发送过来的快照就会加载到自己的数据库中。
            4.最后master讲缓存的命令同步给slave，slave收到命令后执行一遍，这样master与slave数据就保持一致了。
        优点
            1.之所以运用主从，是因为主从一定程度上解决了单机版并发量大，导致请求延迟或者redis宕机服务停止的问题。
            2.从数据库分担主数据库的读压力，若是主数据库是只写模式，那么实现读写分离，主数据库就没有了读压力了。
            3.另一方面解决了单机版单点故障的问题，若是主数据库挂了，那么从数据库可以随时顶上来，综上来说，主从模式一定程度上提高了系统的可用性和性能，是实现哨兵和集群的基础。
            4.主从同步以异步方式进行同步，期间Redis仍然可以响应客户端提交的查询和更新的请求。
        缺点
            1.主从模式好是好，他也有自己的缺点，比如数据的一致性问题，假如主数据库写操作完成，那么他的数据会被复制到从数据库，若是还没有即使复制到从数据库，读请求又来了，此时读取的数据就不是最新的数据。
            2.若是从主同步的过程网络出故障了，导致主从同步失败，也会出现问题数据一致性的问题。
            3.主从模式不具备自动容错和恢复的功能，一旦主数据库，从节点晋升为主数据库的过程需要人为操作，维护的成本就会升高，并且主节点的写能力、存储能力都会受到限制。
    实操搭建
        下面的我们来实操搭建一下主从模式，主从模式的搭建还是比较简单的，我这里一台centos 7虚拟机，使用开启redis多实例的方法搭建主从。redis中开启多实例的方法，首先创建一个文件夹，用于存放redis集群的配置文件：
            mkdir redis
        然后粘贴复制redis.conf配置文件：
            cp /root/redis-4.0.6/redis.conf /root/redis/redis-6379.conf
            cp /root/redis-4.0.6/redis.conf /root/redis/redis-6380.conf
            cp /root/redis-4.0.6/redis.conf /root/redis/redis-6381.conf
        复制三份配置文件，一主两从，6379端口作为主数据库（master），6380、6381作为从数据库（slave）。
        首先是配置主数据库的配置文件：vi redis-6379.conf：
            bind 0.0.0.0 # 注释掉或配置成0.0.0.0表示任意IP均可访问。
            protected-mode no # 关闭保护模式，使用密码访问。
            port 6379  # 设置端口，6380、6381依次为6380、6381。
            timeout 30 # 客户端连接空闲多久后断开连接，单位秒，0表示禁用
            daemonize yes # 在后台运行
            pidfile /var/run/redis_6379.pid  # pid进程文件名，6380、6381依次为redis_6380.pid、redis_6381.pid
            logfile /root/reids/log/6379.log # 日志文件，6380、6381依次为6380.log、6381.log
            save 900 1 # 900s内至少一次写操作则执行bgsave进行RDB持久化
            save 300 10
            save 60 10000 
            rdbcompression yes #是否对RDB文件进行压缩，建议设置为no，以（磁盘）空间换（CPU）时间
            dbfilename dump.rdb # RDB文件名称
            dir /root/redis/datas # RDB文件保存路径，AOF文件也保存在这里
            appendonly yes # 表示使用AOF增量持久化的方式
            appendfsync everysec # 可选值 always， everysec，no，建议设置为everysec
            requirepass 123456 # 设置密码
        然后，就是修改从数据库的配置文件，在从数据库的配置文件中加入以下的配置信息：
            slaveof 127.0.0.1 6379 # 配置master的ip，port
            masterauth 123456 # 配置访问master的密码
            slaveof-serve-stale-data no 
        接下来就是启动三个redis实例，启动的命令，先cd到redis的src目录下，然后执行：
            ./redis-server /root/redis/6379.conf
            ./redis-server /root/redis/6380.conf
            ./redis-server /root/redis/6381.conf
        通过命令ps -aux | grep redis，查看启动的redis进程：如上图所示，表示启动成功，下面就开始进入测试阶段。
    测试
        我这里使用SecureCRT作为redis连接的客户端，同时启动三个SecureCRT，分别连接redis1的三个实例，启动时指定端口以及密码：
            ./redis-cli -p 6379 -a 123456
        启动后，在master（6379），输入：set name 'ldc'，在slave中通过get name，可以查看
    注:
        数据同步成功，这有几个坑一个是redis.conf中没有设置对bind，会导致非本机的ip被过滤掉，一般配置0.0.0.0就可以了。
        另一个是没有配置密码requirepass 123456，会导致IO一直连接异常，这个是我遇到的坑，后面配置密码后就成功了。
        还有，就是查看redis的启动日志可以发现有两个warning，虽然不影响搭建主从同步，看着挺烦人的，但是有些人会遇到，有些人不会遇到。
    
    哨兵模式原理
        哨兵模式是主从的升级版，因为主从的出现故障后，不会自动恢复，需要人为干预，这就很蛋疼啊。
        在主从的基础上，实现哨兵模式就是为了监控主从的运行状况，对主从的健壮进行监控，就好像哨兵一样，只要有异常就发出警告，对异常状况进行处理。
        所以，总的概括来说，哨兵模式有以下的优点（功能点）：
            「监控」：监控master和slave是否正常运行，以及哨兵之间也会相互监控
            「自动故障恢复」：当master出现故障的时候，会自动选举一个slave作为master顶上去。
        哨兵模式的监控配置信息，是通过配置从数据库的sentinel monitor "master-name" "ip" "redis-port" "quorum" 来指定的，比如：
            mymaster 表示给master数据库定义了一个名字，后面的是master的ip和端口，1表示至少需要一个Sentinel进程同意才能将master判断为失效，如果不满足这个条件，则自动故障转移（failover）不会执行
            sentinel monitor mymaster 127.0.0.1 6379 1
    节点通信
    当然还有其它的配置信息，其它配置信息，在环境搭建的时候再说。当哨兵启动后，会与master建立一条连接，用于订阅master的_sentinel_:hello频道。
    该频道用于获取监控该master的其它哨兵的信息。并且还会建立一条定时向master发送INFO命令获取master信息的连接。
    「当哨兵与master建立连接后，定期会向（10秒一次）master和slave发送INFO命令，若是master被标记为主观下线，频率就会变为1秒一次。」
    并且，定期向_sentinel_:hello频道发送自己的信息，以便其它的哨兵能够订阅获取自己的信息，发送的内容包含「哨兵的ip和端口、运行id、配置版本、master名字、master的ip端口还有master的配置版本」等信息。
    以及，「定期的向master、slave和其它哨兵发送PING命令（每秒一次），以便检测对象是否存活」，若是对方接收到了PING命令，无故障情况下，会回复PONG命令。
    所以，哨兵通过建立这两条连接、通过定期发送INFO、PING命令来实现哨兵与哨兵、哨兵与master之间的通信。
    这里涉及到一些概念需要理解，INFO、PING、PONG等命令，后面还会有MEET、FAIL命令，以及主观下线，当然还会有客观下线，这里主要说一下这几个概念的理解：
    INFO：该命令可以获取主从数据库的最新信息，可以实现新结点的发现
    PING：该命令被使用最频繁，该命令封装了自身节点和其它节点的状态数据。
    PONG：当节点收到MEET和PING，会回复PONG命令，也把自己的状态发送给对方。
    MEET：该命令在新结点加入集群的时候，会向老节点发送该命令，表示自己是个新人
    FAIL：当节点下线，会向集群中广播该消息。
    上线和下线
    当哨兵与master相同之后就会定期一直保持联系，若是某一时刻哨兵发送的PING在指定时间内没有收到回复（sentinel down-after-milliseconds master-name milliseconds 配置），那么发送PING命令的哨兵就会认为该master「主观下线」（Subjectively Down）。
    因为有可能是哨兵与该master之间的网络问题造成的，而不是master本身的原因，所以哨兵同时会询问其它的哨兵是否也认为该master下线，若是认为该节点下线的哨兵达到一定的数量（「前面的quorum字段配置」），就会认为该节点「客观下线」（Objectively Down）。
    若是没有足够数量的sentinel同意该master下线，则该master客观下线的标识会被移除；若是master重新向哨兵的PING命令回复了客观下线的标识也会被移除。
    
    选举算法
        当master被认为客观下线后，又是怎么进行故障恢复的呢？原来哨兵中首先选举出一个老大哨兵来进行故障恢复，选举老大哨兵的算法叫做「Raft算法」：
            发现master下线的哨兵（sentinelA）会向其它的哨兵发送命令进行拉票，要求选择自己为哨兵大佬。
            若是目标哨兵没有选择其它的哨兵，就会选择该哨兵（sentinelA）为大佬。
            若是选择sentinelA的哨兵超过半数（半数原则），该大佬非sentinelA莫属。
            如果有多个哨兵同时竞选，并且可能存在票数一致的情况，就会等待下次的一个随机时间再次发起竞选请求，进行新的一轮投票，直到大佬被选出来。
            选出大佬哨兵后，大佬哨兵就会对故障进行自动回复，从slave中选出一名slave作为主数据库，选举的规则如下所示：
            所有的slave中slave-priority优先级最高的会被选中。
            若是优先级相同，会选择偏移量最大的，因为偏移量记录着数据的复制的增量，越大表示数据越完整。
            若是以上两者都相同，选择ID最小的。
            通过以上的层层筛选最终实现故障恢复，当选的slave晋升为master，其它的slave会向新的master复制数据，若是down掉的master重新上线，会被当作slave角色运行。
        优点
            哨兵模式是主从模式的升级版，所以在系统层面提高了系统的可用性和性能、稳定性。当master宕机的时候，能够自动进行故障恢复，需不要人为的干预。
            哨兵与哨兵之间、哨兵与master之间能够进行及时的监控，心跳检测，及时发现系统的问题，这都是弥补了主从的缺点。
        缺点
            哨兵一主多从的模式同样也会遇到写的瓶颈，已经存储瓶颈，若是master宕机了，故障恢复的时间比较长，写的业务就会受到影响。
            增加了哨兵也增加了系统的复杂度，需要同时维护哨兵模式。
    实操搭建
        最后，我们进行一下哨兵模式的搭建，配置哨兵模式还是比较简单的，在上面配置的主从模式的基础上，同时创建一个文件夹用于存放三个哨兵的配置文件：
            mkdir /root/redis-4.0.6/sentinel.conf  /root/redis/sentinel/sentinel1.conf 
            mkdir /root/redis-4.0.6/sentinel.conf  /root/redis/sentinel/sentinel2.conf 
            mkdir /root/redis-4.0.6/sentinel.conf  /root/redis/sentinel/sentinel3.conf 
        分别在这三个文件中添加如下配置：
            daemonize yes # 在后台运行
            sentinel monitor mymaster 127.0.0.1 6379 1 # 给master起一个名字mymaster，并且配置master的ip和端口
            sentinel auth-pass mymaster 123456 # master的密码
            port 26379 #另外两个配置36379,46379端口
            sentinel down-after-milliseconds mymaster 3000 # 3s未回复PING就认为master主观下线
            sentinel parallel-syncs mymaster 2  # 执行故障转移时，最多可以有2个slave实例在同步新的master实例
            sentinel failover-timeout mymaster 100000 # 如果在10s内未能完成故障转移操作认为故障转移失败
        配置完后分别启动三台哨兵：
            ./redis-server sentinel1.conf --sentinel
            ./redis-server sentinel2.conf --sentinel
            ./redis-server sentinel3.conf --sentinel
        然后通过：ps -aux|grep redis进行查看：可以看到三台redis实例以及三个哨兵都已经正常启动，现登陆6379，通过INFO Repliaction查看master信息：
        当前master为6379，然后我们来测试一下哨兵的自动故障恢复，直接kill掉6379进程，然后通过登陆6380再次查看master的信息：
        可以看到当前的6380角色是master，并且6380可读可写，而不是只读模式，这说明我们的哨兵是起作用了，搭建成功，感兴趣的可以自行搭建，也有可能你会踩一堆的坑。
        
    Cluster模式
        最后，Cluster是真正的集群模式了，哨兵解决和主从不能自动故障恢复的问题，但是同时也存在难以扩容以及单机存储、读写能力受限的问题，并且集群之前都是一台redis都是全量的数据，这样所有的redis都冗余一份，就会大大消耗内存空间。
        集群模式实现了Redis数据的分布式存储，实现数据的分片，每个redis节点存储不同的内容，并且解决了在线的节点收缩（下线）和扩容（上线）问题。
        集群模式真正意义上实现了系统的高可用和高性能，但是集群同时进一步使系统变得越来越复杂，接下来我们来详细的了解集群的运作原理。
        数据分区原理
            集群的原理图还是很好理解的，在Redis集群中采用的是虚拟槽分区算法，会把redis集群分成16384 个槽（0 -16383）。
            比如：下图所示三个master，会把0 -16383范围的槽可能分成三部分（0-5000）、（5001-11000）、（11001-16383）分别数据三个缓存节点的槽范围。
            当客户端请求过来，会首先通过对key进行CRC16 校验并对 16384 取模（CRC16(key)%16383）计算出key所在的槽，然后再到对应的槽上进行取数据或者存数据，这样就实现了数据的访问更新。
            之所以进行分槽存储，是将一整堆的数据进行分片，防止单台的redis数据量过大，影响性能的问题。
        节点通信
            节点之间实现了将数据进行分片存储，那么节点之间又是怎么通信的呢？这个和前面哨兵模式讲的命令基本一样。
            首先新上线的节点，会通过 Gossip 协议向老成员发送Meet消息，表示自己是新加入的成员。
            老成员收到Meet消息后，在没有故障的情况下会恢复PONG消息，表示欢迎新结点的加入，除了第一次发送Meet消息后，之后都会发送定期PING消息，实现节点之间的通信。
            通信的过程中会为每一个通信的节点开通一条tcp通道，之后就是定时任务，不断的向其它节点发送PING消息，这样做的目的就是为了了解节点之间的元数据存储情况，以及健康状况，以便即使发现问题。
        数据请求
            上面说到了槽信息，在Redis的底层维护了unsigned char myslots[CLUSTER_SLOTS/8] 一个数组存放每个节点的槽信息。
            因为他是一个二进制数组，只有存储0和1值，如下图所示：
            这样数组只表示自己是否存储对应的槽数据，若是1表示存在该数据，0表示不存在该数据，这样查询的效率就会非常的高，类似于布隆过滤器，二进制存储。
            比如：集群节点1负责存储0-5000的槽数据，但是此时只有0、1、2存储有数据，其它的槽还没有存数据，所以0、1、2对应的值为1。
            并且，每个redis底层还维护了一个clusterNode数组，大小也是16384，用于储存负责对应槽的节点的ip、端口等信息，这样每一个节点就维护了其它节点的元数据信息，便于及时的找到对应的节点。
            当新结点加入或者节点收缩，通过PING命令通信，及时的更新自己clusterNode数组中的元数据信息，这样有请求过来也就能及时的找到对应的节点。
            有两种其它的情况就是，若是请求过来发现，数据发生了迁移，比如新节点加入，会使旧的缓存节点数据迁移到新结点。
            请求过来发现旧节点已经发生了数据迁移并且数据被迁移到新结点，由于每个节点都有clusterNode信息，通过该信息的ip和端口。此时旧节点就会向客户端发一个MOVED 的重定向请求，表示数据已经迁移到新结点上，你要访问这个新结点的ip和端口就能拿到数据，这样就能重新获取到数据。
            倘若正在发正数据迁移呢？旧节点就会向客户端发送一个ASK 重定向请求，并返回给客户端迁移的目标节点的ip和端口，这样也能获取到数据。
        扩容和收缩
            扩容和收缩也就是节点的上线和下线，可能节点发生故障了，故障自动回复的过程（节点收缩）。
            节点的收缩和扩容时，会重新计算每一个节点负责的槽范围，并发根据虚拟槽算法，将对应的数据更新到对应的节点。
            还有前面的讲的新加入的节点会首先发送Meet消息，详细可以查看前面讲的内容，基本一样的模式。
            以及发生故障后，哨兵老大节点的选举，master节点的重新选举，slave怎样晋升为master节点，可以查看前面哨兵模式选举过程。
        优点
            集群模式是一个无中心的架构模式，将数据进行分片，分布到对应的槽中，每个节点存储不同的数据内容，通过路由能够找到对应的节点负责存储的槽，能够实现高效率的查询。
            并且集群模式增加了横向和纵向的扩展能力，实现节点加入和收缩，集群模式是哨兵的升级版，哨兵的优点集群都有。
        缺点
            缓存的最大问题就是带来数据一致性问题，在平衡数据一致性的问题时，兼顾性能与业务要求，大多数都是以最终一致性的方案进行解决，而不是强一致性。
            并且集群模式带来节点数量的剧增，一个集群模式最少要6台机，因为要满足半数原则的选举方式，所以也带来了架构的复杂性。
            slave只充当冷备，并不能缓解master的读的压力。
        实操搭建
            集群模式的部署比较简单，只要在redis.conf加入下面的配置信息即可：
                port 6379# 本示例6个节点端口分别为6379、6380、6381、6382、6383、6384
                daemonize yes # r后台运行 
                pidfile /var/run/redis_6379.pid # 分别对应6379、6380、6381、6382、6383、6384
                cluster-enabled yes # 开启集群模式 
                masterauth 123456# 如果设置了密码，需要指定master密码
                cluster-config-file nodes_6379.conf # 集群的配置文件，同样对应6379、6380、6381、6382、6383、6384六个节点
                cluster-node-timeout 10000 # 请求超时时间
            同时开启这六个实例，通过下面的命令将这六个实例以集群的方式运行
                ./redis-cli --cluster create --cluster-replicas 1 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381  127.0.0.1:6382  127.0.0.1:6383  127.0.0.1:6384  -a 123456
            这样就实现了集群的搭建。
</pre>