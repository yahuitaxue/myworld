---
title: GoLang长期学习路线
author: Yahui
layout: go
category: Go
---

书名:《-》

<pre style="text-align: left;">
go可以做的事情:
	1.服务端开发：以前你使用C或者C++做的那些事情，用Go来做很合适，例如日志处理、文件系统、监控系统等;
	2.DevOps：运维生态中的Docker、K8s、prometheus、grafana、open-falcon等都是使用Go语言开发;
	3.网络编程：大量优秀的Web框架如Echo、Gin、Iris、beego等，而且Go内置的 net/http包十分的优秀;
	4.Paas云平台领域：Kubernetes和Docker Swarm等;
	5.分布式存储领域：etcd、Groupcache、TiDB、Cockroachdb、Influxdb等;
	6.区块链领域：区块链里面有两个明星项目以太坊和fabric都使用Go语言;
	7.容器虚拟化：大名鼎鼎的Docker就是使用Go语言实现的;
	8.爬虫及大数据：Go语言天生支持并发，所以十分适合编写分布式爬虫及大数据处理。
总结
	Go开发核心：深入理解计算机原理、计算机网络协议以及主流协议、数据结构与算法、Linux、MySql、Redis、MQ、RPC、微服务、k8s、docker、架构认识、分布式落地
1.初级
	1.计算机基础(必会)
		1.冯诺伊曼体系(必会)
			1.用二进制进行计算和存储
				高电平低电平主要应用于数字电路。体现在电路上就是只有‘有’和‘无’，没有中间值，这个有在不同电路上的电压值不相同。
			2.基本结构
				输入设备(键盘，鼠标，摄像头，网卡和硬盘等)，输出设备(键盘，鼠标，摄像头，网卡和硬盘等)，存储器(内存)，控制器，运算器。
			3.CPU
				指令由控制单元分配到逻辑单元，经过加工处理之后，再送到存储单元里等待应用程序的使用。
			4.存储器
			5.总线
				CPU从内存中读取数据,就是根据地址总线里的地址传输
				地址总线有几根,就说明可用地址最大范围是多少(比如有8根,那么就只能使用256K的内存,也就是每次操作只能读取一个字节,所以如果想要每次操作4字节,就需要增加地址总线到32根)
			6.输入设备
			7.输出设备
			内存:
				一根内存条是一个rank
				一个rank上的黑色方块(比如是8个)就是一个chip
				一个chip中是8个bank(每个bank就可以通过二维坐标定位地址,那么每个chip读取一位组成8位,就是一个字节的地址,这样可以提高访问效率,但是缺点是读取只能是8的倍数)
				结构体的内存对其,则是根据其中元素最长的长度,例如:
					type A struct {
						a int8 // 对应1个字节
						b int64 // 对应8个字节
						c int32 // 对应4个字节
						d int16 // 对应2个字节
					} // 最长是8个字节,所以对其长度是8
					比如结构体的地址从Xa0000001111开始,相对位置向后对其
					a:1个字节,占用Xa0000001111 + 1 (第一个8位对其仅用了1位,就是相对位置取余为0----0%1=0)
					b:8个字节,占用Xa0000001111 + 8 * 1 (第二个8位占满,就是相对位置取余为0----8%8=0)
					c:占用4个字节,占用Xa0000001111 + 8 * 2 + 4 (第三个8位占了前4位,就是相对位置取余为0----8%8=0)
					d:占用2个字节,占用Xa0000001111 + 8 * 2 + 4 + 2 (第三个8位占了5~6位,就是相对位置取余为0----8%8=0)
			字符
				字符集+编码
					(Unicode是一个字符集的标准，而UTF-8是一种字符编码方案，用于将Unicode字符编码成可存储和传输的字节序列。)
					1. 字符集是一组字符的集合。常见的字符集有ASCII、Unicode、UTF-8等。 
					2. 编码是将字符集中的字符映射为二进制数据的过程。常见的编码有ASCII编码、UTF-8编码等。
					3. 字符集和编码的关系是，字符集包含了一组字符，而编码将字符集中的字符映射为二进制数据。编码是字符集在计算机中的表示方式。不同的编码方式对应着不同的字符集。例如，ASCII编码只能表示128个字符，而Unicode编码可以表示几乎所有的字符。UTF-8编码是对Unicode编码的压缩和优化，使用变长的字节表示字符，能够节省存储空间。
				1个字节(8位)表示数字+字母+标点等(其中格式为0-------)
				2个字节(16位)存储文字(其中格式为110----- 10------)
				3个字节(24位)存储汉子(其中格式为1110---- 10------ 10------), 这也就是为什么说utf-8中中文是由3个字节存储的
		2.计算机网络(必会)
			1.网络协议
				1.物理层:
					解决硬件之间怎么通信的问题,常见的物理媒介有电缆、光纤、无线电波等,实现了相邻计算机节点之间比特流的透明传送,并尽可能地屏蔽掉具体传输介质和物理设备的差异,使其上层(数据链路层)不必关心网络的具体传输介质。
				2.数据链路层:
					接收来自物理层的位流形式的数据,并封装成帧,传送到上一层；同样,也将来自上层的数据帧,拆装为位流形式的数据转发到物理层。由于各种干扰的存在,物理链路是不可靠的,这一层在物理层提供的比特流的基础上通过差错控制、流量控制方法,使有差错的物理线路变为无差错的数据链路,即提供可靠的通过物理介质传输数据的方法。
				3.网络层:IP/ICMP/IGMP
					将网络地址翻译成对应的物理地址,通过路由选择算法,为报文（该层的数据单位,由上一层数据打包而来）通过通信子网选择最适当的路径。这一层定义的是IP地址,通过IP地址寻址,所以产生了IP协议。
				4.传输层:TCP/UDP
					当发送大量数据时，很可能会出现丢包的情况，另一台电脑要告诉是否完整接收到全部的包。如果缺了，就告诉丢了哪些包，然后再发一次，直至全部接收为止。
					简单来说，传输层的主要功能就是：监控数据传输服务的质量，保证报文的正确传输
				5.会话层:
					建立和管理应用程序之间的通信,用户应用程序和网络之间的接口,建立通信链接,保持会话过程通信链接的畅通,同步两个节点之间的对话,决定通信是否被中断以及通信中断时决定从何处重新发送。
				6.表示层:
					不同系统之间的通信语法问题(比如windows与Linux通信),数据的编码,压缩和解压缩,数据的加密和解密,对来自应用层的命令和数据进行解释,以确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。
				7.应用层:HTTP/HTTPS/FTP/SSH/SMTP/TELNET
					负责完成网络中应用程序与网络操作系统之间的联系,建立与结束使用者之间的联系,并完成网络用户提出的各种网络服务及应用所需的监督、管理和服务等各种协议。此外,该层还负责协调各个应用程序间的工作
				<span class="image featured"><img src="{{ 'assets/images/other/osi_netmodel.png' | relative_url }}" alt="" /></span>
			2.序列化协议(主要及时解决对象传输的问题,将客户端的对象转化传输给服务端)
				文本类序列化方式,虽然可读性比较好,但是性能较差,一般不会选择
					XML
					JSON
				二进制序列化,跨语言,多语言支持.序列化反序列化效率高,文件体积小,比json小一倍.兼容json数据格式.
					MessagePack
						import "github.com/vmihailenco/msgpack/v5"
						func main() {
						    b, err := msgpack.Marshal(&Item{Foo: "bar"})
						    if err != nil {
						        panic(err)
						    }

						    var item Item
						    err = msgpack.Unmarshal(b, &item)
						    if err != nil {
						        panic(err)
						    }
						    fmt.Println(item.Foo)
						    // Output: bar
						}
				(选择因素:序列化后的数据大小,序列化效率,是否跨语言跨平台)
			3.七层体系结构
			4.四层体系结构
			5.拓展
				1.集线器(半双工,同时仅能支持一个通信,现在被舍弃)
				2.交换机(全双工,支持多条通信)
					根据数据头部信息的mac地址,记录每个端口对应的mac地址
					举例:
						(两个交换机相连多台电脑,另外一台电脑存有类似数据)
						aa-aa-aa-aa-aa-aa 1端口
						bb-bb-bb-bb-bb-bb 2端口
						cc-cc-cc-cc-cc-cc 3端口
						dd-dd-dd-dd-dd-dd 4端口
						ee-ee-ee-ee-ee-ee 5端口
						ff-ff-ff-ff-ff-ff 6端口(表示连接的是另外一台交换机)
						gg-gg-gg-gg-gg-gg 6端口(表示连接的是另外一台交换机)
						hh-hh-hh-hh-hh-hh 6端口(表示连接的是另外一台交换机)
				3.路由器(因为交换机的mac表大小有限,如果过多导致查找不到mac对应端口从而对所有的机器进行广播)
					每个交换机会有不同的IP地址与mac地址
		3.操作系统(必会)
			1.进程、线程、协程的区别
				进程
					进程是程序一次动态执行的过程，是程序运行的基本单位。
					每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。
					进程占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、页表、文件句柄等）比较大，但相对比较稳定安全。协程切换和协程切换
				线程
					线程又叫做轻量级进程，是CPU调度的最小单位。
					线程从属于进程，是程序的实际执行者。一个进程至少包含一个主线程，也可以有更多的子线程。
					多个线程共享所属进程的资源，同时线程也拥有自己的专属资源。
					程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。
				协程
					协程是一种用户态的轻量级线程，协程的调度完全由用户控制。
					一个线程可以拥有多个协程，协程不是被操作系统内核所管理，而完全是由程序所控制。
					与其让操作系统调度，不如我自己来，这就是协程
			2.进程间常用的通信方式
				进程间常用的通信
					1.管道（pipe）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有血缘关系的进程间使用。进程的血缘关系通常指父子进程关系。通过内核缓冲区实现数据传输
					2.有名管道（named pipe）：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间通信。有名管道以磁盘文件的方式存在，在系统中有对应的路径可以实现本机任意两个进程通信。管道的本质是内核维护了一块缓冲区与管道文件相关联，对管道文件的操作被内核转换成对这块缓冲区内存的操作。
					3.信号量（semophore）：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它通常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
					4.消息队列（message queue）：消息队列是由消息组成的链表，存放在内核中 并由消息队列标识符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
					5.信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某一事件已经发生。
					6.共享内存（shared memory）：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，共享内存是最快的IPC方式，它是针对其他进程间的通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量配合使用，来实现进程间的同步和通信。
					7.套接字（socket）：套接口也是一种进程间的通信机制，与其他通信机制不同的是它可以用于不同及其间的进程通信。
				线程间常用的通信
					1.互斥量 (锁) 只有拥有互斥量的线程才能执行任务
					2.信号量 (PV)  信号量是一个计数器
					3.事件 目事件机制，允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。
			3.5种网络IO模型
				同步IO
					阻塞 IO（blocking IO）
						默认情况下所有的 socket 都是 blocking
						当用户进程调用了 read 这个系统调用，kernel 就开始了 IO 的第一个阶段：准备数据。对于 network io 来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的数据包）这个时候 kernel 就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当 kernel 一直等到数据准备好了，它就会将数据从 kernel 中拷贝到用户内存，然后 kernel 返回结果，用户进程才解除 block 的状态，重新运行起来
					非阻塞 IO（non-blocking IO）
						当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error。从用户进程角度讲 ，它发起一个read 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 error时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call，那么它马上就将数据拷贝到了用户内存，然后返回，所以，在非阻塞式 IO 中，用户进程其实是需要不断的主动询问 kernel数据准备好了没有。
					多路复用 IO（IO multiplexing）
						select
							调用 select 会把所有要管理的 socket 的 fd (文件描述符，Linux下皆为文件，简单理解就是通过 fd 能找到这个 socket)传到内核中,遍历所有 socket，看看是否有感兴趣的事件发生。如果没有一个 socket 有事件发生，那么 select 的线程就需要让出 cpu 阻塞等待，这个等待可以是不设置超时时间的死等，也可以是设置 timeout 的有超时时间的等待。
							当 socket 接收到网卡的数据后，就会去它的睡眠队列里遍历 entry，调用 entry 设置的 callback 方法，这个 callback 方法里就能唤醒 select ！
							所以 select 在每个被它管理的 socket 的睡眠队列里都塞入一个与它相关的 entry，这样不论哪个 socket 来数据了，它立马就能被唤醒然后干活！
							但是，select 的实现不太好，因为唤醒的 select 此时只知道来活了，并不知道具体是哪个 socket 来数据了，所以只能傻傻地遍历所有 socket ，看看到底是哪个 scoket 来活了，然后把所有来活的 socket 封装成事件返回
							(因为被管理的 socket fd 需要从用户空间拷贝到内核空间，为了控制拷贝的大小而做了限制，即每个 select 能拷贝的 fds 集合大小只有1024)
						poll
							poll 这玩意相比于 select 主要就是优化了 fds 的结构，不再是 bit 数组了，而是一个叫 pollfd 的玩意，反正就是不用管啥 1024 的限制了。(现在也没人用 poll，就不多说了)
						epoll
							select存在的问题
								1.比如，为什么每次 select 需要把监控的 fds 传输到内核里？不能在内核里维护个？
								2.为什么 socket 只唤醒 select，不能告诉它是哪个 socket 来数据了？
								epoll 主要就是基于上面两点做了优化。
							过程
								1.搞了个叫 epoll_ctl 的方法，这方法就是用来管理维护 epoll 所监控的哪些 socket(这个 socket 集合是用红黑树实现的)
								2.然后和 select 类似，每个 socket 的睡眠队列里都会加个 entry，当每个 socket 来数据之后，同样也会调用 entry 对应的 callback。
								3.与 select 不同的是，引入了一个 ready_list 双向链表，callback 里面会把当前的 socket 加入到 ready_list 然后唤醒 epoll。
								4.这样被唤醒的 epoll 只需要遍历 ready_list 即可
					信号驱动 IO（signal driven I/O， SIGIO）
				异步IO
					用户进程发起 read 操作之后，立刻就可以开始去做其它的事。而另一方面，从 kernel的角度，当它收到一个 asynchronous read 之后，首先它会立刻返回，所以不会对用户进程产生任何 block。然后，kernel 会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel 会给用户进程发送一个 signal，告诉它 read 操作完成了
			4.并发与并行的区别
				并发：把任务在不同的时间点交给处理器进行处理。在同一时间点，任务并不会同时运行。
				并行：把每一个任务分配给每一个处理器独立完成。在同一时间点，任务是同时运行。
			5.同步与异步的区别
				同步：就是发出一个功能调用时，在没有得到结果之前，该调用就不返回或继续执行后续操作。这时程序是阻塞的，只有接收到返回的值或消息后才往下执行其他的命令。 因此 简单的说，同步就是必须一件一件事做，等前一件做完了才能做下一件事。
				异步：与同步相对，当一个异步过程调用发出后，调用者在没有得到结果之前，就可以继续执行后续操作。当这个调用完成后，一般通过状态、通知和回调来通知调用者。
			6.阻塞与非阻塞的区别
				阻塞：调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
				非阻塞：调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。
			7.常见缓存淘汰算法
				LFU(Least Frequently Used)：最近最不常用算法，根据数据的历史访问频率来淘汰数据。
					1.在缓存中查找客户端需要访问的数据
					2.如果缓存命中，则将访问的数据从队列中取出，并将数据对应的频率计数加1，然后将其放到频率相同的数据队列的头部，比如原来是A(10)->B(9)->C(9)->D(8),D被访问后，它的time变成了9，这时它被提到A和B之间，而不是继续在C后面
					3.如果没有命中，表示缓存穿透，将需要访问的数据从磁盘中取出，加入到缓存队列的尾部，记频率为1，这里也是加入到同为1的那一级的最前面
					4.如果此时缓存满了，则需要先置换出去一个数据，淘汰队列尾部频率最小的数据，然后再在队列尾部加入新数据。
					缺点
						某些数据短时间内被重复引用，并且在很长一段时间内不再被访问。由于它的访问频率计数急剧增加，即使它在相当长的一段时间内不会被再次使用，也不会在短时间内被淘汰。这使得其他可能更频繁使用的块更容易被清除，此外，刚进入缓存的新项可能很快就会再次被删除，因为它们的计数器较低，即使之后可能会频繁使用。
				LRU（Least Recently User） 最近最少使用算法,根据数据的历史访问记录来进行淘汰数据
					1.在缓存中查找客户端需要访问的数据 如果缓存命中，则将访问的数据中队列中取出，重新加入到缓存队列的头部。
					2.如果没有命中，表示缓存穿透，将需要访问的数据从磁盘中取出，加入到缓存队列的尾部；
					3.如果此时缓存满了，淘汰队列尾部的数据，然后再在队列头部加入新数据。
					缺点
						缓存污染：如果某个客户端访问大量历史数据时，可能使缓存中的数据被这些历史数据替换，其他客户端访问数据的命中率大大降低。
				FIFO（First in First out），先进先出算法,最先进入的数据,最先被淘汰。
					最近刚访问的，将来访问的可能性比较大 ,如果一个数据最先进入缓存中，则应该最早淘汰掉。
				2Q（Two queues）
					有两个缓存队列，一个是FIFO队列，一个是LRU队列。当数据第一次访问时，2Q算法将数据缓存在FIFO队列里面，当数据第二次被访问时，则将数据从FIFO队列移到LRU队列里面，两个队列各自按照自己的方法淘汰数据。
		4.数据结构与算法(必会)
			1.时间/空间复杂度
				一个算法所花费的时间与其中语句的执行次数成正比例，算法中的基本操作的执行次数，为算法的时间复杂度。
				空间复杂度是对一个算法在运行过程中临时占用存储空间大小的量度 。
			2.熟悉常用数据结构
				1.字符串
				2.数组
				3.链表
				4.队列
				5.二叉树
				6.栈
					1.过程
						1.下面的span不仅用作堆,栈也同样使用(区别是栈的span是mSpanInUse,堆是mSpanManual)
						2.<32KB的栈,会被分为2K,4K,8K,16K大小(后面是前面的两倍)的四种mspan链表数组
						3.>32KB的栈,会被分为8K,16K,32K,64K
						4.同样,栈中每个P也会有本地的缓存
					2.栈内存分配是发生在goroutine初始创建(初始栈大小都是2K,在分配的时候可能遇到不够用的情况,就涉及到了栈的增长与收缩),goroutine头部会有栈空间检测代码,检测栈空间是否够用;而对于栈收缩,是发生在GC阶段
					3.栈增长(是成倍增长的)
						需要时先把当前栈空间大小*2,并把协程状态改为Gcopystack(表示增长中),重新申请两倍大小的空间,然后将原来栈内数据复制到新空间中,释放旧空间数据,协程状态改为Grunning
					4.栈收缩
						1.正常协程运行结束,goroutine会被放到调度器对象的空闲队列(这里的空闲协程分两种,一种有协程栈,一种没有)
						2.创建协程的时候会优先使用有栈的协程
						(正常是判断该协程有无增长过,如果没有增长,则在运行结束放到由携程栈的队列中(栈长为2K),如果有增长过,则会释放掉栈空间,放到无协程栈的队列中)
						(有协程栈也会在GC阶段将栈空间释放,放到无协程栈队列中)
						3.释放也是根据栈空间大小来判断将释放空间放入到P本地栈缓存/全局栈缓存/堆内存中
							<32K->P本地栈缓存(如果P本地栈缓存队列栈空间总和大于32K,那么就会将一部分放到全局栈缓存,只留16K,如果本地栈缓存不能用,则直接全部放到全局栈缓存中(如果发现这个全局栈缓存的mspan所有的都被释放了,那么就会归还给堆内存))
							>32K->如果是在GC清理阶段则直接放入堆内存中,如果不是则放入全局栈缓存
				7.堆
					1.堆地址空间分为许多的64MB(amd64架构的Linux中)的arena
					2.每个arena包含8192个page(8K)(下文根据块的大小,会将page切割/组合成符合大小的块(也叫span))
					3.(使用Mcmalloc类似算法)每个page分成67种大小不一的块(8b~32K),每块都是大小一样的链表
					4.分配内存时,会根据申请的内存大小找到最匹配的规格,然后从链表中分配一个内存块
					5.有全局管理span的(mspan),如果都从arena中获取span就太消耗性能,所以每个P都有自己的本地span管理(mspan缓存),优先从本地获取
			3.熟悉常用算法
				1.双指针
				2.左右指针
				3.排序
				4.二叉查找
				5.递归
				6.回溯
				7.贪心
				8.动态规划
		5.数据库(必会)
			1.关系型数据库
				1.MariaDB
				2.Mysql(必会)
					1.自增主键不连续问题
						1.唯一索引冲突,导致数据没有插入成功,那么主键就会跳过此次插入继续增加
						2.事务回滚,与1类似
					2.排序(除了ASC/DESC还可以自定义排序)
				3.Oracle
			2.NoSQL
				1.Redis(必会)
					Redis的主从复制主要分为全量复制与增量复制
						1.全量复制主要在初始化的时候，主节点会向从节点发送快照文件，从节点收到快照文件加载数据完成全量复制
						2.增量复制主要在日常运行中，主节点数据变更，主节点维护offset复制偏移量来记录从节点复制情况
				2.MongoDB
				3.LevelDB
				4.Memcache
			3.cookie与session
				1.cookie是服务器将数据保存在客户端浏览器的一种机制,服务器将服务器的状态数据使用key/value的形式保存在客户端浏览器
				2.session针对每一个浏览器的请求都会存储数据,因为http是无状态协议,所以多次请求无法区分是否为同一用户,为了解决这个问题,session通过SESSIONID存储在客户端浏览器,客户端的每次请求都会带着这个SESSIONID,以标识是同一个用户的请求
		6.Internet(必会)
			1.互联网是如何工作的
				IP地址:标识设备和网络寻址
				IP协议将这个32位的地址分为两部分，前面部分代表网络地址，后面部分表示该主机在局域网中的地址。
				子网掩码是一个32位地址，用于屏蔽IP地址的一部分以区别网络标识和主机标识，并说明该IP地址是在局域网上，还是在广域网上。子网掩码不能单独存在，它必须结合IP地址一起使用。
				MAC地址也叫物理地址、硬件地址，由网络设备制造商生产时烧录在网卡(Network lnterface Card)的EPROM(一种闪存芯片，通常可以通过程序擦写)。IP地址与MAC地址在计算机里都是以二进制表示的，IP地址是32位的，而MAC地址则是48位的
			2.HTTP是什么
				HTTP使用TCP作为传输层协议，并采用请求-响应模型来进行通信。
				http1.1与http2.0区别http3
					1.http1.1使用停等协议,也就是虽然使用了TCP的长链接,减少了建立连接的过程,但是需要请求后等待响应才会进行下一次的请求
					2.http1.1文本协议,为了便于解析,文本中加入了特殊字符作为分隔符,造成数据冗余
					3.http1.1数据冗余还包括请求头信息,UA等都是短时间不会变动但是每次请求都会在头信息中包含
					4.http2.0使用二进制传输数据,采用多路复用,头部压缩
					5.http3使用QUIC协议基于UDP实现
			3.浏览器以及浏览器如何运作
				1. 解析URL：当用户在浏览器中输入URL时，浏览器会将这个URL解析成协议名、主机名、端口号、路径等信息。
				2. 建立连接：浏览器通过解析到的主机名和端口号建立与服务器的连接。
				3. 发送请求：浏览器向服务器发送HTTP请求，请求中包括请求方法、对应的资源路径、HTTP版本、请求头信息等。
				4. 接收响应：服务器接收到请求后，会返回对应的HTTP响应码和响应体。浏览器接收到响应后会根据响应码执行相应的操作。
				5. 渲染页面：如果响应是HTML页面，浏览器会根据HTML解析出DOM树，再根据CSS解析出CSSOM树，最后将两者进行合并形成Render Tree，然后进行页面渲染。用户交互和维护：当用户与页面进行交互时，浏览器会触发相应的事件，执行相关的JavaScript代码以更新页面内容。同时，浏览器会维护浏览历史、Cookie、缓存等信息以提高浏览器的使用体验。
			4.域名是什么
			5.hosting是什么
	2.Go编程基础(必会)
		1.开发环境(必会)
			1.go安装
				下载源码包安装
			2.go环境变量
				// 查看
				go env
				// 修改
				go env -w GOOS=windows
			3.go模块
				go mod init ⽣成 go.mod ⽂件
				go mod download 下载 go.mod ⽂件中指明的所有依赖
				go mod tidy 整理现有的依赖
				go mod graph 查看现有的依赖结构
				go mod edit 编辑 go.mod ⽂件
				go mod vendor 导出项⽬所有的依赖到vendor⽬录
				go mod verify 校验⼀个模块是否被篡改过
				go mod why 查看为什么需要依赖某模块
		2.基础(必会)
			1.字面量
			2.常量
			3.变量
			4.类型
			5.操作符
			6.表达式
			7.语句
			8.方法
				1.接口不能直接使用接收者为值类型的方法
				->解决方法,编译器会为值类型接收方法生成指针同名接收方法 (这也就是为什么值/指针方法不能同名)
				2.指针方法包含所有值类型方法
				->编译器会为所有接收者为值类型的生成同名指针类型的方法,链接器会把确定不会用到的指针方法删除掉
			9.错误处理
				1.经典 Go 逻辑
					// ZooTour struct
					type ZooTour interface {
					    Enter() error
					    VisitPanda(panda *Panda) error
					    Leave() error
					}

					// 分步处理，每个步骤可以针对具体返回结果进行处理
					func Tour(t ZooTour1, panda *Panda) error {
					    if err := t.Enter(); err != nil {
					        return errors.WithMessage(err, "Enter failed.")
					    }
					    if err := t.VisitPanda(); err != nil {
					        return errors.WithMessage(err, "VisitPanda failed.")
					    }
					    // ...

					    return nil
					}
				2.屏蔽过程中的 error 的处理
					type ZooTour interface {
					    Enter() error
					    VisitPanda(panda *Panda) error
					    Leave() error
					    Err() error
					}

					func Tour(t ZooTour, panda *Panda) error {

					    t.Enter()
					    t.VisitPanda(panda)
					    t.Leave()

					    // 集中编写业务逻辑代码,最后统一处理error
					    if err := t.Err(); err != nil {
					        return errors.WithMessage(err, "ZooTour failed")
					    }
					    return nil
					}
				3. 利用函数式编程延迟运行
					type Walker interface {
					    Next MyFunc
					}
					type SliceWalker struct {
					    index int
					    funs []MyFunc
					}

					func NewEnterFunc() MyFunc {
					    return func(t ZooTour) error {
					        return t.Enter()
					    }
					}

					func BreakOnError(t ZooTour, walker Walker) error {
					    for {
					        f := walker.Next()
					        if f == nil {
					            break
					        }
					        if err := f(t); err := nil {
					          // 遇到错误break或者continue继续执行
					      }
					    }
					}
				case 1: 如果业务逻辑不是很清楚，比较推荐
				case 2: 代码很少去改动，类似标准库，可以使用
				case 3: 比较复杂的场景，复杂到抽象成一种设计模式
		3.代码组织(必会)
			1.工作区
				1.go mod中replace使用
					1.vim go.mod
						module gin_demo
						go 1.20
						require (
							k8s.io/cloud-provider v0.0.0
							...
						)
						// 这里就是将包替换为本地的包
						replace (
							k8s.io/api = ./staging/src/k8s
							...
						)
				2.go work使用
					1.使用场景
						1.Go 1.18中的工作区可以让你同时处理多个模块，而不必为每个模块编辑go.mod文件。在解决依赖关系时，工作区中的每个模块都被视为根模块。
						2.以前，如果要在一个模块中增加一个功能，并在另一个模块中使用，你需要在第一个模块中发布修改，或者编辑依赖模块的go.mod文件，为你的本地未发布的模块变化添加replace指令。为了不出错地发布，你必须在向第一个模块发布本地修改后，从依赖模块的go.mod文件中删除replace指令。
					2.使用方法
						1.go.work文件有use和replace指令，可以覆盖各个go.mod文件，所以不需要单独编辑每个go.mod文件
						2.可以通过运行go work init来创建一个工作区，并将模块目录列表作为空格分隔的参数。工作区不需要包含你正在使用的模块。init命令创建一个go.work文件，列出工作区的模块。如果你在运行go work init时没有参数，该命令会创建一个空的工作区。
						3.要向工作区添加模块，可以运行go work use [moddir] 或手动编辑go.work文件。运行go work use -r来递归添加参数目录中带有go.mod文件的目录到你的工作区。如果一个目录没有go.mod文件，或者不再存在，使用use指令的目录将会从go.work文件中删除。
						4.要在你的工作区中使用一个本地模块或特定版本作为依赖，运行go work use [path-to-module]。
						5.要替换你的模块的go.mod文件中的现有依赖关系，请使用go work replace [path-to-module]。
						6.要添加你的GOPATH或任何目录中的所有模块，运行go work use -r来递归地添加有go.mod文件的目录到你的工作区。如果一个目录没有go.mod文件，或者不再存在，使用use指令的目录将会从 go.work文件中删除。
						7.go work sync：将go.work文件中的依赖关系推回到每个工作区模块的go.mod文件中。
			2.代码包
				所有Go源码都是包得一部分。
				每个Go源文件都起始于一条package语句。
				命名最好是驼峰,不建议使用_(多一位),简短
			3.源码文件
				go build -o 指定文件目录 go文件
			4.代码块
		4.设计模式(推荐)
			1.设计模式六大原则
				1.开闭原则
					对于扩展是开放的，对于更改是封闭的。
					开闭原则被称为面向对象设计的基石，实际上，其他原则都可以看作是实现开闭原则的工具和手段。
				2.里氏替换原则
					子类可以扩展父类的功能，但是不能改变父类原有的功能。
				3.依赖倒转原则
					高层模块不应该依赖底层模块，二者都应该依赖其抽象了；抽象不依赖细节；细节应该依赖抽象、接口编程。
				4.接口隔离原则
					接口尽量细化，同时保证接口中的方法尽量的少。
				5.迪米特法则
					一个类对自己需要耦合或者调用的类知道的最少，你类内部怎么复杂，我不管，那是你的事，我只知道你有那么多公用的方法，我能调用。
				6.单一职责原则
					一个类只负责一个职责
			2.23钟常见设计模式
				1.行为型模式
				2.结构型模式
				3.创建型模式
		5.标准库(必会)
			1.功能型
				1.net
					cn, err := net.Dial("tcp", "localhost:8080")
						// cn中所包含的方法
						Read(b []byte) (n int, err error)
						Write(b []byte) (n int, err error)
						Close() error
						LocalAddr() Addr
						RemoteAddr() Addr
						SetDeadline(t time.Time) error
						SetReadDeadline(t time.Time) error
						SetWriteDeadline(t time.Time) error
					l, err := net.Listen("tcp", ":8080")
						// l中所包含的方法
						Accept() (Conn, error)
						Close() error
						Addr() Addr
				2.errors
					// error是interface类型
					type error interface {
						Error() string
					}
					// error包中New返回的是一个结构体
					func New(text string) error {
						return &errorString{text}
					}
					type errorString struct {
						s string
					}
					func (e *errorString) Error() string {
						return e.s
					}
				3.os
					1. 文件系统
						对于文件系统的访问，在os包中提供了文件操作相关的函数，例如Create和Open函数：Create函数可以创建一个文件并返回一个文件句柄，Open函数可以打开一个文件并返回一个文件句柄。这些函数在不同的操作系统上实现的方式可能不同。
					2. 环境变量
						在os包中，可以使用Environ函数来获取当前进程的环境变量。它会返回一个字符串切片，每个元素都是“键=值”的形式。可以使用Setenv函数来设置环境变量，使用Unsetenv函数来删除环境变量。
					3. 进程管理
						在os包中，StartProcess函数可以用于启动一个新的进程，并返回一个Process类型的值，该类型表示当前进程所在的进程。这个函数在不同的操作系统上的实现方式可能不同，因此Process类型的组成和相关方法可能有所不同。
					4. 信号处理
						在操作系统中，信号是一种异步事件，因此需要使用操作系统提供的相关函数和类型进行处理。在os包中，Signal函数可以用于注册信号处理函数，Wait函数可以用于等待信号的到来并进行处理。
					5. 用户和组管理
						在操作系统中，用户和组是管理系统权限和访问控制的重要部分。在os包中，User和Group类型分别表示用户和组。当前用户可以使用CurrentUser函数获取，Getegid和Geteuid函数可以获取当前用户是属于哪个组。Getgroups函数可以获取当前用户属于哪些组。
				4.sync
					1.锁机制是同步机制中最基本的一种，主要是保证多个goroutine之间对于共享数据的操作能够正确地被执行。一般有两种锁机制：互斥锁和读写锁。
						1.互斥锁被广泛应用于go语言的并发编程当中，其背后的原理就是独占锁。当某个goroutine获取到了锁，其他goroutine就需要等待，直到锁被释放，这时候才能再次尝试获取锁。互斥锁通过Mutex结构体来实现，其主要方法有：
							- Lock：获取并持有锁，如果锁已被持有，则当前goroutine就会被阻塞；
							- Unlock：释放锁，如果当前并没有任何goroutine尝试获取锁，则该操作会非常快速；
							- TryLock：尝试获取锁，如果获取到了，则返回true，否则返回false。
						2读写锁是另一种锁机制，其主要用于读多写少场景。在读写锁中，读锁是共享锁，可以同时被多个goroutine持有，而写锁是独占锁，只能由一个goroutine来持有。读写锁通过RWMutex结构体来实现，其主要方法有：
							- RLock：获取并持有读锁，如果已经有goroutine持有写锁或正在等待获取写锁，则当前goroutine会被阻塞；
							- RUnlock：释放读锁；
							- Lock：获取并持有写锁，所以等待获取或者持有读锁和写锁的goroutine都会被阻塞；
							- Unlock：释放写锁。
						// 通过原子操作来将互斥锁的状态从未锁定（0）状态修改为锁定状态
						atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked)
						// 实现锁的加锁操作
						m.lockSlow()
					2.条件变量机制主要用于通知goroutine某个条件是否已经满足，只有当某个条件被满足时，才会释放锁，让其他等待同步的goroutine继续执行。
						1.条件变量机制通过Cond结构体来实现，其主要方法有：
							- Wait：进入条件等待，释放锁并阻塞当前goroutine，直到被唤醒；
							- Signal：唤醒一个goroutine，使其从条件等待中醒来；
							- Broadcast：唤醒所有等待同一条件的goroutine。
						w := sync.WaitGroup{}
						w.Add(1)
						w.Done()
						w.Wait()
						sync包WaitGroup内 state的高32位和低32位分别表示等待的goroutine的数量和是否已完成的标志位。
						高32位用于表示需要等待的goroutine数量，即计数器的值，该计数器代表还有多少个goroutine尚未完成并需要等待。调用Wait()时会阻塞，直至计数器的值归零。
						低32位用于表示是否已完成的标志位，该标志位用于表示WaitGroup是否已经完成。当WaitGroup内部计数器的值归零时，该标志位会被设置为已完成，表示所有等待的goroutine都已经完成，此时WaitGroup的所有等待都可以结束。
						(主要通过使用runtime_Semacquire(&wg.sema)来等待计数器归零)
						通过将低32位设置为1，可以在WaitGroup内部防止再次添加等待的goroutine，即不能对已关闭的WaitGroup对象再次添加等待的goroutine。这样可以避免在WaitGroup对象已经被销毁的情况下继续调用其方法，从而避免资源泄漏和运行时错误
				5.time
					1.time.Time
						1.time.Time表示一个具体时间点，类似于C中的time_t类型。它存储了一个64位整数来表示自UTC-1970年1月1日0时0分0秒起经过的纳秒数。time.Time有很多方法可以转化为各种形式的字符串、比较不同时间等。
						2.time.Duration表示一个时间间隔，它也是一个64位的整数，单位为纳秒。
					2.时间格式化
						time.Format()，可以将一个time.Time类型的时间转换为字符串。
							t := time.Now()
							fmt.Println(t.Format("2006-01-02 15:04:05"))
							//Output: 2021-10-01 14:30:10
					3. 时间解析
						除了将时间转换为字符串，Golang中还提供了将字符串解析为时间的函数time.Parse()。如下例：
						t, _ := time.Parse("2006-01-02 15:04:05", "2021-10-01 14:30:10")
						fmt.Println(t)
					4. 时间比较
						t1 := time.Now()
						t2 := time.Now().Add(time.Duration(1) * time.Hour)
						if t1.After(t2) / t1.Before(t2) ...
					5. 定时器
						1.延迟执行
							// 延迟1秒执行
							c := time.NewTimer(time.Second)
							<-c.C
						2.循环执行
							// 每一秒执行
							d := time.NewTicker(time.Second)
							for {
								<-d.C
							}
			2.输入输出型
				1.io
					1.io.Reader / io.Writer
						一个实现了io.Reader接口的对象可以被用来从某处读取数据，而实现了io.Writer接口的对象则可以用来向某处写入数据。一些常用的实现这两个接口的类型有File（读写文件）、strings.Reader（读取字符串）、bytes.Buffer（读写内存）等等。
					2. io.Copy
						复制操作是I/O编程中最常见的任务之一。Golang提供了一个方便的方法来复制（拷贝）源文件或者reader的内容到目标文件或者writer，即io.Copy()。
					3. io.ReadFull / io.WriteString
						io包还提供了一些常用的辅助函数，比如io.ReadFull()可以读取一个指定长度的字节流（如果读取不到指定长度的字节，将返回错误），io.WriteString()可以将一个字符串写入到一个writer中。
					4. io.Pipe
						io.Pipe()返回一对关联的*Pipe对象，可用于在不同的goroutine之间传递数据。一个*Pipe对象有两个方法，Read()和Write()。调用Read()方法会阻塞直到有数据可读；调用Write()方法会阻塞直到所有写入的数据都被读取。
				2.fmt
					// 该函数用于将格式化的字符串输出到标准输出流，常用于控制台输出。
					fmt.Printf(format string, a ...interface{})
					// 自动在字符串末尾添加一个换行符，并输出到控制台。
					fmt.Println(a ...interface{})
					// 但是不输出换行符，输出到控制台。
					fmt.Print(a ...interface{})
					// 该函数和Printf函数类似，但是不输出到控制台，而是返回一个格式化后的字符串。
					fmt.Sprintf(format string, a ...interface{})
					// 该函数用于将格式化的字符串和错误码（code）封装成一个错误类型，返回给调用者。
					fmt.Errorf(format string, a ...interface{}) error
						err := fmt.Errorf("code:%d, error:%s", 404, "Not Found")
					    if errors.Is(err, fmt.Errorf("code:%d, error:%s", 404, "Not Found")) {
					        fmt.Println("Error:", err)
					    }
					// 其中的io.Writer是一个接口，可以是各种实现了该接口的类型，例如文件、网络连接等。
					func Fprint(w io.Writer, a ...interface{}) (n int, err error)
						txt1 := "Hello"
					    txt2 := "World"
					    _, _ := fmt.Fprint(os.Stdout, txt1, ", ", txt2)
					    (fmt.Print就是调用的fmt.Fprint)
				3.log
					- func Print(v ...interface{})：打印普通日志消息
					- func Printf(format string, v ...interface{})：打印格式化的日志消息
					- func Println(v ...interface{})：打印带换行符的日志消息
					- func Fatal(v ...interface{})：打印致命错误消息并退出程序
					- func Fatalf(format string, v ...interface{})：打印格式化的致命错误消息并退出程序
					- func Fatalln(v ...interface{})：打印带换行符的致命错误消息并退出程序
					- func Panic(v ...interface{})：打印错误消息并引发panic
					- func Panicf(format string, v ...interface{})：打印格式化的错误消息并引发panic
					- func Panicln(v ...interface{})：打印带换行符的错误消息并引发panic

					log包中默认的输出流是标准错误（stderr）。可以使用SetOutput函数更改输出流。例如，要将日志消息输出到文件中，可以使用以下代码：
					可以将日志输入到文件中
						file, err := os.OpenFile("./a.txt", os.O_WRONLY|os.O_CREATE|os.O_APPEND, 777)
						if err != nil {
							log.Fatal(err)
						}
						defer file.Close()
						log.SetOutput(file)
						log.SetFlags(log.Ldate | log.Ltime)
						log.Println("asdfasdfassad")
		6.版本控制(必会)
			1.Git
2.高级
	1.Go编程进阶(必会)
		1.原理(必会)
			1.map
				golang map底层由两个核心的结构体实现：hmap和bmap，bmap本篇用桶代替。
				type hmap struct {
					count     int // count字段是map目前的元素数目,当使用len()函数获取map长度时,返回的便是count成员的值,因此len()函数作用于map结构时,其时间复杂度为O(1)
					flags     uint8 // 标志 map 的状态, 如 map 当前正在被遍历或正在被写入
					B         uint8  // 哈希桶数目以2为底的对数,在go map中,哈希桶的数目都是2的整数次幂(这样设计的好处是可以是用位运算来计算取余运算的值,即N mod M = N & (M-1))
					noverflow uint16 // 溢出桶的数目,这个数值不是恒定精确的
					hash0     uint32 // 随机哈希种子,map创建时调用fastrand函数生成的随机数,设置的目的是为了降低哈希冲突的概率
					buckets    unsafe.Pointer // 指向当前哈希桶的指针数组,也就是指向bmap结构体的数组(每个数组下标处存储的是一个bucket)
					oldbuckets unsafe.Pointer // 当桶扩容时指向旧桶的指针
					nevacuate  uintptr        // 是当桶进行调整时指示的搬迁进度,小于此地址的buckets是以前搬迁完毕的哈希桶,
					extra *mapextra // 溢出桶的变量
				}
				// 其中bucketCnt是1 << 3得来的
				// 每个bucket中可以存储8个kv键值对，当每个bucket存储的kv对到达8个之后，会通过overflow指针指向一个新的bucket，从而形成一个链表,看bmap的结构
				type bmap struct {
					tophash [bucketCnt]uint8 // 键哈希值的高 8 位
				}
				// 这个是编译时增加的结构体内容
				type bmap struct {
				    topbits  [8]uint8 // 每个键的hash值的高八位。
				    keys     [8]keytype
				    values   [8]valuetype
				    pad      uintptr
				    overflow uintptr
				}
				type mapextra struct {
					overflow    *[]*bmap
					oldoverflow *[]*bmap
					nextOverflow *bmap
				}
				key定位过程
					1.key经过哈希计算后得到哈希值共64个bit位（64位机），计算它到底要落在哪个桶时，只会用到最后B个bit位。(如果B=5，那么桶的数量，也就是buckets数组的长度是 2^5 = 32)
						比如:10010111 | 000011110110110010001111001010100010010110010101010 │ 01010
					2.用最后的 5 个 bit 位，也就是 01010，值为 10，也就是 10 号桶。这个操作实际上就是取余操作，但是取余开销太大，所以代码实现上用的位操作代替。
					3.再用哈希值的高 8 位，找到此 key 在 bucket 中的位置，这是在寻找已有的 key。最开始桶内还没有 key，新加入的 key 会找到第一个空位，放入。
						注:buckets 编号就是桶编号，当两个不同的 key 落在同一个桶中，也就是发生了哈希冲突。冲突的解决手段是用链表法：在 bucket 中，从前往后找到第一个空位。这样，在查找某个 key 时，先找到对应的桶，再去遍历 bucket 中的 key。
						<span class="image featured"><img src="{{ 'assets/images/other/go_map_base.jpg' | relative_url }}" alt="" /></span>
					4.上图中，假定 B = 5，所以 bucket 总数就是 2^5 = 32。首先计算出待查找 key 的哈希，使用低 5 位 00110，找到对应的 6 号 bucket，使用高 8 位 10010111，对应十进制 151，在 6 号 bucket 中寻找 tophash 值（HOB hash）为 151 的 key，找到了 2 号槽位，这样整个查找过程就结束了。
						(如果在 bucket 中没找到，并且 overflow 不为空，还要继续去 overflow bucket 中寻找，直到找到或是所有的 key 槽位都找遍了，包括所有的 overflow bucket。)

					注：kv的存放，为什么不是k1v1，k2v2..... 而是k1k2...v1v2...，我们看上面的注释说的 map[int64]int8,key是int64（8个字节），value是int8（一个字节），kv的长度不同，如果按照kv格式存放，则考虑内存对齐v也会占用int64，而按照后者存储时，8个v刚好占用一个int64,从这个就可以看出go的map设计之巧妙。
				整体流程：
					//获取hash算法
					//计算hash值
					//如果bucket数组一开始为空，则初始化
					//定位存储在哪一个bucket中
					//得到bucket的结构体
					//获取高八位hash值
					//死循环
					//循环bucket中的tophash数组
					//如果hash不相等
					//判断是否为空，为空则插入
					//插入成功，终止最外层循环
					//到这里说明高八位hash一样，获取已存在的key
					//判断两个key是否相等，不相等就循环下一个
					//如果相等则更新
					//获取已存在的value
					//如果上一个bucket没能插入，则通过overflow获取链表上的下一个bucket
				在Go语言中，map底层实现使用了哈希表。但是在哈希表涉及到扩容时，会发生哈希冲突的情况，此时Go语言使用了红黑树来解决哈希冲突的问题。当哈希表发生冲突，且冲突的bucket中的元素数量大于8时，Go语言会将bucket中的键值对转移到红黑树中。通过红黑树的平衡性，可以有效避免hash碰撞过多时，哈希表退化为链表的情况。
			2.channel
				type hchan struct {
				    qcount   uint // chan里元素数量
				    dataqsiz uint // chan底层循环数组的长度
				    buf      unsafe.Pointer // 指向底层循环数组的指针，只针对有缓冲的channel
				    elemsize uint16 // chan中元素大小
				    closed   uint32 // chan是否被关闭的标志
				    elemtype *_type // chan中元素类型
				    // 有缓冲channel内的缓冲数组会被作为一个“环型”来使用。当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置
				    sendx    uint   // 下一次发送数据的下标位置
				    recvx    uint   // 下一次读取数据的下标位置
				    // 当循环数组中没有数据时，收到了接收请求，那么接收数据的变量地址将会写入读等待队列
				    // 当循环数组中数据已满时，收到了发送请求，那么发送数据的变量地址将写入写等待队列
				    recvq    waitq  // 读等待队列（双向链表）
				    sendq    waitq  // 写等待队列（双向链表）
				    // 保护hchan中所有字段
				    lock mutex
				}
				向chan发送数据
					// 如果 channel 是 nil
				    if c == nil {
				        // 不能阻塞，直接返回 false，表示未发送成功
				        if !block {
				            return false
				        }
				        // 当前 goroutine 被挂起
				        gopark(nil, nil, "chan send (nil chan)", traceEvGoStop, 2)
				        throw("unreachable")
				    }

				    // 省略 debug 相关……

				    // 对于不阻塞的 send，快速检测失败场景
				    //
				    // 如果 channel 未关闭且 channel 没有多余的缓冲空间。这可能是：
				    // 1. channel 是非缓冲型的，且等待接收队列里没有 goroutine
				    // 2. channel 是缓冲型的，但循环数组已经装满了元素
				    if !block && c.closed == 0 && ((c.dataqsiz == 0 && c.recvq.first == nil) ||
				        (c.dataqsiz > 0 && c.qcount == c.dataqsiz)) {
				        return false
				    }

				    var t0 int64
				    if blockprofilerate > 0 {
				        t0 = cputicks()
				    }

				    // 锁住 channel，并发安全
				    lock(&c.lock)

				    // 如果 channel 关闭了
				    if c.closed != 0 {
				        // 解锁
				        unlock(&c.lock)
				        // 直接 panic
				        panic(plainError("send on closed channel"))
				    }

				    // 如果接收队列里有 goroutine，直接将要发送的数据拷贝到接收 goroutine
				    if sg := c.recvq.dequeue(); sg != nil {
				        send(c, sg, ep, func() { unlock(&c.lock) }, 3)
				        return true
				    }

				    // 对于缓冲型的 channel，如果还有缓冲空间
				    if c.qcount < c.dataqsiz {
				        // qp 指向 buf 的 sendx 位置
				        qp := chanbuf(c, c.sendx)

				        // ……

				        // 将数据从 ep 处拷贝到 qp
				        typedmemmove(c.elemtype, qp, ep)
				        // 发送游标值加 1
				        c.sendx++
				        // 如果发送游标值等于容量值，游标值归 0
				        if c.sendx == c.dataqsiz {
				            c.sendx = 0
				        }
				        // 缓冲区的元素数量加一
				        c.qcount++

				        // 解锁
				        unlock(&c.lock)
				        return true
				    }

				    // 如果不需要阻塞，则直接返回错误
				    if !block {
				        unlock(&c.lock)
				        return false
				    }

				    // channel 满了，发送方会被阻塞。接下来会构造一个 sudog

				    // 获取当前 goroutine 的指针
				    gp := getg()
				    mysg := acquireSudog()
				    mysg.releasetime = 0
				    if t0 != 0 {
				        mysg.releasetime = -1
				    }

				    mysg.elem = ep
				    mysg.waitlink = nil
				    mysg.g = gp
				    mysg.selectdone = nil
				    mysg.c = c
				    gp.waiting = mysg
				    gp.param = nil

				    // 当前 goroutine 进入发送等待队列
				    c.sendq.enqueue(mysg)

				    // 当前 goroutine 被挂起
				    goparkunlock(&c.lock, "chan send", traceEvGoBlockSend, 3)

				    // 从这里开始被唤醒了（channel 有机会可以发送了）
				    if mysg != gp.waiting {
				        throw("G waiting list is corrupted")
				    }
				    gp.waiting = nil
				    if gp.param == nil {
				        if c.closed == 0 {
				            throw("chansend: spurious wakeup")
				        }
				        // 被唤醒后，channel 关闭了。坑爹啊，panic
				        panic(plainError("send on closed channel"))
				    }
				    gp.param = nil
				    if mysg.releasetime > 0 {
				        blockevent(mysg.releasetime-t0, 2)
				    }
				    // 去掉 mysg 上绑定的 channel
				    mysg.c = nil
				    releaseSudog(mysg)
				    return true
				向channel写数据的过程
					1.如果等待接收队列recvq不为空，说明缓冲区中没有数据或者没有缓冲区，此时直接从recvq取出G,并把数据写入，最后把该G唤醒结束发送过程;
					2.如果接受队列recvq为空，且缓冲区中有空余位置将数据写入缓冲区，结束发送过程;
					3.如果接受队列recvq为空，缓冲区中没有空余位置，将待发送数据写入G，将当前G加入sendq，进入睡眠，等待被读oroutine唤醒
				从一个channel读数据简单过程
					1.如果等待发送队列sendq不为空，且没有缓冲区，直接从sendq中取出G，把G中数据读出，最后把G唤醒，结束读取过程;
					2.如果等待发送队列sendq不为空，此时说明缓冲区已满，从缓中区中首部读出数据，把G中数据写入缓中区尾部，把G唤醒，结束读取过程:
					3.如果缓冲区中有数据， 则从缓冲区取出数据，结束读取过程;4.将当前goroutine加入recvq，进入睡眠，等待被写goroutine唤醒;
			3.goroutine
			4.slice
				type slice struct {
					// 指向底层数组第一个位置的指针
					array unsafe.Pointer
					len   int
					cap   int
				}
				1.当在 slice 中添加元素时，如果当前 slice 没有足够的容量，Go 语言会创建一个新的底层数组，并将原 slice 值复制到新数组中。然后将新值附加到新底层数组中，并修改 slice 对应的指针、长度和容量。如果底层数组长度不够扩容则会重新分配一块更大的连续空间，将原来的数据拷贝到新的空间中。
				2.当 slice 被传递给函数时，只会传递指向底层数组的指针、长度和容量信息。当函数接收到 slice 后，可以随意修改 slice 中的元素，这也同样修改了底层数组中对应位置的值。因此，如果一个函数需要修改 slice 中的元素的值，它必须接收一个指向 slice 的指针
				3.空切片和 nil 切片的区别在于，空切片指向的地址不是nil，指向的是一个内存地址，但是它没有分配任何内存空间，即底层元素包含0个元素。
			5.runtime
				1. Goroutine
					Goroutine是Go语言的协程，由runtime包提供支持。以下是一些常用的函数：
						- go：创建并启动一个新的Goroutine。
						- Gosched：将当前的Goroutine挂起，让出CPU给其他Goroutine执行。
						- NumCPU：返回当前机器的CPU数量。
						- GOMAXPROCS：设置并发执行的最大CPU数。默认值为机器的CPU数量。
				2. 内存管理
					Go语言的内存管理是由runtime包提供支持的。以下是一些常用的函数：
						- GC：手动触发垃圾收集。
						- MemProfile：生成内存分配的性能分析数据。
						- MemStats：获取内存使用情况和垃圾收集信息。
						- SetFinalizer：设置对象的析构函数，用于在对象被回收前执行一些清理操作。
				3. 错误处理
					Go语言中的错误处理是通过错误值进行的，以便在程序执行过程中遇到问题时及时处理。以下是一些常用的函数：
						- panic：抛出一个异常，导致程序中断。
						- recover：捕获panic引起的异常，并恢复程序执行。
				4. 并发控制
					Go语言中的并发控制是基于互斥锁（Mutex）和读写互斥锁（RWMutex）实现的。以下是一些常用的函数：
						- Lock：获取互斥锁，如果锁已经被占用，则阻塞等待。
						- Unlock：释放互斥锁。
						- RLock：获取读写互斥锁的读锁。
						- RUnlock：释放读写互斥锁的读锁。
						- NewCond：创建一个新的条件变量。
						- Cond.Wait：等待条件变量的信号。
				5. 其他函数和数据结构
					runtime包中还有许多其他函数和数据结构，以下是一些常用的：
						- FuncForPC：根据程序计数器（PC）获取函数信息。
						- Caller：获取当前调用栈信息。
						- GOARCH、GOOS、Version等常量：获取Go程序编译的目标架构、操作系统和版本信息。
		2.GMP模型(必会)
			<span class="image featured"><img src="{{ 'assets/images/other/go_GMP.jpg' | relative_url }}" alt="" /></span>
			1.Go语言是原生支持语言级并发的，这个并发的最小逻辑单元就是goroutine。goroutine就是Go语言提供的一种用户态线程，当然这种用户态线程是跑在内核级线程之上的。当我们创建了很多的goroutine，并且它们都是跑在同一个内核线程之上的时候，就需要一个调度器来维护这些goroutine，确保所有的goroutine都使用cpu，并且是尽可能公平的使用cpu资源。这个调度器的原理以及实现值得我们去深入研究一下。支撑整个调度器的主要有4个重要结构，分别是M、G、P、Sched，前三个定义在runtime.h中，Sched定义在proc.c中。
				G：
					表示 Goroutine。每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。当 Goroutine 被调离 CPU 时，调度器代码负责把 CPU 寄存器的值保存在 G 对象的成员变量之中，当 Goroutine 被调度起来运行时，调度器代码又负责把 G 对象的成员变量所保存的寄存器的值恢复到 CPU 的寄存器。
				M：
					OS 底层线程的抽象，它本身就与一个内核线程进行绑定，每个工作线程都有唯一的一个 M 结构体的实例对象与之对应，它代表着真正执行计算的资源，由操作系统的调度器调度和管理。M 结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的 Goroutine 以及是否空闲等等状态信息之外，还通过指针维持着与 P 结构体的实例对象之间的绑定关系。
				P：
					表示逻辑处理器。对 G 来说，P 相当于 CPU 核，G 只有绑定到 P(在 P 的 local runq 中)才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等。它维护一个局部 Goroutine 可运行 G 队列，工作线程优先使用自己的局部运行队列，只有必要时才会去访问全局运行队列，这可以大大减少锁冲突，提高工作线程的并发性，并且可以良好的运用程序的局部性原理。
			2.go关键字就是用来创建一个goroutine的，后面的函数就是这个goroutine需要执行的代码逻辑。go关键字对应到调度器的接口就是runtime·newproc。runtime·newproc干的事情很简单，就负责制造一块砖(G)，然后将这块砖(G)放入当前这个地鼠(M)的小车(P)中。每个新的goroutine都需要有一个自己的栈，G结构的sched字段维护了栈地址以及程序计数器等信息，这是最基本的调度信息，也就是说这个goroutine放弃cpu的时候需要保存这些信息，待下次重新获得cpu的时候，需要将这些信息装载到对应的cpu寄存器中。				
			3.当我们使用 go 关键字之后，就会调用底层的 runtime.newproc() 函数，创建 goroutine 的同时，也会初始化栈空间，上下文 等信息。
			4.程序支持最多的goroutine并行,是取决于GOMAXPROCS来确定的
			5.P的本地队列,最大仅支持256个G(也就是256个goroutine)
			6.在程序运行时创建，它是 Go 后台运行的一个系统线程池。GMP 的目的是为了支持协程（goroutine）的创建、调度和垃圾回收。
			其中:
				M0
					启动程序后的编号为0的主线程
					在全局变量runtime.m0中，不需要在heap上分配
					负责执行初始化操作和启动第一个G(可以理解为程序的main函数)
					启动第一个G之后，MO就和其他的M一样了
				G0
					每次启动一个M，都会第一个创建的gourtine，就是G0
					G0仅用于给当前的M进行负责调度的G(G0是存在M0的结构体中的)
					G0不指向任何可执行的函数
					每个M都会有一个自己的G0
					在调度或系统调用时会使用M会切换到GO,来调度
					M0的G0会放在全局空间
			7.开始执行程序
				1.创建进程
				2.创建线程M0
				3.M0创建G0(每个M都会有自己的G0,其中G0是第一个G(main函数)的调度者,并没有实际的func来执行)
				4.根据配置文件创建P(包括本地队列与全局队列)
				5.M0启动第一个G(就是main函数),并放入到到对应P的队列当中,然后按照正常从P的队列中取出mian函数并执行
				6.如果main有阻塞,则M会将mian重新放回P的队列中,再次执行
			注:
				1.G中由M新创建的G是优先加入当前P的本地队列
				2.如果G执行完毕,M会调用G0获取环境变量,再从P中的本地队列调用下个G
				3.从全局队列获取G的数量是 min(全局队列中G的数量/M的数量 + 1, 全局队列中G的数量 / 2)
				4.GOMAXPROCS是限定P的数量
				5.自旋线程的数量限制: 执行M + 自旋M <= GOMAXPROCS
				6.G0可以执行任何Goroutine，而P只能执行与自己关联的Goroutine。当Goroutine在一个P上运行时，它将成为该P的一个任务，一旦它完成或者阻塞，该P将选择另一个任务执行。
				7. G0只有一个，是程序的主线程，它负责调度和管理所有的P，包括创建和销毁P，以及在需要时向P分配G等。
				8. P是Go语言运行时系统中的一组处理器，用来执行Goroutine。P的数量由Go运行时系统自动调整，每个P都拥有自己的本地调度器（LTS），它负责调度和管理与自己关联的Goroutine。
		3.GC(必会)
			1.标记清除法(1.3版本)
				1.从根节点出发,所有可达的节点做标记,不可达的就会被回收
				2.缺点
					1.执行GC时会出现stop the world(STW),程序会暂停,待扫描完毕后恢复执行(开始STW->标记(mark)->清除(Swaap)->结束STW)
					2.需要扫描所有的heap
			2.三色标记法(1.5)
				1.Toot Set数据来源
					1.程序栈中的引用：程序栈中保存了函数的调用关系信息，其中包含了函数参数和局部变量等引用对象信息，这些引用对象就构成了ROOT Set。
					2.全局变量引用：全局变量中引用的对象也可以作为ROOT Set。
					3.常量池中的引用：常量池中的字符串、数字和其他常量都有可能引用对象。
					4.注册给CGO的函数的参数、返回值和全局变量：如果程序有使用CGO调用其他语言的函数，那么这些函数的参数、返回值和全局变量也会加入ROOT Set。
				2.触发机制
					1. 当程序中的堆空间使用量达到了阈值（即 heap size > heap trigger），这时垃圾回收器就会被触发。
					2. 当程序中的 goroutine 数量达到了阈值（即在单个逻辑处理器 P 中，同时运行的 goroutine 数量达到了 GOMAXPROCS），垃圾回收器也会被触发。
					3. 当程序用完了本地缓存空间（Local Allocation Buffer，LAB）后，GC也会被触发。
					4. 当程序调用了 runtime.GC() 函数，手动触发垃圾回收器。
				3.过程
					1.扫描Toot Set根节点集合,将所有的对象放入到白色集合中(White标记表),将可直达(只遍历一次,并不是递归)的放入到灰色集合中(Grey标记表)
					2.循环灰色集合,将集合中的对象放入到黑色集合中(Black标记表),并找出这些可直达的对象标记为灰色(放入到灰色集合中)
					3.循环步骤2,直到没有灰色的对象
					4.回收白色集合中所有的对象,从而只剩下黑色集合
				4.缺点
					还是不能缺少STW机制:
						1.黑色对象引用白色对象 (使用强三色不变来破坏该规则)
						2.同时灰色对象失去白色对象的引用 ((使用弱三色不变来破坏该规则))
					强三色:
						1.黑色可以引用灰色,但不能直接引用白色对象
					弱三色:
						1.黑色可以引用白色,但是白色必须有被其他灰色直接或者间接引用
			3.三色标记法+屏障保护(屏障不会使用在栈空间)
				1.注:
					1.在正常的逻辑执行当中,增加一些判断机制,而增加的这些判断机制就是屏障
					2.栈空间被用于存储函数调用时的参数和局部变量。当一个函数执行完毕时，它的栈空间将被回收。当golang运行时发现某个goroutine的栈空间使用量超过了阈值（默认为1MB），就会触发栈空间的垃圾回收机制，将不再使用的栈空间进行回收。这个垃圾回收机制的实现方式与堆空间的垃圾回收机制类似，但是由于栈空间的特殊性质，垃圾回收的效率和精度都比堆空间的垃圾回收高很多。
					3.GC发生的时候主要是回收在堆（heap）上分配的内存。因为堆内存是由程序员手动分配的，而栈内存是由编译器自动管理的。
				2.插入屏障
					1.对象被引用时,触发机制
					2.在A对象引用B对象的时候,B被插入到灰色集合中
						// 伪代码
						添加下游对象(当前下游对象A, 新插入下游对象B) {
							添加B到灰色集合中
							当前下游对象 = B
						}
						// 调用
						A.添加下游对象(nil, B) // 当前下游没有对象, 添加B
						A.添加下游对象(C, B) // 当前下游为C改为B
					3.此时,如果栈中发生类似(黑色对象引用新建对象(白色))的情况,此时就会发生:
						1.将栈中所有对象置为白色,并触发STW机制
					4.缺点:
						结束时,栈空间还需要STW机制
				3.删除屏障
					1.对象被删除时,触发机制
					2.在A对象删除B对象的引用,B对象如果是灰色/白色,则被修改为灰色
						// 伪代码
						// A添加引用对象为nil/其他对象,则B就相当于被删除
						添加下游对象(当前下游对象B, 新插入下游对象C) {
							if (对象B是灰色 || 白色) {
								修改对象B为灰色
							}
							当前下游对象 = C
						}
						// 调用
						A.添加下游对象(B, nil) // 将下有对象改为nil，相当于删除
						A.添加下游对象(B, C) // 当前下游为B改为C，相当于删除
					3.缺点
						回收精度低,一个对象即使被删除了,依旧会存活一轮,在下一轮中才会被删除掉
			4.三色标记法+混合写屏障
				1.流程
					1.将栈上所有的可达对象标记为黑色(不用二次扫描,也就无需STW)
					2.任何在栈上新建的对象也标记为黑色
					3.堆上任何被删除的对象,被标记为灰色
					4.堆上添加的对象都被标记为灰色
					// 伪代码
					添加下游对象(当前下游对象B, 新插入下游对象C) {
						修改当前下游对象B为灰色
						修改新插入下游对象C为灰色
						当前下游对象 = C
					}
					// 调用
					A.添加下游对象(B, nil) // 将下有对象改为nil，相当于删除
					A.添加下游对象(B, C) // 当前下游为B改为C，相当于删除
				2.场景1,对象B被堆中删除引用,成为栈中对象的下游
					1.删除下游对象,需要把下游标记为灰色,所以此时对象B为灰色
					2.栈中增加下游对象B
					3.此时对象B是灰色,下一轮中,就会变为黑色
				3.场景2,对象B被栈对象删除引用,成为另一个栈中对象的下游
					1.因为栈中不会触发混合屏障,所以没有什么操作
					(如果只是删除了对下游对象的引用,那么此时是黑色被保护的,下一轮中就会被标记为白色,被删除)
				4.场景3,对象B被堆对象删除引用,成为另一个堆中对象的下游
					1.新增下游对象B会被标记为灰色
					2.删除下游对象B也会被标记为灰色
				5.场景4,对象B被栈中删除引用,成为堆中对象的下游
					1.原来堆中对象删除下游时,需要将下游标记为灰色(在下一次的GC中会被删除)
					2.原来栈中对象删除下游时,不触发混合屏障,所以不做改变
					3.堆中对象的下游改为对象B(此时对象B还在栈中,所以不触发混合写屏障,所以还是黑色)
		4.CGO(必会)
			CGO 是 Go 语言提供的 C 语言调用接口，用于解决 Go 语言无法直接调用 C 代码的问题。
			实现:
				1. 生成C语言头文件：在Go代码中导入C语言的头文件，通过命令"go tool cgo"将该头文件转化为Go语言的包。
				2. 编译生成动态库：将C语言的源代码编译为动态库，供Go语言调用。
				3. Go语言中调用C语言函数：在Go代码中调用C语言函数时，会先将参数和函数名转化为C语言的形式，然后通过动态库调用C语言函数，最后将返回值转换为Go语言的形式。
				4. 内存管理：由于Go语言使用垃圾回收机制进行内存管理，而C语言没有垃圾回收机制，因此在进行内存交互时需要进行内存管理。Go语言提供了一系列的内存管理函数，例如C.CBytes、C.GoBytes等函数，用于在Go语言和C语言之间进行内存传递的时候，进行内存的分配、释放和复制等操作。
				总的来说，CGO实际上是在Go语言和C语言之间搭建起了一座桥梁，使得两种语言可以互相调用和交互。这个过程需要进行参数和返回值的转换，内存的管理等操作，因此CGO的实现原理比较复杂。
			形式
				package main
				import "C"
				/*
				#include <stdio.h>
				static void SayHello(const char* s) {
				 puts(s);
				}
				*/
				import "C"
				func main() {
					C.SayHello(C.CString("hello \n"))
				}
		5.反射(必会)
		6.并发编程(必会)
			1.goroutine调度
				mian.go文件
				->编译成可执行文件
				->内存加载可执行文件
				->根据系统(Windows/Linux)执行runtime.main函数创建 main goroutine协程
				->main goroutine协程调用main.main的函数
				->全局变量G0与M0内都存有对方的信息(M0与G0是主协程)
				->如果程序有go func()...创建协程
				->主协程调用newproc()来新建G,并根据GOMAXPROC的数量放到对应的P队列中去
				->主协程完成新建后,程序执行完毕调用exit()主进程结束(所以需要sleep/chan/WaitGroup)
				(使用sleep还是chan都会调用gopark/goready..来改变协程状态)
			2.channel调度
			3.锁
				1.mutex
					type Mutex struct {
						state int32 // 0是0表示未上锁
						sema int32 // 
					}
				2.rwmutex
			4.waitGroup
			5.context
				1.在context树中,如果取消,则同时会把children中的子goroutine一同取消
				2.使用WithValue时,如果key相同,那么父级的值会被子设置的值替换(设计初期,是不建议去变动key对应的值,所以最好key设置为自定义的值,而不是基础类型(var i int),这样在使用的时候就不会覆盖父级的key)
				3.context.WithTimeout(parent, time.Millisecond*100) 如果父子都设置截止时间,则会根据时间较短的那个结束执行 / 手动调用context.WithCancel(context.TODO())来手动结束
				<span class="image featured"><img src="{{ 'assets/images/other/go_context.jpg' | relative_url }}" alt="" /></span>
			6.sync
			7.原子操作 atomic
				通过使用CPU底层的CAS（Compare-and-swap）指令来实现的。CAS指令是一种操作系统级别的原子操作，它能够在一个寄存器内的值与给定的值相等时将给定的值写入到指定的内存地址中，并返回操作前内存地址中的值。
				用来进行原子的存储、取值、比较和交换操作。其中比较和交换操作是比较重要的，可以用来实现一些高级的同步操作，如自旋锁、读写锁等。
				// 原子存储和取值操作
				func AddInt32(addr *int32, delta int32) (new int32)
				func AddInt64(addr *int64, delta int64) (new int64)
				func AddUint32(addr *uint32, delta uint32) (new uint32)
				func AddUint64(addr *uint64, delta uint64) (new uint64)
				func LoadInt32(addr *int32) (val int32)
				func LoadInt64(addr *int64) (val int64)
				func LoadUint32(addr *uint32) (val uint32)
				func LoadUint64(addr *uint64) (val uint64)
				// 原子比较和交换操作
				func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)
				func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool)
				func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool)
				func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool)
				func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool)
				func SwapInt32(addr *int32, new int32) (old int32)
				func SwapInt64(addr *int64, new int64) (old int64)
				func SwapUint32(addr *uint32, new uint32) (old uint32)
				func SwapUint64(addr *uint64, new uint64) (old uint64)
		7.测试(必会)
			1.单元测试
			2.压力测试
			3.覆盖测试
			4.性能测试
		8.数据结构与算法(必会)
		9.操作系统(必会)
			1.熟悉5种网络IO模型原理
				1.数据流
					通过I/O设备（如磁盘、网络、键盘等）传输的数据流，可以是输入流或输出流。可以是字符、二进制数据或其他格式的数据。在读取或写入数据时，程序需要打开一个流，然后可以通过读写流来与I/O设备进行交互。常见的流包括标准输入流、标准输出流、文件流、网络流等。
				2.I/O操作
					对流读写的操作就叫IO操作
				3.阻塞
					1.阻塞等待(不占用CPU时间片)
					2.非阻塞忙轮询(占用CPU系统资源)
						// 伪代码
						for true {
							// 反复查询
							for _, v := range []流 {
								if v 收到信息 {
									处理流
								}
							}
						}
					缺点
						1.不能同时处理多个I/O请求问题
				4.多路I/O复用
					既能够阻塞,也不浪费资源,也能够监听多个I/O请求的状态
					1.select
						// 伪代码
						for true {
							select([]流) // 如果没有IO请求则阻塞,直到有IO请求,然后通知,但是没有同时具体哪个IO,所以还是需要轮询查找哪个,仅支持1024个IO请求
							// 反复查询
							for _, v := range []流 {
								if v 收到信息 {
									处理流
								}
							}
						}
					2.epoll
						1.伪代码
							for true {
								可处理的IO := epoll_wait([]流) // 如果没有IO请求则阻塞,直到有IO请求,然后通知,可清楚通知是哪些IO,这样不用再去轮询查找出
								// 反复查询
								for _, v := range 可处理的IO {
									处理流
								}
							}
						2.epoll中API开发流程
							// 创建 epoll
							int epfd = epoll_crete(1000);
							// 将 listen_fd 添加进 epoll 中
							epoll_ctl(epfd，EPOLL_CTL_ADD，listen_fd，&listen_event);
							while (1) {
								// 阻塞等待 epoll 中 的fd 触发
								int active_cnt = epoll_wait(epfd, events，1000，-1);
								for (i = 0; i < active_cnt; i++) {
									if (evnets[il.data.fd == listen.fd) {
										accept，并且将新accept 的fd 加进epoll中，
									} else if (events[i].events & EPOLLIN) {
										对此fd 进行读操作
									} else if (events[i].events & EPOLLOUT) {
										对此fd 进行写操作
									}
								}
							}
						3.触发模式
							1.水平触发(默认),将内核态的事件复制到用户态的列表中进行处理,如果用户态没有处理,那么将从新置入内核态的堆中,等待下次处理
								优点:
									保证事件都会被处理
								缺点:
									内核态与用户态之间来回复制,浪费性能
							2.边缘触发,只将内核态的时间复制一次到用户态的列表中,不管处理情况
								优点:
									性能高
								缺点:
									无法保证事件被处理
			2.熟悉IO多路复用技术原理
				1.单线程Accept(无多路复用)
					主要逻辑
						// 创建监听套接字
						create listen_fd
						// 套接字绑定端口进行监听
						bind+listen
						// 等待接收客户端的连接
						accept(listen_fd)
					优点
						过程简单明了
					缺点
						单线程阻塞,造成请求拥堵
					<span class="image featured"><img src="{{ 'assets/images/other/io_thread1.jpg' | relative_url }}" alt="" /></span>
				2.单线程Accept+多线程读写业务
					主要逻辑
						// 创建监听套接字
						create listen_fd
						// 套接字绑定端口进行监听
						bind+listen
						// 等待接收客户端的连接
						ConnFd1 = accept(listen_fd) // ConnFd1就是当前客户端请求的上下文信息
						// 主线程创建子线程来接收与处理客户端通信的fd(资源共享的方式)
						New Thread(ConnFd1)
					优点
						支持了并发
					缺点
						如果子线程长时间无业务并没有断开,此时就会浪费资源,高并发场景,受限于硬件
					<span class="image featured"><img src="{{ 'assets/images/other/io_thread2.jpg' | relative_url }}" alt="" /></span>
				3.单线程多路复用
					主要逻辑
						// 创建监听套接字
						create listen_fd
						// 套接字绑定端口进行监听
						bind+listen
						// 开启多路复用
						start()
						// 等待接收客户端的连接
						ConnFd1 = accept(listen_fd)
						// 处理读写请求
						Read+Write
						(其实就是多个客户端请求过来,先将请求建立的ConnFd1放入到开启的多路复用队列当中,当主线程处理完一个请求,就会去队列中找下一个等待的请求)
					优点
						与单线程Accept(无多路复用)类似(区别就是多个客户端的请求能否快速响应)
					缺点
						单线程阻塞,造成请求拥堵
					<span class="image featured"><img src="{{ 'assets/images/other/io_thread3.jpg' | relative_url }}" alt="" /></span>
				4.单线程多路复用+多线程读写业务
					在3的基础上,将处理逻辑交给线程池中的线程处理,而读与写还是有主线程处理
					主要逻辑
						// 创建监听套接字
						create listen_fd
						// 套接字绑定端口进行监听
						bind+listen
						// 开启多路复用
						start()
						// 等待接收客户端的连接
						ConnFd1 = accept(listen_fd)
						// 处理读写请求
						Read
						// 将读取内容交给线程池中的线程处理
						Deal
						// 线程池处理完毕,将数据交给主线程,主线程再返回给客户端
						Write
						(其实就是多个客户端请求过来,先将请求建立的ConnFd1放入到开启的多路复用队列当中,当主线程处理完一个请求,就会去队列中找下一个等待的请求)
					优点
						在3的基础上,能够减少客户端访问Server导致业务串行执行会有大量请求判断的延迟时间。实际上读写的业务并发为1，但是业务流程的并发为worker pool线程数量，加快了业务处理的并行效率
					缺点
						读写依然是main thread单独处理，最高的读写并行通道依然为1
						虽然多个worker线程处理业务，但是最后返回给客户端依旧也需要排队。因为出口还是mainthraed的read+write 1个通道
					<span class="image featured"><img src="{{ 'assets/images/other/io_thread4.jpg' | relative_url }}" alt="" /></span>
				5.单线程多路复用+多线程多路复用
					多线程
						主要逻辑
							// 创建监听套接字
							create listen_fd
							// 套接字绑定端口进行监听
							bind+listen
							// 开启多路复用
							start()
							// 等待接收客户端的连接
							ConnFd1 = accept(listen_fd)
							(然后将ConnFd1交给其他子线程池来处理Read/Deal/Write)
							// 其他子线程池,同样是多路复用+Read+Write,直接返回给客户端
						优点
							在3的基础上,能够减少客户端访问Server导致业务串行执行会有大量请求判断的延迟时间。实际上读写的业务并发为1，但是业务流程的并发为worker pool线程数量，加快了业务处理的并行效率
						缺点
						<span class="image featured"><img src="{{ 'assets/images/other/io_thread5.jpg' | relative_url }}" alt="" /></span>
					多进程
						<span class="image featured"><img src="{{ 'assets/images/other/io_thread6.jpg' | relative_url }}" alt="" /></span>
			3.熟悉socket和多线程编程
		10.计算机原理与网络(必会)
			1.熟悉常见网络协议原理
				1. TCP/IP协议：TCP/IP协议是一种网络协议，它是现代网络通信的基础。它由两个部分组成：TCP协议和IP协议。TCP协议负责数据的传输，而IP协议负责数据的路由。
					1.数据包乱序-(数据包有seq,用来表示数据包的传输顺序)
					2.数据包校验-(tcp包有校验码,用来对数据包进行校验,不通过的包会被丢弃)
					3.数据包丢失-(使用超时重传机制)
					4.数据包效率-(滑动窗口,双方发送数据都会带有滑动窗口的大小,以此来动态调整窗口的大小)
				2. HTTP协议：HTTP协议是一种用来传输Web页面或其他数据的协议。它是建立在TCP/IP协议基础之上的。HTTP协议规定了客户端和服务器之间的请求和响应方式，包括请求方法，状态码，报文格式等，是Web应用程序的核心。
				3. FTP协议：FTP协议是一种用于文件传输的协议。FTP协议可以通过 TCP/IP 协议在网络上传输文件。FTP协议支持多用户之间的文件上传和下载，具有安全性、可靠性和灵活性等特点。
				4. POP3/SMTP协议：POP3和SMTP协议是邮件传输协议。POP3协议用来接收邮件，SMTP协议用来发送邮件。POP3协议支持接收邮件，SMTP协议支持发送邮件。
				5. DNS协议：DNS协议是一种域名解析协议，用于将域名解析成IP地址，使计算机能够通过域名访问Internet上的服务器。DNS是一个分布式的系统，它又分为本地DNS服务器、根DNS服务器、顶级域名服务器、二级域名服务器和主机服务器等多层次组成，可以完成全球范围内的域名解析工作。
				6. Telnet协议：Telnet协议是一种远程登录协议。它可以通过网络远程访问服务器，使用户可以像操作本地计算机一样地远程管理和控制远程服务器。
				7. SSH协议：SSH协议是一种更为安全的远程登录协议。它将用户登录信息、命令和结果进行加密传输，可以有效地保护用户的网络安全和隐私。
				8. VPN协议：VPN协议是一种虚拟私人网络协议，它可以在公共网络上建立一个加密通道，使得用户在互联网上可以安全地访问私人网络资源。VPN协议支持数据加密和认证机制，可以有效地保护用户的数据安全和隐私。
			2.熟悉常见序列化协议原理
		11.缓存(必会)
			1.深入理解Redis核心数据类型使用场景和内部实现
			2.深入理解Redis线程模型
			3.熟悉持久化方式
			4.熟悉数据过期策略
			5.熟悉数据淘汰策略
			6.熟悉分布式锁实现
			7.熟悉缓存高并发场景
		12.数据库(必会)
			1.熟悉数据库存储引擎
			2.熟悉数据库索引实现原理
				MySQL增加索引锁表问题
					1. 共享锁（Shared Lock）：在MySQL中，读操作默认使用共享锁。当我们要进行索引创建操作时，MySQL会首先获取表级共享锁（Table Lock），以防止其他事务对该表进行写操作。这是为了保证索引创建时表数据的一致性，避免数据被修改。
					2. MDL（Metadata Lock）：在MySQL中，MDL是一种针对元数据的锁机制。当我们创建索引时，MySQL会自动获取适当的MDL，以确保数据的一致性。MDL锁是在表级别上操作的，它会阻止其他事务对表的结构进行更改，包括表结构的修改、索引的创建等。
					3. 互斥锁（Exclusive Lock）：在MySQL中，写操作需要使用互斥锁。当索引创建过程中，MySQL会获取表级互斥锁，以保证只有一个事务在进行索引创建操作，避免并发问题。这样可以保证索引创建的正确性和数据的完整性。
					总结起来，MySQL在进行索引创建过程中会先获取表级共享锁和MDL锁，以阻止其他事务对表的写操作和结构修改。然后，MySQL会获取表级互斥锁，确保只有一个事务在进行索引创建操作。这样可以保证索引创建的正确性、数据的一致性和完整性。
					4.间隙锁:MySQL中使用for update来加锁,如果是范围查询,则会增加记录锁+间隙锁
						例如主键ID 1-4-7-10
						如果查询为 SELECT * FROM table WHERE id>4 FOR UPDATE;
						加锁就是(4,7),7,(7,10),10,(10,无穷大]
						如果查询为 SELECT * FROM table WHERE id = 8 FOR UPDATE;(数据没有id为8的记录)
						加锁就是(7,10)
			3.熟悉数据库锁
			4.熟悉数据库事务实现机制
			5.熟悉数据库主从复制
			6.熟悉数据库读写分离
			7.熟悉数据库分库分表
			8.掌握数据库常用调优手段
		13.设计模式(必会)
		14.Linux(必会)
			1.熟练掌握相关命令
				1.系统命令工具
				2.基础命令工具
				3.网络参数工具
					1. ifconfig：显示与网络相关的接口信息，例如IP地址、MAC地址、掩码等。
					2. netstat：显示网络连接、路由表、接口统计信息等。
					3. route： 显示和修改系统的路由表信息。
					4. iptables：用于配置Linux内核自带的防火墙软件（netfilter），设置Linux内网的IP包过滤规则。
					5. hostname：显示或设置主机名称。
					6. tcpdump：一个常用的网络数据包捕获工具，可用于检测网络流量。
					7. ping：向远程主机发送一个ICMP ECHO_REQUEST，并接收ECHO_RESPONSE。主要用于测试网络连接。
					8. traceroute：排查网络故障的工具，用于显示前往目标主机每个路由节点的响应时间。
					9. dig：查询域名的DNS记录信息。
					10. nslookup：查询DNS服务器中域名解析信息。
					11. ssh：远程登录并执行命令。
					12. scp：用于安全地将文件从一台计算机复制到另一台计算机。
					13. telnet：可用于测试主机端口是否可达。
					14. curl：用于向服务器发送请求并获取响应，支持HTTP、FTP、SMTP等协议。
				4.磁盘参数工具
					1. df：显示磁盘使用情况。
					2. du：显示文件或目录的磁盘使用情况。
					3. hdparm：查询和设置磁盘参数。
					4. fdisk：对硬盘进行分区。
					5. mkfs：创建文件系统。
					6. mount：挂载文件系统到指定挂载点。
					7. umount：卸载已挂载的文件系统。
					8. parted：对磁盘进行分区。
					9. lsblk：列出块设备的信息。
					10. blkid：查询块设备的UUID和文件系统类型。
			2.熟练掌握网络编程
	2.工程化(必会)
		1.微服务(必会)
			1.go-zero
		2.web框架(必会)
			1.gin
		3.中间件(必会)
			1.日志
				2.logrus
			2.服务发现
				4.zookeeper
			3.消息队列
				6.kafka
			4.缓存
				8.redis
			5.数据库
				10.mysql
			6.搜索引擎
				12.ElasticSearch
			7.rpc
				14.gRPC
			8.链路追踪
				16.jaeger
3.资深
	1.Go源码分析(必会)
		1.runtime源码
		2.net源码
		3.io源码
		4.map源码
		5.slice源码
		6.channel源码
		7.mutex源码
		8.gc源码
	2.中间件源码分析(推荐)
		1.MySQL源码
		2.Redis源码
		3.Kafka源码
		4.Elasticsearch源码
		5.ZooKeeper源码
		6.Flink源码
		7.RabbitMq源码
		8.Etcd源码
			1.组成部分
				1.boltdb
				2.wal
					预写式日志，记录所有的写操作，在etcd重启后可以通过快速回放这些写操作来恢复数据状态，保证数据的可靠性和一致性。然后将数据写入磁盘
						1. 避免数据丢失：WAL缓存可以在etcd进程崩溃或断电重启后恢复数据，避免数据丢失。
						2. 提高写入速度：WAL是一个追加式日志，它的写入速度比直接写入磁盘快，能提高etcd写入速度。
						3. 减少IO开销：WAL可以将多个数据写入缓存中，等缓存满了再一次性写入磁盘，减少IO操作，减少开销。
				3.snapshot
				4.gRPC Server
			2.分布式事务
				就是基于raft算法实现
				1.简单的KV操作
					get
					put
					del
				2.监听K状态的变更
					watch
				3.事务操作(这些操作是在开启事务时,用来判断success/failed的时候用到的)
					1.value(K) // 表示获取K的具体值
					2.create(K) // 表示K创建的版本ID
					3.mod(K) // 修改的版本ID
					4.
				4.每一个K都对应一个B+tree索引(可以使用.\etcdctl.exe get key -w json 命令来使用json的形式获取信息)
					其中存储的是K的历史版本信息
					// json内容
					{
					    "header":{
					        "cluster_id":14841639068965178418,
					        "member_id":10276657743932975437,
					        "revision":49, // 键值存储的修改次数。每当一个键值对被修改、创建或删除时，它的revision就会增加。可以通过比较revision的大小来判断哪些键值对被修改过，从而实现版本控制和快照备份等功能。
					        "raft_term":8 // 长度64位单调递增的ID,是当前Raft协议的任期(term)，也就是当前leader维护的term。Raft协议中每个任期(term)都有一个唯一的leader，其他节点必须遵守该leader的指导。在每个任期(term)中，集群中的每个节点都有一个唯一的编号，称为该节点在该任期(term)中的编号。
					    },
					    "kvs":[
					        {
					            "key":"a2V5",
					            "create_revision":47, // 记录一个键值对创建时的版本号。每次创建一个键值对时，都会将revision记录下来并为其分配一个新的create_revision。
					            "mod_revision":49, // mod_revision是一个64位整数，表示键值对的修改版本。每次一个键值对被修改或删除，它的mod_revision就会自增。mod_revision可以被用来保证某个对象的版本一致性，或者用于实现乐观锁。
					            "version":3,
					            "value":"bWFyaw=="
					        }
					    ],
					    "count":1
					}
					// mod_revision是指最近一次对key进行修改操作时所在的revision，而revision是指当前etcd存储的所有key-value的版本号。因此，当一个key被修改后，它的mod_revision会变化，而对应的revision也会变化，但是如果只是查询操作，mod_revision不会变化，但是revision会增加。
				5.查找流程,内存中是Btree来通过key->revision,磁盘中B+tree通过revision->Value
				6.定时(lease)
					1.首先定义一个lease并规定时长 .\etcdctl.exe lease grant 10(是秒为单位)
					2.然后将key通过 .\etcdctl.exe put key -lease (lease的Id) 来绑定,以达到TTL的目的
			3.raft算法-(https://hardcore.feishu.cn/docs/doccnMRVFcMWn1zsEYBrbsDf8De#)
				<span class="image featured"><img src="{{ 'assets/images/other/raft_base.jpg' | relative_url }}" alt="" /></span>
				(在raft中，写操作必须由leader节点处理。)
				(raft中的index指的是日志条目的索引，每个日志条目都有一个唯一的索引号，用于标识该条目在日志中的位置。)
					通用持久性状态
						currentTerm:服务器已知最新的任期(在服务器首次启动的时候初始化为0，单调递增),通过心跳来更新
						votedFor:当前任期内收到选票的候选者id 如果没有投给任何候选者 则为空，需要记录将投票给了谁
						log:日志条目:每个条目包含了用于状态机的命令，以及领导者接收到该条目时的任期(第一个索引为1)
							log内容包含三个字段，命令请求(set/add...),term,index
					通用易失性状态
						commitIndex:已知已提交的最高的日志条目的索(初始值为0，单调递增)
						lastApplied:已经被应用到状态机的最高的日志条目的索引(初始值为0，单调递增)
					领导者上的易失性状态
						nextIndex:Leader认为Follower i需要复制的下一个日志条目的下标。初始值为Leader最后一条日志的下标加1。Leader每次发送AppendEntries RPC时携带一个nextIndex[i]参数，告诉Follower从哪个下标开始复制日志。也就是commitIndex+1的值,表示下一步将要同步给Follower的下标
						matchIndex:有限状态机处理Follower i日志复制到的最后一条日志的下标。初始值为0。当Leader发送AppendEntries RPC成功后，会更新Follower的matchIndex为发出的日志复制条目的最后一个下标。这样Leader就可以知道当前已经复制的日志条目数，并通过这个值来判断是否已经复制了大多数节点的日志条目。
						(所以并不是代表nextIndex = matchIndex + 1,因为如果长时间没有同步日志,那么nextIndex > matchIndex + 1)
				阐述
					1.RAFT算法将一致性问题分解为几个部分：选举、日志复制和安全性。在RAFT算法中，每个节点可以扮演三种不同的角色：领导者、跟随者和候选人。
					2.当一个节点成为领导者时，它负责处理客户端请求，将这些请求转化为状态机操作，并将结果发送给跟随者。领导者还负责对日志进行复制和同步，确保所有节点拥有相同的日志。
					3.当领导者宕机或者无法正常工作时，会引发选举过程。在选举过程中，跟随者会发现没有领导者，它们随机选择一个节点作为候选人，如果大多数节点支持候选人，它就成为领导者，开始处理客户端请求。
				特点
					在RAFT算法中，有三种节点身份：Leader、Follower和Candidate。
					1. Leader：是系统中唯一的Leader节点，负责接收客户端请求并将操作复制到Follower节点。Leader节点还负责向Follower节点发送心跳消息，以维持集群的稳定性。
					2. Follower：是系统中除Leader节点外的所有节点，只能响应Leader节点的请求，并将操作复制到自己的本地状态机上。在正常情况下，Follower节点是不会主动发送消息的。
					3. Candidate：在某些情况下，Follower节点可能会尝试成为新的Leader节点。当Follower节点认为当前Leader节点无响应或故障时，它会成为Candidate节点并发起投票。如果多数节点（包括自己）投票同意它成为Leader节点，则它会转变为Leader节点。
				计时器
					// 初始时,每个节点的超时时间会在一定范围内进行随机,这样保证不会出现同一时间,多个节点的选举计时器同时超时的情况(如果某一时刻,进行选举,选举超时计时器又都是一样的,那么在初始状态下,每个节点都是选自己并且给其他节点发送心跳拉取选票,这样就会一直处在平衡状态,无法选举出领导者)
					1.心跳计时器
						节点之间的检测,如果超时,则表示主节点宕机,那么从节点就会变为候选节点,开始推送自己为主节点
					2.选举超时计时器(选举超时时间  150-300ms 避免来活锁)
						if 选举超时计时器超时 {
							则会重新发送拉票
						} else {
							if 收到的是选票 {
								则根据是否选票过半,来判断是否成为主节点
							} else if 收到的是心跳 {
								表示集群中已经有领导者,则变为跟随者
							}
						}
						(任期数会在心跳发送的时候传过去,这样在发生脑裂的情况下,就可以根据任期数来决策谁成为领导者谁成为跟随者)
						(避免在每个任期内,超过半数写入的数据不会丢失的原则,规定,在新上任的主节点会首先给超过半数的节点发送当前的任期号(no-op信号),这样就保证最少会有一个节点拥有最全所有的数据,这样就保证候选节点被选举为主节点的一定是拥有最新任期数的)
				补充
					1.候选者在成为leader的时候,会首先给子节点发送心跳,包含term等信息,接收到过半的ack后,才会真正的成为leader
					2.跟随者在成为候选者的时候,会首先发送心跳,来检测集群内节点数量是否过半,这样防止出现大集群与小集群脑裂,导致小集群内term大于大集群的term,从而在网络恢复通常后,小集群的term会覆盖掉大集群的term
					3.跟随者缺少的日志长度超过了主节点能够保存日志的长度,或新节点加入时,通过一段时间不能读写,仅能同步数据的方式,会导致新节点长时间都处于同步状态(数据量比较大的情况),所以使用快照(可能就是json或者其他压缩数据)的形式进行日志同步
						1.快照中包含该快照最后日志的ID,一是用来删除旧快照,二是如果跟随者的日志大于它,则跟随者日志到最后日志ID之间的都可以删除,用快照代替,如果跟随者日志小于日志ID,则全部可被快照替代.
			4.共识算法/一致性算法
				1.共识算法，也称为分布式一致性算法，是指一组分布式节点通过相互通信和协作达成共识的过程。其目的是在分布式环境下，使所有节点能够就某个值或结果达成一致的意见。一致性算法是指在分布式环境下，确保系统中所有节点的数据副本都保持一致。这可以通过共识算法实现。
				2.因此，共识算法和一致性算法密不可分，它们的主要区别在于前者是一个过程，而后者是一个结果。共识算法强调如何将不同的节点纳入一个特定的共识过程，而一致性算法则强调系统中所有节点数据的统一性。
			5.源码
				// 从整体上来说，一个集群中的每个节点都是一个状态机，而raft管理的就是对这个状态机进行更改的些操作，这些操作在代码中被封装为一个 Entry .(就是最小的日志)
				// https://github.com/etcd-io/etcd/blob/v3.3.10/raft/raftpb/raft.pb.go#L2031
				type Entry struct {
					Term uint64
					Index uint64
					Type EntryType //EntryNormal，EntryConfchange
					Data []byte // KV值
				}

				// Raft集群中节点之间的通讯都是通过传递不同的 Message 来完成的，这个 Message 结构就是一个非常general的大容器，它涵盖了各种消息所需的字段。
				// https://github.com/etcd-io/etcd/blob/v3.3.10/raft/raftpb/raft.pb.go#L2392
				type Message struct {
					Type MessageType // 心跳，追加日志，投票,上层应用消息等很多个
					To uint64 // 接受者
					From uint64 // 发送者
					Term uint64 // 任期 逻辑时钟
					LogTerm uint64 // 发送者最后一条日志的任期号
					Index uint64 // 如果是投票请求时 其表示发送者最后一条日志的索引号
					Entries []Entry // 需要存储的日志
					Commit uint64 // 已提交的所偶音质
					Snapshot snapshot // 存放快照
					Reject bool //对方节点拒绝了当前的请求
					RejectHint uint64 //对方节点拒绝了 当前的请求
					Context []byte 上下文信息 用于跟踪
				}

				// 顾名思义，unstable数据结构用于还没有被用户层持久化的数据，它维护了两部分内容 snapshot 和 entries :
				// https://github.com/etcd-io/etcd/blob/v3.3.10/raft/log unstable.go#L231
				type unstable struct {
					// the incoming unstable snapshot,if any.
					snapshot *pb.Snapshot
					// all entries that have not yet been written to storage.
					entries []pb.Entry
					offset uint64
					logger Logger
				}
	3.性能优化(必会)
		1.熟练掌握常用优化手段
		2.熟练掌握常见问题排查手段
			1.pprof
			2.go tool trace
			3.火焰图
			4.gdb
			5.perf
	4.系统设计(必会)
		1.拥有一定的架构设计能力
		2.分布式ID生成器
		3.电商下单减库存支付
		4.秒杀系统
			1.网页静态化(动静分离)
			2.静态资源使用CDN
			3.提前预热数据,将数据存入到缓存中,减轻数据库压力(比如配置信息,商品信息等,用来验证前端传参是否合法)
			2.服务器集群(k8s做弹性扩容,缩容)
			3.MySQL,Redis等优化
			4.超卖问题
				1.Redis使用lua脚本扣库存
				1.MQ异步减库存
				2.分布式锁(相对于1,性能低,不太推荐,使用Redis的set(key, 请求ID(requestID,如果使用userId,那么会出现删除锁时删了刚加的新锁), "NX", "PX"(表示设置过期时间是millisecond), ttl))
					也可以使用
				3.令牌桶(Redis抢token令牌,成功后再进行减库存)
		5.短链接系统
		6.微博
	5.服务稳定性(必会)
		1.限流
			1.令牌桶算法(Token Bucket Algorithm)：使用一个固定容量的桶来存放令牌，每当有请求到达时，消耗一个令牌，只有当桶中有足够的令牌时才能继续服务，否则请求被拒绝。
			2.漏桶算法(Leaky Bucket Algorithm)：类似于令牌桶算法，但是桶的容量是固定的，每当请求到达时，桶会以固定的速度漏水，如果桶满了，则请求被拒绝。
			3.固定窗口计数器(Fixed Window Counter)：设置一个固定的时间窗口，统计在此时间窗口内的请求次数，如果超过了设定的最大请求数，则拒绝后续的请求。
			4.滑动窗口计数器(Sliding Window Counter)：类似于固定窗口计数器，但是时间窗口会滑动，即每隔一段时间就更新计数器，通过统计滑动窗口内的请求次数来进行限流。
			5.漏斗算法(Lossy Bucket Algorithm)：类似于漏桶算法，但是在桶满的情况下，仍然接收请求，但是根据设定的速率进行请求的丢弃或处理。
			6.平均流量限制(Average Rate Limiting)：设定一个平均请求速率，通过统计一定时间内的请求数来控制请求的通过率。
		2.熔断
		3.降级
		4.隔离
		5.重试
		6.超时控制
		7.监控
		8.报警
		9.预案
	6.高并发实战(必会)
		1.常见技术(必会)
			1.无状态设计
			2.多线程
			3.连接池
				主要是资源的复用,避免资源的创建/销毁带来的开销,在数据库场景中,每次crud操作的时候,都会创建连接,频繁创建会影响数据库的性能,而连接池就是已经创建好的连接,这样就避免了重复的创建与销毁
				主要参数:
					1.初始化的连接数量,在应用程序舒适化的时候,建立的连接数量
					2.最大连接数,连接数最大的一个限制,超过限制则会阻塞
					3.最大空闲连接数,没有请求的时候,连接池保存的空闲连接数量
					4.最小空闲连接,当连接数小于这个值的时候,连接池会创建连接
			4.异步化
			5.并发
			6.缓存
	2.数据库(必会)
		1.表优化
		2.索引优化
		3.读写分离
		4.分库分表
		5.集群
	3.分布式(必会)
		1.幂等性问题
			同一操作出现多次请求造成的结果与首次操作结果相同的问题,多次调用造成的结果只有一次
			1.针对查询/删除,不会出现幂等的问题
			2.针对插入,建立唯一索引,这样在插入的时候可以进行查询是否存在操作来验证并过滤重复插入,可以在重复插入的情况下直接返回结果
			3.针对修改,Redis验证修改的请求是否处理过/悲观锁/增加修改的版本ID
			总之大致分为两种:
				1.接口只能调用一次,避免重复调用
					唯一索引,Redis的setnx(消息队列重复消费也可以使用)
				2.数据影响有一次
					状态机,乐观锁
	4.常见问题(必会)
		1.如何避免缓存”穿透”的问题？
		2.如何避免缓存”雪崩”的问题？
		3.如何避免缓存”击穿”的问题？
		4.缓存和 DB 的一致性如何保证？
	5.分布式原理与实战
		1.分布式理论(必会)
			1.CAP
				一致性（Consistency）
					写操作之后进行读操作无论在哪个节点都需要返回写操作的值
				可用性（Availability）
					非故障的节点在合理的时间内返回合理的响应
				分区容错性（Partition tolerance）
					当出现网络分区后，系统能够继续工作。打个比方，这里个集群有多台机器，有台机器网络出现了问题，但是这个集群仍然可以正常工作。
				注:
					1.在分布式系统中，网络无法100%可靠，分区其实是一个必然现象，如果我们选择了CA而放弃了P，那么当发生分区现象时，为了保证一致性，这个时候必须拒绝请求，但是A又不允许，所以分布式系统理论上不可能选择CA架构，只能选择CP或者AP架构。
					2.对于CP来说，放弃可用性，追求一致性和分区容错性，我们的zookeeper其实就是追求的强一致
					3.对于AP来说，放弃一致性(这里说的一致性是强一致性)，追求分区容错性和可用性，Nacos就是AP模式，这是很多分布式系统设计时的选择，后面的BASE也是根据AP来扩展。
					(比如服务发现就是AP模型)
			2.BASE
				基本可用（Basically Available）
					基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性一-注意，这绝不等价于系统不可用。比如:
						1.响应时间上的损失。正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒
						2.系统功能上的损失: 正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面
				软状态（Soft state）
					软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时
				最终一致性（Eventually consistent）。
					最终一致性强调的是所有的数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。
				注:
					与传统的ACID事务模型相比，BASE理论更适用于分布式系统的设计和实现。
			3.ACID
				原子性
				一致性
				隔离性
				持久性
		2.分布式事务(必会)
			1.TCC
				1. Try阶段：在该阶段中，系统尝试执行业务操作，并预留必要的资源。这一阶段可以看作是一个“准备阶段”，系统会检查各种前置条件和规则，以确保业务操作可以正常执行，同时记录相关信息和状态。

				2. Confirm阶段：在该阶段中，系统确认并持久化已执行的业务操作。如果前面的Try阶段执行成功，系统会确认执行这个操作，并将相关的数据永久保存下来。

				3. Cancel阶段：在该阶段中，系统撤销已执行的业务操作，并释放事务中预留的资源。如果前面的Try阶段执行失败或者在Confirm阶段出现异常，系统会撤销已执行的操作，恢复到Try阶段之前的状态，同时释放相关的资源。

				TCC模式的优点是可以确保分布式系统中各个操作的一致性，即使在出现异常或失败的情况下也能够进行回滚。同时，TCC模式还可以通过补偿机制来处理分布式事务中的部分成功或部分失败的情况，提高系统的容错性和可恢复性。

				然而，TCC模式也有一些限制和挑战。首先，实现TCC模式需要对业务操作进行细粒度的拆分和设计，以便在Confirm和Cancel阶段能够对操作进行恢复或撤销。其次，TCC模式在数据一致性和事务性能之间需要进行平衡，因为在Try阶段和Confirm/Cancel阶段都需要对数据进行读写操作，可能会影响系统的性能。此外，TCC模式还需要进行分布式事务的协调和监控，以确保各个阶段的执行顺序和正确性。
				(是一种侵入式的解决方案,不依赖数据库,也就是说不依赖锁,而是在业务层面进行实现,seata只是在全局整合所有的prepare,commit,rollback)
			2.2PC
				内容:
					分布式事务是指涉及多个不同系统或服务之间的事务操作，其中每个系统或服务都可以独立地进行本地事务操作，并且需要保证这些本地事务操作的一致性。

					两阶段提交（Two-Phase Commit，简称2PC）是一种用于实现分布式事务一致性的协议。它由协调者（Coordinator）和参与者（Participant）组成，通常采用同步执行的方式。

					1. 准备阶段（Preparation Phase）
						- 1. 协调者向所有参与者发送事务准备请求（Prepare Request）。
						- 2. 参与者接收到准备请求后，执行本地事务操作，将事务的undo和redo操作记录在日志中，并且将undo和redo日志写入磁盘，并返回一个“准备就绪”（Prepared）的响应给协调者。

					2. 提交阶段（Commit Phase）
						- 1. 协调者接收到来自所有参与者的“准备就绪”响应后，向所有参与者发送提交请求（Commit Request）。
						- 2. 参与者接收到提交请求后，执行事务的提交操作，将事务的undo日志删除，并将redo日志应用到数据库中，返回一个“已提交”（Committed）的响应给协调者。
						- 3. 协调者接收到来自所有参与者的“已提交”响应后，执行确认操作。如果所有参与者都返回“已提交”，协调者向所有参与者发送“全局提交完成”（Global Commit）的消息；否则，协调者向所有参与者发送“全局回滚”（Global Rollback）的消息。

					两阶段提交协议确保了只要有一个参与者出现问题无法提交，整个分布式事务就会回滚，从而保证了分布式系统的一致性。然而，由于两阶段提交的同步执行特性，协议的性能较低，并且存在单点故障的问题。因此，在实际应用中，还需要考虑更高效和更可靠的分布式事务解决方案，如基于消息队列的最终一致性方案、基于无锁算法的乐观并发控制方案等。
				解决方案:
					1.XA事务(Oracle,MySQL都支持2PC)
						$dbtest1 = new db("rdsg4hgebq8827g143m5o.mysql.rds.aliyuncs.com","query1","cdS1234567","base0");
						$dbtest2 = new db("39.99.165.81","root","cdS1234567","atest");
						//为XA事务指定一个id，xid 必须是一个唯一值。
						$xid = uniqid("");
						//两个库指定同一个事务id，表明这两个库的操作处于同一事务中
						$dbtest1->exec("XA START '$xid'");//准备事务1
						$dbtest2->exec("XA START '$xid'");//准备事务2
						try {
						    //$dbtest1
						    $return = $dbtest1->exec("UPDATE atest SET id=3 WHERE id=2") ;
						    echo "xa1:"; print_r($return);
						    if(!in_array($return,['0','1'])) {
						        throw new Exception("库1执行sql操作失败！");
						    }

						    //$dbtest2
						    $return = $dbtest2->exec("UPDATE atest_2 SET id2=3 WHERE id2=2") ;
						    echo "xa2:"; print_r($return);
						    if(!in_array($return,['0','1'])) {
						        throw new Exception("库2执行sql操作失败！");
						    }

						    //阶段1：$dbtest1提交准备就绪
						    $dbtest1->exec("XA END '$xid'");
						    $dbtest1->exec("XA PREPARE '$xid'");

						    //阶段1：$dbtest2提交准备就绪
						    $dbtest2->exec("XA END '$xid'");
						    $dbtest2->exec("XA PREPARE '$xid'");

						    //阶段2：提交两个库
						    $dbtest1->exec("XA COMMIT '$xid'");
						    $dbtest2->exec("XA COMMIT '$xid'");
						} catch (Exception $e) {
						    //阶段2：回滚
						    $dbtest1->exec("XA ROLLBACK '$xid'");
						    /*上面这行代码是2pc中的xa事务，
						    update set a = a+1
						    如果是TCC，那么上面这行代码就变了，变成调用一个php接口，这个接口的作用就是把之前的操作给取消
						    update set a = a-1*/

						    $dbtest2->exec("XA ROLLBACK '$xid'");
						    die("Exception:".$e->getMessage());

						}
					2.seate使用
						注:
							TC (Transaction Coordinator) - 事务协调者
								维护全局和分支事务的状态，驱动全局事务提交或回滚。
							TM (Transaction Manager) - 事务管理器
								定义全局事务的范围：开始全局事务、提交或回滚全局事务。
							RM (Resource Manager) - 资源管理器
								管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。
						1.配置
							应用层的框架,可以支持多语言(只要数据库支持事务即可)
							1.安装插件
							2.配置参数(seate数据存储形式:file,mysql...;MySQL地址...)
							3.使用
						2.将全局事务的分支事务业务信息放到表中(视频中是undo_log表,并是不MySQL的undo_log信息),表中记录这事务执行前与执行后的数据信息,这样解决了2PC中长时间占用数据库资源的缺点.
						(注,一般的AT,TCC,Saga都是补偿型的,记录数据前后变化并进行提交/回滚,也就是说会出现中间状态(脏读),而XA是强一致性的,不会出现(脏读))
						分为:
							1.AT
								提供无侵入自动补偿的事务模式 [这里是基于本地能支持事务的关系型数据库，然后java代码可以通过JDBC访问数据库，这里的无侵入: 我们只需要加上对应的注解就可以开启全局事务]
							2.XA
								支持已实现XA接口的数据库的XA模式[这里一般是需要数据库实现对应的XA模式的接口，一般像mysql oracle 都实现了XA]
							3.TCC
								TCC则可以理解为在应用层面的 2PC，是需要我们编写业务逻辑来实现
							4.SAGA
								为长事务提供有效的解决方案
						3.补偿事务
							1.Try 阶段主要是对业务系统做检测及资源预留
							2.Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行 Confirm阶段时，默认 Confirm阶段是不会出错的。即: 只要Try成功，Confirm一定成功。
							3.Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放,此时就需要进行补偿来处理回滚的操作
				缺点:
					1.单点问题:事务管理器在整个流程中扮演的角色很关键，如果其宕机，比如在第一阶段已经完成，在第二阶段正准备提交的时候事务管理器宕机，资源管理器就会一直阻塞，导致数据库无法使用
					2.同步阻塞:在准备就绪之后，资源管理器中的资源一直处于阻塞，直到提交完成，释放资源
					3.数据不一致:两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务commit的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性
			3.3PC
				1. 准备阶段（Preparation Phase）：
				   - 协调者（Coordinator）向所有参与者（Participant）发出事务提交请求。
				   - 参与者执行事务，并将执行结果和准备就绪通知发送给协调者。
				   - 参与者在接收到准备就绪通知后，将事务日志写入磁盘，并进入预备提交状态。

				2. 提交请求阶段（Commit Request Phase）：
				   - 协调者收到所有参与者的准备就绪通知后，向所有参与者发送事务提交请求。
				   - 参与者在接收到事务提交请求后，检查本地的事务操作是否执行成功。
				   - 如果本地事务执行成功，参与者将返回“同意”响应，否则返回“拒绝”响应。

				3. 决策阶段（Decision Phase）：
				   - 协调者根据收到的响应情况进行决策。
				   - 如果所有参与者都返回“同意”，协调者将发送“全局提交”指令给所有参与者。
				   - 如果任何一个参与者返回“拒绝”，协调者将发送“全局回滚”指令给所有参与者。

				分布式事务三阶段提交的优点是能够保证分布式系统中的数据一致性，确保所有节点在事务提交时都达到一致的状态。然而，它也存在一些缺点，比如协调者的单点故障问题，以及由于网络延迟或节点故障导致的协议超时和性能下降问题。
			4.Saga
				1. 特点
					Saga是一种实现分布式事务的机制，它通过将一个大型事务拆分为多个子事务，并在每个子事务中引入补偿机制来保证整个事务的一致性。

					在Saga中，每个子事务代表着一个操作，它可能是一个数据库操作、一个远程服务调用或者其他一些需要保证一致性的操作。每个子事务都有一个对应的补偿操作，用于撤回或修复该子事务引起的改变。

					Saga的执行过程如下：
					1. 开始事务：事务协调器创建一个全局事务标识，并将该标识传递给所有的子事务。
					2. 执行子事务：各个子事务根据全局事务标识执行自己的操作，并将操作结果保存下来。
					3. 检查点：在每个子事务执行完成后，将该子事务的执行结果持久化保存下来，以便后续的补偿操作使用。
					4. 事务协调：事务协调器根据各个子事务的执行结果来决定是否继续执行后续的子事务，或者执行补偿操作以回滚前面的操作。
					5. 回滚或确认：如果任何一个子事务失败了，事务协调器将按照相反的顺序执行该子事务的补偿操作来回滚前面的操作。如果所有子事务都执行成功，则事务协调器确认整个事务的提交。

					Saga的好处是它能够在一个分布式环境中实现事务的一致性，而不需要使用传统的两阶段提交协议（2PC）等复杂的分布式事务协议。另外，Saga能够在某些故障场景下保证局部事务的一致性，而不需要回滚整个事务。

					然而，Saga也有一些限制和挑战。首先，Saga对于子事务的执行顺序要求比较严格，只有按照事务协调器指定的顺序执行子事务才能保证一致性。此外，Saga的补偿操作需要开发者手动编写，并且需要保证补偿操作的幂等性和可逆性。

					总之，Saga是一种适用于分布式环境下实现事务一致性的机制，它通过拆分事务，并引入补偿机制来保证分布式事务的正确执行。但是，开发者需要对事务的执行顺序和补偿操作有较强的控制力，并且需要考虑一些额外的编码和管理复杂性。
				2. 与三阶段的区别
					1. 事务模型：
					- Saga是一种长事务模型，通过将一个大事务拆分为多个小事务，并通过补偿操作来处理事务的部分失败。
					- 三阶段提交是一种原子事务模型，它将整个事务分为三个阶段：准备阶段、提交阶段和确认阶段。

					2. 数据一致性：
					- Saga通过补偿操作来保持数据一致性。如果一个事务失败，Saga会执行补偿操作来回滚之前已经执行成功的操作，以确保所有修改都被撤销。
					- 三阶段提交使用协调者和参与者之间的消息交互，通过检查点机制来保持数据一致性。在所有参与者都执行完准备阶段后，协调者会向所有参与者发起提交请求，如果所有参与者都准备就绪，则协调者会发送确认请求来最终提交事务。

					3. 可用性：
					- Saga在部分失败的情况下，可以继续执行未失败的部分操作，从而提高系统的可用性。
					- 三阶段提交在协调者或参与者失效的情况下，整个事务都会被阻塞，直到恢复或者超时，从而可能影响系统的可用性。

					4. 性能：
					- Saga的性能较好，因为它将事务拆分为多个小事务，并且可以并发地执行这些小事务。
					- 三阶段提交的性能较差，因为它需要进行多次消息交互和等待确认的过程。
			5.消息事务
				1.执行业务,将事件插入到事件表中(数据库存储)
				2.从表中读取未发送的事件到消息队列中并更新为已发送
				3.消费端相应ack并将事件插入到消费表中(数据库存储)
				4.读取消费表中的事件进行处理
					把分布式事务分割为多个阶段的本地小事务进行处理
				优点:
					用户体验响应快
				缺点
					逻辑复杂,出现问题排查麻烦
		3.分布式协议与算法(推荐)
			1.Paxos算法
			2.Raft算法
			3.一致性哈希算法
			4.Gossip协议
			5.Quorum NWR算法
			6.PBFT算法
			7.PoW算法
			8.ZAB协议
		4.分布式缓存(必会)
			1.Redis
		5.分布式数据库(必会)
			1.TiDB
		6.分布式搜索引擎(必会)
			1.ElasticSearch
		7.分布式存储(必会)
			1.Ceph
		8.分布式文件系统(必会)
			1.Hadoop
		9.分布式队列(必会)
			存在的问题
				1.消息重复
					1.Producer产生重复消息
					2.kafka的offset被回调
					3.consumer确认失败
					4.consumer超时
					5.业务逻辑发起重试
				2.数据不一致
				3.消息丢失
					1.Producer产生消息丢失
					2.磁盘持久化异常
					3.kafka的offset被回调
					4.consumer接收消息并回应ack,此时MQ重启
				4.消息的顺序性
					1.kafka中不同partition无序
					2.MQ同一个queue不同消费者无序消费
				5.消息堆积
					Producer速度大于consumer
			解决方式(对应问题的序号)
				1.
					1.幂等设计(增加消费消息表,使用messageId来存储消息,用来区分是否消费过)
				2.
					1.强一致性,增加重试机制(增加消息重试表,使用messageId来存储消息,用来区分是否消费过)
				3.	
					1.生产端,需要开启ack机制
					2.MQ,开启持久化
					3.消费端,开启手动应答ack(防止在消费的时候出现逻辑报错,导致自定应答从而消息被消费)
					4.增加数据表(增加消息发送表,使用状态标记待确认,消费消息时改为已确认,如果表中一直存在有待确认的,则表示消息丢失)
				4.
					1.使用单一生产者/消费者,保证顺序性
					2.根据用户/订单号路由到不同的partition中(类似分库分表)
					3.多生产者乱序发送到队列,消费端对序号进行判断,前一个序号是否已经消费过,如果前一个已经消费,则进行消费并把当前序号记录下来(比如用Redis),如果前一个没有消费,则重新投到队列中(不推荐,队列压力大)
					4.在3的基础上,将如果前一个没有消费,则存储在内存中(比如Redis, 待处理消息也作为value存入),然后从内存中检索是否有下一个待处理的序号,如果没有则
				5.
					1.如果不需要顺序性,则可增加consumer数量
					2.如果需要保持顺序性,则可根据消息类似4的方式进行(类似分库分表),到不同的partition中
			1.Kafka
			2.RabbitMq
		10.分布式协调(必会)
			1.Zookeeper
			2.Etcd
			3.Consul
		11.分布式锁(必会)
			1.Redis实现
			2.Zookeeper实现
			3.MySQL实现
		12.分布式计算(必会)
			1.Spark
			2.Storm
			3.Flink
		13.容器化(必会)
			1.Docker
			2.Kubernetes
				1.深入掌握，并有一定实际经验
		14.分布式ID
			1.UUID
				优点:
					本地生成，生成简单，性能好，没有高可用风险
				缺点:
					长度过长，存储冗余，且无序不可读，查询效率低
			2.数据库自增ID
				使用数据库的id自增策略，如 MySQL 的 auto increment。并且可以使用两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。
				优点:
					数据库生成的ID绝对有序，高可用实现方式简单
				缺点:
					需要独立部署数据库实例，成本高，有性能瓶颈
			3.批量生成ID
				一次按需批量生成多个ID，每次生成都需要访问数据库，将数据库修改为最大的ID值，并在内存中记录当前值及最大值。
				优点:
					避免了每次生成ID都要访问数据库并带来压力，提高性能
				缺点:
					属于本地生成策略，存在单点故障，服务重启造成ID不连续
			4.Redis生成ID
				Redis的所有命令操作都是单线程的，本身提供像 incr 和 increby 这样的自增原子命令，所以能保证生成的ID 肯定是唯一有序的
				优点:
					高性能，低延迟，按时间有序，一般不会造成ID碰撞
				缺点:
					需要独立的开发和部署，依赖于机器的时钟
		15.行业砥柱(必会)
			1.开源社区-开源贡献-开源项目
			2.图像编解码
			3.直播
			4.视频编解码
			5.游戏
			6.金融
			7.云原生
	6.常见的负载均衡算法
		轮询负载均衡算法: RR ，Round Robin，挨个发，适合于所有服务器硬件都相同的场景两个服务器。
		代码实现:
			用i 保存 取 服务器的 下标。第一次来取0，第二次来取1，第三次来 取 0
		加权轮询算法: weighted round robin，wrr，按照权重不同来分发，基本上是基于配置
			举例:
				// 权重分别为521,总和为8,取权重最大值的节点(就为当前一次的处理节点),然后该节点减去总和,然后再加上每个的节点权重,依次下去
				A(5) B(2) C(1) #(节点A权重 - 8)  A(-3) B(2) C(1) #(所有节点 + 初始权重)
				A(2) B(4) C(2) #(节点B权重 - 8)  A(2) B(-4) C(2) #(所有节点 + 初始权重)
				A(7) B(-2) C(3) #(节点A权重 - 8)  A(-1) B(-2) C(3) #(所有节点 + 初始权重)
				A(4) B(0) C(4) #(节点A权重 - 8)  A(-4) B(0) C(4) #(所有节点 + 初始权重)
				A(1) B(2) C(5) #(节点C权重 - 8)  A(1) B(2) C(-3) #(所有节点 + 初始权重)
				A(6) B(4) C(-2) #(节点A权重 - 8)  A(-2) B(4) C(-2) #(所有节点 + 初始权重)
				A(3) B(6) C(-1) #(节点B权重 - 8)  A(3) B(-2) C(-1) #(所有节点 + 初始权重)
				A(8) B(0) C(0) #(节点A权重 - 8)  A(0) B(0) C(0) #(所有节点 + 初始权重)
				A(5) B(2) C(1)...
				这样调用顺序就为 A B A A C A B A,不会出现 A A A A A B B C 这样
		代码实现:
			两个服务权重分别是6和4，我们的方法，在1-10之间取 随机数，比如取到 1-6，就走6的权重，取到710，就走4权重的服务。
		随机轮询算法: Random
		代码实现:这个就随意了
		最少链接: Least connections，记录每个服务器正在处理的 连接数 (请求数)，将新的请求 分发到最少连接的服务器上，这是最符合负载均衡的算法
4.专家
	1.架构设计(必会)
		1.领域架构设计
		2.微服务
		3.服务网格
			1.istio
		4.云原生
		5.一定的架构落地能力
			1.具备从零搭建大型分布式系统能力
			2.引领团队
			3.公司业务执行落地
			4.具备行业城市方案
	2.解决方案(必会)
		1.实际解决过问题
		2.有线上事故的处理经验
		3.深入行业，具备实施行业领先解决方案的能力
	3.开源项目(必会)
		1.主导或参与过开源项目
		2.为知名开源项目贡献过源码
	4.高并发(必会)
		1.具备应对高并发的能力
		2.对计算机、网络基础设施、数据库都需要有深入了解
	5.容器技术(必会)
		1.深入源码
		2.具备改造能力
		3.具备造轮子能力
		4.Kubernetes
		5.Docker
注:
	1.如果程序出现高并发需要进行原子操作的场景, 可以考虑使用atomic的相关原子方法
	2.接口限制调用次数(说的高级一点叫将cpu次数限制转为io限制),可以考虑chan
	3.可以使用time包自带的方法func After(d Duration) <-chan Time来实现定时处理
		在实际使用中，如果需要控制定时器的停止时间，使用`time.NewTimer`更合适；如果只是简单地等待一段时间后触发某个事件，可以使用`time.After`。
		- `time.NewTimer`需要显式地停止定时器，可以调用`Stop()`方法停止定时器，否则定时器会一直触发。
		- `time.After`会在等待时间结束后自动停止定时器，不需要手动停止。
</pre>