---
title: MySQL性能调优与架构设计
author: Yahui
layout: mysql
category: MySQL
---


书名:《MySQL性能调优与架构设计》

<pre style="text-align: left;">
	1.MySQL物理文件组成
	    1.日志文件
	        1. Error log,默认情况下,错误日志是关闭的,可以在启动的时候-log-error来开启,如需要备份日志文件并生成新的,可使用FLUSH LOG
	        2. Binary Log(二进制日志),也就是binlog,所有修改数据库的query都会被记录进来
	        	show master logs; // 查看当前binlog文件
				show master status; // 查看所有的binlog文件
				show binlog events in 'mysql-bin.001171' // 查看某个binlog的内容
			3. update log,更新日志,在5.0后就不支持
			4. query log查询日志,记录的所有的query,同时包括select,所以文件相对非常大,一般用于追踪某个时间段的sql性能会暂时开启,一般不建议开启
			5. slow query log(文本格式,可通过编辑器查看)慢查询日志,其中包含语句执行的时间,消耗的时间,执行的用户,主机信息等,可以使用mysqlslowdump工具分析慢日志
			6. redo log(Innodb在线redo日志),事务的安全性主要就是通过redo日志和记录在表空间中的undo信息来保证的.
				redo记录了Innodb所做的所有物理变更和事务信息,用于记录数据修改后的记录,顺序记录,如果这个修改在flush到磁盘文件时出现异常,可以使用redo log实现重做操作,保证事务的持久性
				undo用于存放数据修改被修改前的值,实现回滚操作,保证事务的一致性
				例:(假设有A、B值分别为1,2开始一个事务,事务的操作内容为:把1修改为3,2修改为4)
				A.事务开始.
				B.记录A=1到undo log.
				C.修改A=3.
				D.记录A=3到redo log.
				E.记录B=2到undo log.
				F.修改B=4.
				G.记录B=4到redo log.
				H.将redo log写入磁盘
				I.事务提交
		2.数据文件
			1.(皆有).frm:与表相关的元数据（meta）信息都存放在".frm"文件中,包括表结构的定义信息等
			2.(MyISAM).MYD:存放 MyISAM 表的数据
			3.(MyISAM).MYI:存放 MyISAM 表的索引相关信息
			4.(Innodb).ibd:独享表空间存储方式使用.ibd文件来存放数据
			5.(Innodb).ibdata:如果选用共享存储表空间来存放数据,则会使用 ibdata 文件来存放,所有表共同使用一个（或者多个,可自行配置）ibdata 文件
		3.主从复制(Replication)相关文件
			1.master.info文件:存在于Slave端的数据目录下,里面存放了该Slave的Master端的相关信息,包括Master的主机地址,连接用户,连接密码,连接端口,当前日志位置,已经读取到的日志位置等信息
			2.relay log(中继日志)文件:
				mysql-relay-bin.xxxxxn:用于存放Slave端的I/O线程从Master端所读取到的Binary Log信息,然后由Slave端的SQL线程从该relay log中读取并解析相应的日志信息,转化成Master所执行的SQL语句,然后在Slave端应用
				mysql-relay-bin.index:功能类似于mysql-bin.index,同样是记录日志的存放位置的绝对路径,只不过他所记录的不是Binary Log,而是Relay Log
			3.relay-log.info文件:类似于master.info,它存放通过Slave的I/O线程写入到本地的relay log的相关信息.供Slave端的SQL线程以及某些管理操作随时能够获取当前复制的相关信息
		补充.主从复制
			异步复制(Async replication)
				在master将事务写入binlog后,将新写入的binlog事务日志传送给slave节点,但并不等待传送的结果,就会在存储引擎中提交事务
			半同步复制(Semi-sync replication)
				在master将事务写入binlog后,将新写入的binlog事务日志传送给slave节点,但需要等待slave返回传送的结果
				slave收到binlog事务后,将其写入relay log中,然后向master返回传送成功ACK
				master收到ACK后,再在存储引擎中提交事务
		4.其他文件
			1.system config file:系统配置文件一般都是"my.cnf",Unix/Linux下默认存放在"/etc"目录下,Windows 环境一般存放在"c:/windows"目录下面"my.cnf"文件中包含多种参数选项组(group),每一种参数组都通过中括号给定了固定的组名,如"[mysqld]"组中包括了mysqld服务启动时候的初始化参数,"[client]"组中包含着客户端工具程序可以读取的参数,此外还有其他针对于各个客户端软件的特定参数组,如mysql程序使用的"[mysql]",mysqlchk使用的"[mysqlchk]"等等.如果读者朋友自己编写了某个客户端程序,也可以自己设定一个参数组名,将相关参数配置在里面,然后调用mysql客户端api程序中的参数读取api读取相关参数.
			2、pid file:mysqld应用程序在Unix/Linux环境下的一个进程文件,和许多其他Unix/Linux服务端程序一样,存放着自己的进程id.
			3、socket file文件也是在Unix/Linux环境下才有的,用户在Unix/Linux环境下客户端连接可以不通过TCP/IP网络而直接使用Unix Socket来连接MySQL
	2.MySQL系统架构(可以看成是二层架构)
		1.我们通常叫做SQL Layer,在MySQL数据库系统处理底层数据之前的所有工作都是在这一层完成的,包括权限判断,sql解析,执行计划优化,query cache的处理等等
			1、初始化模块
				顾名思议,初始化模块就是在MySQL Server启动的时候,对整个系统做各种各样的初
				始化操作,比如各种 buffer,cache 结构的初始化和内存空间的申请,各种系统变量的初始
				化设定,各种存储引擎的初始化设置,等等
			2、核心 API
				核心 API 模块主要是为了提供一些需要非常高效的底层操作功能的优化实现,包括各种
				底层数据结构的实现,特殊算法的实现,字符串处理,数字处理等,小文件 I/O,格式化输
				出,以及最重要的内存管理部分,核心 API 模块的所有源代码都集中在 mysys 和 strings
				文件夹下面,有兴趣的读者可以研究研究
			3、网络交互模块
				底层网络交互模块抽象出底层网络交互所使用的接口 api,实现底层网络数据的接收与
				发送,以方便其他各个模块调用,以及对这一部分的维护,所有源码都在 vio 文件夹下面
			4、Client & Server 交互协议模块
				任何 C/S 结构的软件系统,都肯定会有自己独有的信息交互协议,MySQL 也不例外,MySQL
				的 Client & Server 交互协议模块部分,实现了客户端与 MySQL 交互过程中的所有协议
				当然这些协议都是建立在现有的 OS 和网络协议之上的,如 TCP/IP 以及 Unix Socket
			5、用户模块
				用户模块所实现的功能,主要包括用户的登录连接权限控制和用户的授权管理,他就像
				MySQL 的大门守卫一样,决定是否给来访者“开门”
			6、访问控制模块
				造访客人进门了就可以想干嘛就干嘛么？为了安全考虑,肯定不能如此随意,这时候就
				需要访问控制模块实时监控客人的每一个动作,给不同的客人以不同的权限,访问控制模块
				实现的功能就是根据用户模块中各用户的授权信息,以及数据库自身特有的各种约束,来控
				制用户对数据的访问,用户模块和访问控制模块两者结合起来,组成了 MySQL 整个数据库系
				统的权限安全管理的功能
			7、连接管理、连接线程和线程管理
				连接管理模块负责监听对 MySQL Server 的各种请求,接收连接请求,转发所有连接请
				求到线程管理模块,每一个连接上 MySQL Server 的客户端请求都会被分配（或创建）一个
				连接线程为其单独服务,而连接线程的主要工作就是负责 MySQL Server 与客户端的通信
				接受客户端的命令请求,传递 Server 端的结果信息等,线程管理模块则负责管理维护这些
				连接线程,包括线程的创建,线程的 cache 等
			8、Query 解析和转发模块
				在 MySQL 中我们习惯将所有 Client 端发送给 Server 端的命令都称为 query,在 MySQL
				Server 里面,连接线程接收到客户端的一个 Query 后,会直接将该 query 传递给专门负责
				将各种 Query 进行分类然后转发给各个对应的处理模块,这个模块就是 query 解析和转发模
				块,其主要工作就是将 query 语句进行语义和语法的分析,然后按照不同的操作类型进行分
				类,然后做出针对性的转发
			9、Query Cache 模块
				Query Cache 模块在 MySQL 中是一个非常重要的模块,他的主要功能是将客户端提交给
				MySQL 的 Select 类 query 请求的返回结果集 cache 到内存中,与该 query 的一个 hash 值做
				一个对应,该 Query 所取数据的基表发生任何数据的变化之后,MySQL 会自动使该 query 的
				Cache 失效,在读写比例非常高的应用系统中,Query Cache 对性能的提高是非常显著的
				当然它对内存的消耗也是非常大的
			10、Query 优化器模块
				Query 优化器,顾名思义,就是优化客户端请求的 query,根据客户端请求的 query 语
				句,和数据库中的一些统计信息,在一系列算法的基础上进行分析,得出一个最优的策略
				告诉后面的程序如何取得这个 query 语句的结果
			11、表变更管理模块
				表变更管理模块主要是负责完成一些 DML 和 DDL 的 query,如:update,delte,insert
				create table,alter table 等语句的处理
			12、表维护模块
				表的状态检查,错误修复,以及优化和分析等工作都是表维护模块需要做的事情
			13、系统状态管理模块
				系统状态管理模块负责在客户端请求系统状态的时候,将各种状态数据返回给用户,像
				DBA 常用的各种 show status 命令,show variables 命令等,所得到的结果都是由这个模块
				返回的
			14、表管理器
				这个模块从名字上看来很容易和上面的表变更和表维护模块相混淆,但是其功能与变更
				及维护模块却完全不同,大家知道,每一个 MySQL 的表都有一个表的定义文件,也就是*.frm
				文件,表管理器的工作主要就是维护这些文件,以及一个 cache,该 cache 中的主要内容是
				各个表的结构信息,此外它还维护 table 级别的锁管理
			15、日志记录模块
				日志记录模块主要负责整个系统级别的逻辑层的日志的记录,包括 error log,binary
				log,slow query log 等
			16、复制模块
				复制模块又可分为 Master 模块和 Slave 模块两部分,Master 模块主要负责在
				Replication 环境中读取 Master 端的 binary 日志,以及与 Slave 端的 I/O 线程交互等工作 
				Slave 模块比 Master 模块所要做的事情稍多一些,在系统中主要体现在两个线程上面,一
				个是负责从 Master 请求和接受 binary 日志,并写入本地 relay log 中的 I/O 线程,另外一
				个是负责从 relay log 中读取相关日志事件,然后解析成可以在 Slave 端正确执行并得到和
				Master 端完全相同的结果的命令并再交给 Slave 执行的 SQL 线程
			17、存储引擎接口模块
				存储引擎接口模块可以说是 MySQL 数据库中最有特色的一点了,目前各种数据库产品
				中,基本上只有 MySQL 可以实现其底层数据存储引擎的插件式管理,这个模块实际上只是一
				个抽象类,但正是因为它成功地将各种数据处理高度抽象化,才成就了今天 MySQL 可插拔存
				储引擎的特色
		2.就是存储引擎层,我们通常叫做Storage Engine Layer ,也就是底层数据存取操作实现部分,由多种存储引擎共同组成
	3.MySQL执行过程
		1.启动 MySQL 命令之后,MySQL的初始化模块就从系统配置文件中读取系统参数和命令行参数,并按照参数来初始化整个系统,如申请并分配 buffer,初始化全局变量,以及各种结构等,同时各个存储引擎也被启动,并进行各自的初始化工作,当整个系统初始化结束后,由连接管理模块接手,连接管理模块会启动处理客户端连接请求的监听程序,包括 tcp/ip 的网络监听,还有 unix 的 socket,这时候基本启动完成,准备好接受客户端请求了
		2.当连接管理模块监听到客户端的连接请求（借助网络交互模块的相关功能）,双方通过Client & Server 交互协议模块所定义的协议“寒暄”几句之后,连接管理模块就会将连接请求转发给线程管理模块,去请求一个连接线程
		3.连接线程模块在接到连接请求后,首先会检查当前连接线程池中是否有被 cache 的空闲连接线程,如果有,就取出一个和客户端请求连接上,如果没有空闲的连接线程,则建立一个新的连接线程与客户端请求连接(连接线程模块并不是在收到连接请求后马上就会取出一个连接线程连和客户端连接,而是首先通过调用用户模块进行授权检查,只有客户端请求通过了授权检查后,他才会将客户端请求和负责请求的连接线程连上)
		4.连接线程就开始处理客户端请求发送过来的各种命令（或者 query）,接受相关请求。它将收到的 query 语句转给Query解析和转发模块,Query解析器先对Query进行基本的语义和语法解析,然后根据命令类型的不同,有些会直接处理,有些会分发给其他模块来处理
		5.如果是一个 Query 类型的请求,会将控制权交给 Query 解析器。Query 解析器首先分析看是不是一个 select 类型的 query,如果是,则调用查询缓存模块,让它检查该 query 在query cache 中是否已经存在。如果有,则直接将 cache 中的数据返回给连接线程模块,然后通过与客户端的连接的线程将数据传输给客户端。如果不是一个可以被 cache 的 query类型,或者 cache 中没有该 query 的数据,那么 query 将被继续传回 query 解析器,让 query解析器进行相应处理,再通过 query 分发器分发给相关处理模块。
		6.如果解析器解析结果是一条未被 cache 的 select 语句,则将控制权交给 Optimizer,也就是 Query 优化器模块,如果是 DML 或者是 DDL 语句,则会交给表变更管理模块,如果是一些更新统计信息、检测、修复和整理类的 query 则会交给表维护模块去处理,复制相关的query 则转交给复制模块去进行相应的处理,请求状态的 query 则转交给了状态收集报告模块。实际上表变更管理模块根据所对应的处理请求的不同,是分别由 insert 处理器、delete处理器、update 处理器、create 处理器,以及 alter 处理器这些小模块来负责不同的 DML和 DDL
		7.在各个模块收到 Query 解析与分发模块分发过来的请求后,首先会通过访问控制模块检查连接用户是否有访问目标表以及目标字段的权限,如果有,就会调用表管理模块请求相应的表,并获取对应的锁。表管理模块首先会查看该表是否已经存在于 table cache 中,如果已经打开则直接进行锁相关的处理,如果没有在 cache 中,则需要再打开表文件获取锁,然后将打开的表交给表变更管理模块
		8.当表变更管理模块“获取”打开的表之后,就会根据该表的相关 meta 信息,判断表的存储引擎类型和其他相关信息。根据表的存储引擎类型,提交请求给存储引擎接口模块,调用对应的存储引擎实现模块,进行相应处理
		<span class="image featured"><img src="{{ 'assets/images/other/mysql-base.jpg' | relative_url }}" alt="" /></span>
	4.MySQL提供的一些客户端(bin目录下的,mysql也是属于一种客户端)
	5.MySQL存储引擎
		1.MyISAM
			B-Tree 索引:顾名思义,就是所有的索引节点都按照 balance tree 的数据结构来
			存储,所有的索引数据节点都在叶节点。
			R-Tree 索引:存储方式和 b-tree 索引有一些区别,主要设计用于为存储空间和多
			维数据的字段做索引,所以目前的 MySQL 版本来说,也仅支持 geometry 类型的字段作索引。 
			Full-text 索引:就是我们长说的全文索引,他的存储结构也是 b-tree.主要是为了
			解决在我们需要用 like 查询的低效问题
		2.Innodb
			由于 Innodb 是事务安全的存储引擎,所以系统 Crash 对他来说并不能造成非常严重的损失,由于有 redo 日志的存在,有 checkpoint 机制的保护,Innodb 完全可以通过 redo 日志将数据库 Crash 时刻已经完成但还没有来得及将数据写入磁盘的事务恢复,也能够将所有部分完成并已经写入磁盘的未完成事务回滚并将数据还原。
		3.Memory
			不会将任何数据存放到磁盘上,仅仅存放了一个表结构相关信息的.frm 文件在磁盘上面由于是存放在内存中,所以 Memory 都是按照定长的空间来存储数据的,而且不支持 BLOB 和 TEXT类型的字段。Memory 存储引擎实现页级锁定
		4.NDB
			也叫 NDB Cluster 引擎,主要用于 MySQL Cluster 分布式集群环境,Cluster 是 MySQL 从 5.0 版本才开始提供的新功能。这部分我们可能并不仅仅只是介绍 NDB存储引擎,因为离开了 MySQL CLuster 整个环境,NDB 存储引擎也将失去太多意义
		5.Merge
			可以简单的理解为其功能就是实现了对结构相同的MyISAM表,通过一些特殊的包装对外提供一个单一的访问入口,以达到减小应用的复杂度的目的
		6.BDB
			全称为 BerkeleyDB 存储引擎支持事务安全,数据存放也是每个表两个物理文件,一个.frm 和一个.db 的文件,数据和索引信息都是存放在.db 文件中。此外,BDB 为了实现事务安全,也有自己的 redo 日 志 ,和 Innodb 一样,也可以通过参数指定日志文件存放的位置。在锁定机制方面,BDB 和 Memory存储引擎一样,实现页级锁定
		7.CSV
			存储引擎实际上操作的就是一个标准的 CSV 文件,他不支持索引。起主要用途就是大家有些时候可能会需要通过数据库中的数据导出成一份报表文件,通过先在数据库中建立一张 CVS 表,然后将生成的报表信息插入到该表,即可得到一份 CSV 报表文件了
	6.权限
		流程:
		<span class="image featured"><img src="{{ 'assets/images/other/mysql-base-grant.jpg' | relative_url }}" alt="" /></span>
		当执行SQL的时候,验证权限从Global Level->Database Level(按照User,Db,Host依次由精到略进行权限验证,如果不满足则直接返回没有权限)->Table Level->Column Leve依次进行验证,如果满足权限,则不用验证后面的登记权限
		1.GRANT SELECT,UPDATE,DELETE,INSERT ON *.* TO 'def'@'localhost'
		2.先通过USE命令选定需要授权的数据库,然后通过"*"来限定作用域,这样授权的作用域实际上就是当前选定的整个数据库
		3.如果该用户在该表中某列上面没有 INSERT 权限,则该列的数据将以默认值填充
		更新权限后生效时间:
			对于 Global Level 的权限信息的修改,仅仅只有更改之后新建连接才会用到,对于已经连接上的 session 并不会受到影响。而对于 Database Level 的权限信息的修改,只有当客户端请求执行了“USE database_name”命令之后,才会在重新校验中使用到新的权限信息。所以有些时候如果在做了比较紧急的Global和 Database这两个Level 的权限变更之后 ,可能需要通过“KILL”命令将已经连接在 MySQL 中的 session 杀掉强迫他们重新连接以使用更新后的权限。对于 Table Level 和 Column Level 的权限,则会在下一次需要使用到该权限的 Query 被请求的时候生效,也就是说,对于应用来讲,这两个 Level 的权限,更新之后立刻就生效了,而不会需要执行“KILL”命令
	7.备份
		1.通过mysqldump
		2.直接复制文件
	8.锁定机制
		在 MySQL数据库中,使用表级锁定的主要是MyISAM,Memory,CSV等一些非事务性存储引擎,而使用行级锁定的主要是 Innodb 存储引擎和 NDB Cluster 存储引擎,页级锁定主要是 BerkeleyDB 存储引擎的锁定方式
		1.行级锁定(锁定颗粒度最小的,带来的消耗自然也就更大了,此外,行级锁定也最容易发生死锁)
			行级锁定不是 MySQL 自己实现的锁定方式,而是由其他存储引擎自己所实现的如Innodb
			Innodb行级锁定同样分为两种类型,共享锁和排他锁
			间隙锁基于非唯一索引,它锁定一段范围内的索引记录。间隙锁基于下面将会提到的Next-Key Locking 算法,请务必牢记:使用间隙锁锁住的是一个区间,而不仅仅是这个区间中的每一条数据
			是通过在指向数据记录的第一个索引键之前和最后一个索引键之后的空域空间上标记锁定信息而实现的。
			(无索引升级为表锁)
		2.表级锁定(最大颗粒度的锁定机制,锁定资源争用的概率也会最高,致使并大度大打折扣)
			lock table test_table write(read) 写锁(读锁)
			MySQL 的表级锁定主要分为两种类型,一种是读锁定,另一种是写锁定(但是在MySQL内部实现中却有多达11 种锁定类型)。在 MySQL 中,主要通过四个队列来维护这两种锁定:两个存放当前正在锁定中的读和写锁定信息,另外两个存放等待中的读写锁定信息
			• Current read-lock queue (lock->read)
			• Pending read-lock queue (lock->read_wait)
			• Current write-lock queue (lock->write)
			• Pending write-lock queue (lock->write_wait)
			一个新的客户端请求在申请获取读锁定资源的时候,需要满足两个条件:
				1、 请求锁定的资源当前没有被写锁定；
				2、 写锁定等待队列（Pending write-lock queue）中没有更高优先级的写锁定等待；
				如果满足了上面两个条件之后,该请求会被立即通过,并将相关的信息存入 Current read-lock queue 中,而如果上面两个条件中任何一个没有满足,都会被迫进入等待队列 Pending read-lock queue 中等待资源的释放
			当客户端请求写锁定的时候,MySQL 首先检查在 Current write-lock queue 是否已经有锁定相同资源的信息存在。
			读请求和写等待队列中的写锁请求的优先级规则主要为以下规则决定:
				1. 除了 READ_HIGH_PRIORITY 的读锁定之外,Pending write-lock queue 中的 WRITE 写锁定能够阻塞所有其他的读锁定；
				2. READ_HIGH_PRIORITY 读锁定的请求能够阻塞所有 Pending write-lock queue 中的写锁定；
				3. 除了 WRITE 写锁定之外,Pending write-lock queue 中的其他任何写锁定都比读锁定的优先级低。
		3.页级锁定(不常见)
	9.MySQL Query Optimizer(优化 SELECT 语句的优化器模块)
		小结果集驱动大结果集
		A表100条数据,B表10条数据
		select * from A left join B A.userid=B.userid
		这样则需要用A表循环100次才能查询出来,而如果用B表驱动A表则只需要循环10次就能查询出来如:
		select * from B left join A B.userid=A.userid
		多使用EXPLAIN + PROFILES来优化
			show PROFILES;
			show profile cpu, block io for query 1
	10.索引
		注:
			1.InnoDB会自动帮你创建一个不可见的、长度为6字节的row_id,而且这个row_id是由InnoDB维护全局的dictsys.row_id
			2.外键是需要代价的:即时检查,逐行进行每次修改时都要对另外一张表多一次select操作,使用select lock in share mode方式 这将导致更多的锁等待,甚至是死锁,因为关联到其他表
		B-tree
			所有实际需要的数据都存放于Tree的LeafNode,而且到任何一个LeafNode的最短路径的长度都是完全相同的
		Hash(主要是 Memory 存储引擎使用)
			就是通过一定的Hash算法,将需要索引的键值进行Hash运算,然后将得到的Hash值存入一个Hash表中.然后每次需要检索的时候,都会将检索条件进行相同算法的Hash运算,然后再和Hash表中的Hash值进行比较并得出相应的信息.在Memory存储引擎中,MySQL还支持非唯一的Hash索引.存储引擎会将他们链接到同一个hash键值下以一个链表的形式存在,然后在取得实际键值的时候时候再过滤不符合的键
			注:
				1.仅能使用'=','IN','<=>'查询,不能使用范围查询
				2.排序问题
				3.对于组合索引,Hash 索引在计算 Hash 值的时候是组合索引键合并之后再一起计算Hash值,而不是单独计算Hash值,所以当我们通过组合索引的前面一个或几个索引键进行查询的时候,Hash索引也无法被利用到
				4.Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高
		Full-Text(全文索引)
			目前在MySQL中仅有MyISAM存储引擎支持,而且也并不是所有的数据类型都支持全文索引.目前来说,仅有CHAR,VARCHAR和TEXT
			注:
				中文支持方面还不太好,需要借助第三方的补丁或者插件来完成.而且Full-text的创建所消耗的资源也是比较大的
		注:
			1.explain select id from user where `name` !=/<=>(或者不带=) '安慰' 正常我们都会说不等式用不到索引的,但是根据索引特点,上面还是可以用到idx_name的
			2.如果MySQL Query Optimizer选择的索引不是最好的,可以手动使用指定索引EXPLAIN SELECT * FROM table FORCE INDEX(idx_name) WHERE ...
	11.数据页
		数据页是InnoDB磁盘管理的最小的数据单位,数据页的默认大小为16KB
	12.join查询
		1、永远用小结果集驱动大结果集(其本质就是减少外层循环的数据数量)
		2、为匹配的条件增加索引(减少内层表的循环匹配次数)
		3、增大join buffer size的大小(一次缓存的数据越多,那么内层包的扫表次数就越少)
		4、减少不必要的字段查询(字段越少,join buffer 所缓存的数据就越多)
	13.group分组
		索引字段(group_id,user_id,gmt_create)
		1.如果查询为 SELECT user_id,max(gmt_create) FROM group_message WHERE group_id < 10 GROUP BY group_id,user_id
			流程为:
				1.some of group_id
				2.scan one time every duplicate user_id in same group_id
				3.jump to last gmt_create in same user_id
			要利用到松散索引扫描实现GROUP BY:
				1.GROUP BY 条件字段必须在同一个索引中最前面的连续位置
				2.在使用 GROUP BY 的同时,只能使用 MAX 和 MIN 这两个聚合函数
				3.如果引用到了该索引中 GROUP BY 条件之外的字段条件的时候,必须以常量形式存在
		2.如果查询为 SELECT max(gmt_create) FROM group_message WHERE group_id = 2 GROUP BY user_id
			流程为:
				1.all of group_id // group_id = 2
				2.all of user_id , gmt_create that group_id = 2
				3.return last gmt_create at every duplicate user_id
			当GROUP BY 条件字段并不连续或者不是索引前缀部分的时候,无法使用松散索引扫描,但如果 Query 语句中存在一个常量值来引用缺失的索引键,则可以使用紧凑索引扫描
		3.如果查询为 SELECT max(gmt_create) FROM group_message WHERE group_id > 1 and group_id < 10 GROUP BY user_id
			只能先通过索引范围扫描得到需要的数据,然后将数据存入临时表,然后再进行排序和分组操作来完成 GROUP BY
		对于上面三种MySQL处理GROUP BY的方式,我们可以针对性的得出如下两种优化思路:
			1.尽可能让MySQL可以利用索引来完成GROUP BY操作,当然最好是松散索引扫描的方式最佳,在系统允许的情况下,我们可以通过调整索引或者调整Query这两种方式来达到目的
			2.当无法使用索引完成GROUP BY的时候,由于要使用到临时表且需要filesort,所以我们必须要有足够的sort_buffer_size来供MySQL排序的时候使用,而且尽量不要进行大结果集的GROUP BY操作,因为如果超出系统设置的临时表大小的时候会出现将临时表数据copy到磁盘上面再进行操作,这时候的排序分组操作性能将是成数量级的下降
	14.distinct去重
		DISTINCT 的实现和 GROUP BY 的实现也基本差不多,没有太大的区别。同样可以通过松散索引扫描或者是紧凑索引扫描来实现,当然,在无法仅仅使用索引即能完成 DISTINCT 的时候,MySQL只能通过临时表来完成。但是,和 GROUP BY 有一点差别的是,DISTINCT 并不需要进行排序。
	15.优化复制
		MySQL复制环境中,实际上是是有 8 个参数可以让我们控制需要复制或者需要忽略而不进行复制的 DB 或 者 Table 的,分别为:
			1.Binlog_Do_DB(Master端):设定哪些数据库（Schema）需要记录 Binlog
			2.Binlog_Ignore_DB(Master端):设定哪些数据库（Schema）不要记录 Binlog
			3.Replicate_Do_DB(Slave端):设定需要复制的数据库（Schema）,多个 DB 用逗号（“,”）分隔
			4.Replicate_Ignore_DB(Slave端):设定可以忽略的数据库（Schema）
			5.Replicate_Do_Table(Slave端):设定需要复制的 Table
			6.Replicate_Ignore_Table(Slave端):设定可以忽略的 Table
			7.Replicate_Wild_Do_Table(Slave端):功能同 Replicate_Do_Table,但可以带通配符来进行设置
			8.Replicate_Wild_Ignore_Table(Slave端):功能同 Replicate_Ignore_Table,可带通配符设置
	16.Query Cache优化
		客户端请求的 Query 语句（当然仅限于 SELECT 类型的 Query）通过一定的 hash 算法进行一个计算而得到一个 hash 值,存放在一个 hash 桶中。同时将该 Query 的结果集（Result Set）也存放在一个内存 Cache 中的。存放 Query hash 值的链表中的每一个 hash 值所在的节点中同时还存放了该 Query 所对应的 Result Set 的 Cache 所在的内存地址,以及该 Query 所涉及到的所有 Table 的标识等其他一些相关信息。系统接受到任何一个SELECT 类型的 Query 的时候,首先计算出其 hash 值,然后通过该 hash 值到 Query Cache 中去匹配,如果找到了完全相同的 Query,则直接将之前所 Cache 的 Result Set 返回给客户端而完全不需要进行后面的任何步骤即可完成这次请求。而后端的任何一个表的任何一条数据发生变化之后,也会通知 Query Cache,需要将所有与该 Table 有关的 Query 的 Cache 全部失效,并释放出之前占用的内存地址,以便后面其他的 Query 能够使用。
		“query_cache_limit”参数值来控制 Query Cache 中所 Cache 的最大 Result Set ,系统默认为1M（1048576）。当某个 Query 的 Result Set 大于“query_cache_limit”所设定的值的时候,Query Cache 是不会 Cache 这个 Query 的
	17.恢复通过现有 Slave 所得到的热备份
		CHANGE MASTER TO
		-> MASTER_HOST='192.168.0.1',
		-> MASTER_USER='repl',
		-> MASTER_PASSWORD='password',
		-> MASTER_LOG_FILE='mysql-bin.000035',
		-> MASTER_LOG_POS=399;
		执行完 CHANGE MASTER TO 命令之后，就可以通过如下命令启动 SLAVE 了：
		root@localhost : mysql 08:33:49> START SLAVE;
</pre>