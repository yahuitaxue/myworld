
.1]---
title: 面试总结
author: Yahui
layout: Other
category: Other
---

书名:《-》

<pre style="text-align: left;">
CPU
	从逻辑上可以分为 3 个模块,分别是
		控制单元
		运算单元
		存储单元
	几乎所有的冯·诺伊曼型计算机的CPU,其工作都可以分为5个阶段:「取指令、指令译码、执行指令、访存取数、结果写回」.
		取指令阶段:
			是将内存中的指令读取到 CPU 中寄存器的过程,程序寄存器用于存储下一条指令所在的地址
		指令译码阶段:
			在取指令完成后,立马进入指令译码阶段,在指令译码阶段,指令译码器按照预定的指令格式,对取回的指令进行拆分和解释,识别区分出不同的指令类别以及各种获取操作数的方法.
		执行指令阶段:
			译码完成后,就需要执行这一条指令了,此阶段的任务是完成指令所规定的各种操作,具体实现指令的功能.
		访问取数阶段:
			根据指令的需要,有可能需要从内存中提取数据,此阶段的任务是:根据指令地址码,得到操作数在主存中的地址,并从主存中读取该操作数用于运算.
		结果写回阶段:
			作为最后一个阶段,结果写回（Write Back,WB）阶段把执行指令阶段的运行结果数据写回到 CPU 的内部寄存器中,以便被后续的指令快速地存取；
web安全
	CSRF(跨站请求伪造)
		攻击方式
			1.登录受信任网站A，并在本地生成Cookie。（如果用户没有登录网站A，那么网站B在诱导的时候，请求网站A的api接口时，会提示你登录）
			2.在不登出A的情况下，访问危险网站B（其实是利用了网站A的漏洞）。
			3.在B网站的诱导下，点击跳转到A网站（带有不安全参数），这样就获取到A网站的信息
			注意cookie保证了用户可以处于登录状态，但网站B其实拿不到cookie。
		造成的结果
			CRSF能做的事情包括利用你的身份发邮件、发短信、进行交易转账等，甚至盗取你的账号，更新账号细节，完成购物，注销甚至登录等操作，获取用户的隐私数据
		防护
			1.将cookie设置为HttpOnly
				CRSF攻击很大程度上是利用了浏览器的cookie，为了防止站内的XSS漏洞盗取cookie,需要在cookie中设置“HttpOnly”属性，这样通过程序（如JavaScript脚本、Applet等）就无法读取到cookie信息，避免了攻击者伪造cookie的情况出现。设置cookie为HttpOnly的代码如下：response.setHeader( "Set-Cookie", "cookiename=cookievalue;HttpOnly");
			2.Token 验证(用的最多)
			3.隐藏令牌：把token隐藏在http的head头中(与2机制相同)
			4.Referer验证
				只接受本站的请求，服务器才做响应；如果不是，就拦截。
	XSS(跨域脚本攻击)
		攻击方式
			1.盗用Cookie破坏页面的正常结构，插入广告等恶意内容
			2.发出请求时，XSS代码出现在url中，作为输入提交到服务器端，服务器端解析后响应，XSS代码随响应内容一起传回给浏览器，最后浏览器解析执行XSS代码
		防护
			1.encode+过滤
	SQL注入
		攻击方式
			传入的“数据”拼接到SQL语句中后，被当作SQL语句的一部分执行
		防护
			1.转译
				addslashes
			2.PDO
				$pdo->prepare('select * from biao1 where id=:id');
				$pdo->execute([':id'=>4]);
				语句一，服务器发送一条sql给mysql服务器，mysql服务器会解析这条sql。
				语句二，服务器发送一条sql给mysql服务器，mysql服务器不会解析这条sql，只会把execute的参数当做纯参数赋值给语句一。哪怕参数中有sql命令也不会被执行，从而实现防治sql注入。
socket连接：
	socket不属于协议范畴,而是一个调用接口（API）,是对TCP/IP协议的封装。实现服务器与客户端之间的物理连接,并进行数据传输。Socket处于网络协议的传输层,主要有TCP/UDP两个协议（当然也有TCP/IP协议族中其他的协议）。
	socket连接是长连接,理论上客户端和服务器端一旦建立起连接将不会主动断掉；但是由于各种环境因素可能会使连接断开,比如：服务器端或客户端主机宕机了、网络故障,或者两者之间长时间没有数据传输,网络防火墙可能会断开该连接以释放网络资源。所以当一个socket连接中没有数据的传输,那么为了维持连接需要发送心跳消息。
	socket传输的数据可自定义,为字节级,数据量小,可以加密,数据安全性高,适合Client/Server之间信息实时交互。
http连接：
	HTTP是基于TCP/IP协议的应用层协议,定义的是传输数据的内容的规范。
	HTTP是基于请求-响应形式并且是短连接,即客户端向服务器端发送一次请求,服务器端响应后连接即会断掉。
	HTTP是无状态的协议,针对其无状态特性,在实际应用中又需要有状态的形式,因此一般会通过session/cookie技术来解决此问题。
	HTTP的传输速度慢,数据包大,数据传输安全性差,如实现实时交互,服务器性能压力大。
PHP
	__autoload自动加载
		如果调用某个未经include或require的类,在报错之前,系统会调用__autoload($className)函数,并把类名传给自动加载类函数,就可以在里面加载需要的类.
		缺点:
			假如需要使用很多其它的类库,就必须在__autoload()函数中将所有的映射规则全部实现,因此函数有可能会非常复杂,甚至无法实现.最后可能会导致函数十分臃肿,这时即便能够实现,也会给将来的维护和系统效率带来很大的负面影响
	spl_autoload_register自动加载
		1.调用spl_autoload_register()函数,当调用未定义类时,系统会按顺序调用注册到spl_autoload_register()函数的所有函数,而不是自动调用__autoload()函数
			spl_autoload_register(function($className){
				echo 'spl autoload自动加载1', $className;
			});
			spl_autoload_register(function($className){
				echo 'spl autoload自动加载2', $className;
			});
			$myClass1 = new MyClass1();
		2.调用spl_autoload_register()函数以注册一个回调函数,而不是为函数提供一个字符串名称.如提供一个如array('class','method')这样的数组,使得可以使用某个对象的方法
			// 静态方法
			class MyClass 
			{
				public static function autoload($className) 
				{
					echo 'class autoload自动加载', $className;
				}
			}
			spl_autoload_register(array('MyClass', 'autoload'));
		例
			入口文件AutoLoader.php调用(PHPExcel_Autoloader::register())
			class PHPExcel_Autoloader
			{
			    /**
			     * Register the Autoloader with SPL
			     *
			     */
			    public static function register()
			    {
			        if (function_exists('__autoload')) {
			            // Register any existing autoloader function with SPL, so we don't get any clashes
			            spl_autoload_register('__autoload');
			        }
			        // Register ourselves with SPL
			        if (version_compare(PHP_VERSION, '5.3.0') >= 0) {
			            return spl_autoload_register(array('PHPExcel_Autoloader', 'load'), true, true);
			        } else {
			            return spl_autoload_register(array('PHPExcel_Autoloader', 'load'));
			        }
			    }
			    /**
			     * Autoload a class identified by name
			     *
			     * @param    string    $pClassName        Name of the object to load
			     */
			    public static function load($pClassName)
			    {
			        if ((class_exists($pClassName, false)) || (strpos($pClassName, 'PHPExcel') !== 0)) {
			            // Either already loaded, or not a PHPExcel class request
			            return false;
			        }
			        $pClassFilePath = PHPEXCEL_ROOT .
			            str_replace('_', DIRECTORY_SEPARATOR, $pClassName) .
			            '.php';
			        if ((file_exists($pClassFilePath) === false) || (is_readable($pClassFilePath) === false)) {
			            // Can't load
			            return false;
			        }
			        require($pClassFilePath);
			    }
			}
	常见异常
		502 Bad Gateway
			在php.ini和php-fpm.conf中分别有这样两个配置项:max_execution_time和request_terminate_timeout. 这两项都是用来配置一个PHP脚本的最大执行时间的.当超过这个时间时,PHP-FPM不只会终止脚本的执行,还会终止执行脚本的Worker进程.所以Nginx会发现与自己通信的连接断掉了,就会返回给客户端502错误.
		504 Gateway Time-out
			由于程序执行时间过长导致响应超时,例如程序需要执行90秒,而nginx最大响应等待时间为30秒,这样就会出现超时.
			PHP-FPM设置的脚本最大执行时间已经够长了,但执行耗时PHP脚本时,发现Nginx报错从502变为504了.这是为什么呢？
			因为我们修改的只是PHP的配置,Nginx中也有关于与上游服务器通信超时时间的配置factcgi_connect/read/send_timeout.
			# fastcgi连接超时时间,默认60秒
			fastcgi_connect_timeout 
			# nginx 进程向 fastcgi 进程发送请求过程的超时时间,默认值60秒
			fastcgi_send_timeout 
			# fastcgi 进程向 nginx 进程发送输出过程的超时时间,默认值60秒 
			fastcgi_read_timeout
	反射
		注解路由使路由定义更为方便,但PHP本身没有类似于Java的Annotation机制,那是如何实现的呢？这就不得不说到PHP的反射机制.
			通过反射类获取类的所有public方法；
			分析每个public方法的文档注释,如果含有特定路由标志,则将该方法作为路由处理函数
	生成器
		注:
			生成器函数中出现的 yield,首先它都是语句,而跟在 yield 后面的任何表达式的值将作为调用生成器函数的返回值,如果 yield 后面没有任何表达式（变量、常量都是表达式）,那么它会返回 NULL,这一点和 return 语句一致.
		实例:
			function createRange($number){
			    for($i=0;$i<$number;$i++){
			        yield time();
			    }
			}
			$result = createRange(10); // 这里调用上面我们创建的函数
			foreach($result as $value){
			    sleep(1);
			    echo $value;
			}
			// 这里会每一秒输出一次,而不是像return一样,一下子输出
			1.首先调用 createRange 函数,传入参数10,但是 for 值执行了一次然后停止了,并且告诉 foreach 第一次循环可以用的值.
			2.foreach 开始对 $result 循环,进来首先 sleep(1) ,然后开始使用 for 给的一个值执行输出.
			3.foreach 准备第二次循环,开始第二次循环之前,它向 for 循环又请求了一次.
			4.for 循环于是又执行了一次,将生成的时间戳告诉 foreach .
			5.foreach 拿到第二个值,并且输出.由于 foreach 中 sleep(1) ,所以, for 循环延迟了1秒生成当前时间
	写入拷贝
		如果有多个调用者同时要求相同资源（如内存或磁盘上的数据存储）,他们会共同获取相同的指针指向相同的资源,直到某个调用者试图修改资源的内容时,系统才会真正复制一份专用副本给该调用者
		PHP变量的定义
			struct _zval_struct {
			    zvalue_value value;      /*注意这里,这个里面存的才是变量的值*/
			    zend_uint refcount__gc;  /*引用计数*/
			    zend_uchar type;        /* 变量当前的数据类型 */
			    zend_uchar is_ref__gc;   /*变量是否引用*/
			};
			// 可以打印$i的结构
			xdebug_debug_zval('i');
			i: (refcount=0, is_ref=0)=4
	依赖注入
		(Closure,匿名函数,是php5.3的时候引入的,又称为Anonymous functions.字面意思也就是没有定义名字的函数.比如以下代码(文件名是do.php))
		class Ioc {
		    /**
		     * @var array 注册的依赖数组
		     */
		    protected static $registry = array();
		 
		    /**
		     * 添加一个 resolve （匿名函数）到 registry 数组中
		     *
		     * @param string  $name    依赖标识
		     * @param Closure $resolve 一个匿名函数,用来创建实例
		     * @return void
		     */
		    public static function register($name, Closure $resolve) {
		        static::$registry[$name] = $resolve;
		    }
		    ...
		}
		Ioc::register("book", function () {
		    $book = new Book();
		    $book->setdb('db');
		    $book->setfile('file');
		    return $book;
		});
		// 注入依赖
		$book = Ioc::resolve('book');
	安全
		1.减少PHP模块(修改PHP配置文件)
		2.隐藏PHP版本信息(可以禁用expose_php配置项隐藏X-Powered-By信息:expose_php = Off)
		3.禁用远程执行代码(通过file_get_content或者fopen函数,可以从远程获取数据,操作不当会出现漏洞,可以禁用allow_url_fopen配置项:allow_url_fopen=Off)
		4.限制PHP访问文件系统(open_basedir配置项可以指定允许PHP访问的目录:open_basedir = "/www/websites/www/gitlib/")
		5.禁用全局变量自动注册(PHP会根据register_globals配置项,判断是否将$_GET|$_POST|$_COOKIE|$_ENV|$_SERVER|$REQUEST等数组变量里的内容自动注册为全局变量:register_globals = Off)
	htmlspecialchars
		把预定义的字符转换为 HTML 实体。
			Bill & 'Steve' => Bill &amp; 'Steve'(通过修改第二个参数,来实现单/双引号是否转换)
	addslashes
		在每个双引号（"）前添加反斜杠
MySQL
	binlog
		以事件形式记录,还包含语句所执行的消耗的时间,MySQL的二进制日志是事务安全型的。
		binlog日志包括两类文件：
			二进制日志索引文件(文件名后缀为.index)用于记录所有的二进制文件。
			二进制日志文件(文件名后缀为.00000)记录数据库所有的DDL和DML(除了数据查询语句select)语句事件。
		流程
			事务执行过程中,binlog 首先会被写到 binlog cache 中；事务提交的时候,再将binlog cache 写到 binlog 文件中。一个事务的 binlog 是原子的,无论多大都需要保证完整性。
			系统为每个客户端线程分配一个 binlog cache,其大小由 binlog_cache_size 控制。如果binlog cache 超过阀值,就会临时持久化到磁盘。当事务提交的时候,再将 binlog cache 中完整的事务持久化到磁盘中,并清空 binlog cache。
			每个客户端线程都有自己独立的 binlog cache,但是会共享一份 binlog files。
		刷新日志
			flush logs; // 刷新log日志,自此刻开始产生一个新编号的binlog日志文件;
			reset master; // 重置（清空）所有binlog日志
		恢复数据
			mysqlbinlog --start-position=154 --stop-position=513 bin-log.000001 > /path/bak.sql;
			mysql -uroot -p < /path/bak.sql;
	主从复制
		1.Slave上面的IO进程连接上Master,并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容。
		2.Master接收到来自Slave的IO进程的请求后,负责复制的IO进程会根据请求信息读取日志指定位置之后的日志信息,返回给Slave的IO进程。返回信息中除了日志所包含的信息之外,还包括本次返回的信息已经到Master端的bin-log文件的名称以及bin-log的位置。
		3.Slave的IO进程接收到信息后,将接收到的日志内容依次添加到Slave端的relay-log文件的最末端,并将读取到的Master端的 bin-log的文件名和位置记录到master-info文件中,以便在下一次读取的时候能够清楚的告诉Master从何处开始读取日志。
		4.Slave的Sql进程检测到relay-log中新增加了内容后,会马上解析relay-log的内容成为在Master端真实执行时候的那些可执行的内容,并在自身执行。
		复制支持多种不同的复制策略:
			异步复制：Master不需要等待Slave应答就可以提交。
			同步复制：Master要等待所有Slave应答之后才会提交（MySql对DB操作的提交通常是先对操作事件进行二进制日志文件写入然后再进行提交）。
			半同步复制：Master等待至少一个Slave应答就可以提交。
				1.从库会在连接到主库时告诉主库,它是不是配置了半同步。
				2.如果半同步复制在主库端是开启了的,并且至少有一个半同步复制的从库节点,那么此时主库的事务线程在提交时会被阻塞并等待,结果有两种可能,要么至少一个从库节点通知它已经收到了所有这个事务的Binlog事件,要么一直等待直到超过配置的某一个时间点为止,而此时,半同步复制将自动关闭,转换为异步复制。
				3.从库节点只有在接收到某一个事务的所有Binlog,将其写入并Flush到Relay Log文件之后,才会通知对应主库上面的等待线程。
				4.如果在等待过程中,等待时间已经超过了配置的超时时间,没有任何一个从节点通知当前事务,那么此时主库会自动转换为异步复制,当至少一个半同步从节点赶上来时,主库便会自动转换为半同步方式的复制。
				5.半同步复制必须是在主库和从库两端都开启时才行,如果在主库上没打开,或者在主库上开启了而在从库上没有开启,主库都会使用异步方式复制。
			注:
				半同步复制是一个功能模块,默认并没有安装,Mysql插件目录下semisync_master.so文件编译安装后默认就有。
				主库my.ini添加配置如下：
					plugin-load=rpl_semi_sync_master=semisync_master.so
					rpl_semi_sync_master_enabled=1
				从库my.ini添加配置如下：
					plugin-load=rpl_semi_sync_slave=semisync_slave.so
					rpl_semi_sync_slave_enabled=1
				配置完成后(重启Mysql)后可以通过命令show plugins 查看已经启用的插件列表是有刚刚安装的插件。
				另外,可以通过以下命令查看半同步是否在运行：
					mysql> show status like 'Rpl_semi_sync_master_status';
	部署主从
		主:
			1.在my.cnf配置文件下添加如下配置
				[mysqld]
				## 同一局域网内注意要唯一
				server-id=1
				## 指定mysql的binlog的存放路径,默认会存放到mysql的data目录下
				log-bin=mysql-bin
			2.在master数据库创建数据同步用户,授予用户 slave REPLICATION SLAVE权限和REPLICATION CLIENT权限,用于在主从库之间同步数据。
				CREATE USER 'tongbu'@'%' IDENTIFIED BY '123456';
				GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'tongbu'@'%';
			3.查看主服务器状态
				show master status;
		从:
			1.在my.cnf配置文件下添加如下配置
				[mysqld]
				## 设置server_id,注意要唯一
				server-id=2 
				## 开启二进制日志功能,以备Slave作为其它Slave的Master时使用
				log-bin=mysql-slave-bin 
				## 指定relay_log日志的存放路径和文件前缀,不指定的话默认以主机名作为前缀
				relay_log=slave-relay-bin
			2.配置从服务器连接到Master服务器
				change master to master_host='主IP', master_user='tongbu', master_password='123456', master_port=3306, master_log_file='mysql-bin.000011', master_log_pos= 154, master_connect_retry=30;
					master_host：主服务器的IP
					master_port：3306(这里没有配置,默认3306)
					master_user：Master 服务器授权用户,也就是 Master 前面创建的那个用户
					master_password：Master 服务器授权用户对应的密码
					master_log_file：Master binlog 文件名
					master_log_pos：Master binlog 文件中的 Postion 值
				(关于position值,这里做一个说明：如果主服务器已经是有很多数据了的,那就先需要备份主服务器的数据到从服务器中,然后再使用命令show master status记录需要开始同步的位置。)
			3.开启主从复制
				## 启动复制
				start slave;
				## 关闭复制
				stop slave;
			4.查看从服务器状态
				show slave status;
		主从复制粒度(配置文件binlog_format的值)
			STATEMENT(语句粒度)
				每一条会修改数据的sql都会记录在binlog中。
				优点：不需要记录每一行的变化,减少了binlog日志量,节约了IO,提高性能。只需要记录在 master 上所执行的语句的细节,以及执行语句时候的上下文的信息。
				缺点：由于记录的只是执行语句,为了这些语句能在slave上正确运行,因此还必须记录每条语句在执行的时候的一些相关信息,以保证所有语句能在slave得到和在master端执行时候相同的结果。像一些特定函数功能,slave可与master上要保持一致会有很多相关问题(如sleep()函数,rand()函数等会出现问题warning)
			ROW(行粒度)
				不记录sql语句上下文相关信息,仅保存哪条记录被修改,也就是说日志中会记录成每一行数据被修改的形式,然后在 slave 端再对相同的数据进行修改。
				优点：binlog中可以不记录执行的sql语句的上下文相关的信息,仅需要记录那一条记录被修改成什么了。所以rowlevel的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程,或function,以及trigger的调用和触发无法被正确复制的问题。
				缺点：在 row 模式下,所有的执行的语句当记录到日志中的时候,都将以每行记录的修改来记录,这样可能会产生大量的日志内容。
			MIXED(混合粒度)
				是以上两种level的混合使用,一般的语句修改使用statment格式保存binlog,如一些函数,statement无法完成主从复制的操作,则采用row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式,也就是在Statement和Row之间选择一种；
				新版本的MySQL中对row模式也被做了优化,并不是所有的修改都会以rowl来记录,像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句,还是会记录所有行的变更。
		主从复制类型
			基于二进制日志的复制
				即基于Binary log实现的复制机制,从库需要告知主库要从哪个偏移量进行增量同步,如果指定错误会造成数据的遗漏,从而造成数据的不一致。
			GTID基于事务的复制
				GTID (Global Transaction ID) )即全局事务ID,是对于一个已提交事务的全局唯一编号,由UUID+TID组成的,其中 UUID 是一个 MySQL 实例的唯一标识,保存在mysql数据目录下的auto.cnf文件里。TID 代表了该实例上已经提交的事务数量,并且随着事务提交单调递增。下面是一个GTID的具体形式：
					3E11FA47-71CA-11E1-9E33-C80AA9429562:23
			GTID工作原理
				Master更新数据时,会在事务前产生GTID,一同记录到binlog日志中；
				Slave在接受Master的binlog时,会校验Master的GTID是否已经执行过
				Slave端的I/O线程将变更的binlog,写入到本地的relay log中；
				Sql线程从relay log中获取GTID,然后对比Slave端的binlog是否有记录；
				如果有记录,说明该GTID的事务已经执行,slave会忽略；
				如果没有记录,slave就会从relay log中执行该GTID的事务,并记录到binlog
			GTID配置
				[mysqld]
				#GTID:
				gtid_mode=on
				enforce_gtid_consistency=on
	SQL执行原理
		连接器
			首先客户端连接mysql时就是连接到了连接器上,连接器负责跟客户端建立连接/校验用户身份,获取权限
			如果用户名或者密码不正确,客户端会收到一个“Access denied for user”的错误。
			如果用户名和密码校验正确,连接器会检查用户所拥有的权限。之后,这个连接里的权限逻辑判断,都依赖此时读到的权限。
			这就意味着一个用户成功建立连接之后,即使你用管理员把这个用户的权限更改了,也是不会影响到已经连接的这个用户,除非这个用户断开重新连接。让连接器重新读取权限才可以。
		查询缓存
			连接建立成功之后,你就能够执行select等语句了,这时就会进行第二步：查询缓存
			Mysql收到一个sql请求之后,先检查缓存,看看之前是不是有执行过。如果执行过并缓存没有过期,结果会以key-value的形式存储在内存中,key是查询语句,value是查询结果。如果有缓存,直接把对应的value返回给客户端。
			如果语句不在查询缓存中,就会向下执行下面的阶段,执行完成后,会把结果放到缓存中。
			查询缓存的失效很平凡,因为只要更新一个表,那么这个表的所有查询缓存结果都会被清空,所以对经常变更的表,查询缓存的命中率很低。除非这个表数据比较稳定,不经常改变,才适合查询缓存。
		分析器
			如果没用命中缓存,分析器就开始工作了,对sql语句进行解析。
			首先分析器会做“词法分析”,你输入的多个字符加上空格组成的sql语句,分析器需要分析出来里面字符分别都代表什么。
			如从你输入的”select”关键字开始,mysql知道这是一个查询语句,然后分析出那个是表名,那个是你输入的条件等等。
			做完了词法分析,开始做“语法分析”,根据词法分析的结果,语法分析会判断你输入的这条sql语句是否符合Mysql语法。
			如果你的语句不对,就会收到“You have an error in you SQL syntax”的错误提醒
		优化器
			经过了分析器,Mysql已经知道你要做什么了,在开始执行之前,还需要经过优化器的处理。
			优化器是在表里面有多个索引的时候,决定使用哪个索引；或者在一个语句有多表关联的时候,决定各个表的连接顺序。
		执行器
			Mysql通过分析器知道了你要做什么,通过优化器知道了如何做,接下来就是执行器开始执行语句；
			开始执行之前, 会先判断你对要操作的表或库有没有权限,如果没有就返回权限的错误。
			如果有权限,就打开表继续执行。打开表的时候,执行器会根据表的引擎定义,去使用这个引擎提供的接口。
			比如这个select语句：select * from db1 where ID=100;
			先调用Inodb引擎接口获取表的第一行,判断ID值是不是100,如果不是则跳过,如果是则将结果存在结果集中；
			调用引擎接口获取“下一行”,重复相同的判断逻辑,直到读取这个表的最后一行。
			执行器将上述遍历过程所有符合要求的结果返回给客户端。
			至此,这个select语句算是执行完了。
			数据库的慢查询日志中会看到rows_examined的字段,表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。
			有些情况下,执行器调用一次,在引擎内部则扫描了多行,因此引擎扫描行数跟rows_examined并不完全相同。
	优化
		优化选择
			硬件-系统配置-数据库表结构-SQL及索引
			(优化成本由高到低)
			(优化效果由低到高)
		优化工具
			SHOW [SESSION | GLOBAL] variables 查看数据库参数信息
			SHOW [SESSION | GLOBAL] STATUS 查看数据库的状态信息
			information_schema 获取元数据的方法
			SHOW ENGINE INNODB STATUS Innodb引擎的所有状态
			SHOW PROCESSLIST 查看当前所有连接session状态
			explain 获取查询语句的执行计划
			SHOW index 查看表的索引信息
			slow-log 记录慢查询语句
			mysqldumpslow 分析slowlog文件的
		硬件的优化
			采用好服务器
			存储用ssd或者盘阵,提升随机写的性能
			主从间保证处在同一个交换机下面
		架构的优化
			单个库读写分离,一主多从,主写从读,分散压力。这样从库压力比主库高,保护主库
			使用比主库更好的硬件设备作为slave总结,mysql压力小,延迟自然会变小
		数据库表结构的优化
			选择正确的存储引擎
			永远为每张表设置一个ID,应该为数据库里的每张表都设置一个ID做为其主键,而且最好的是一个INT型的（推荐使用UNSIGNED）,并设置上自动增加的 AUTO_INCREMENT标志
			将字段很多的表分解成多个表 ,于字段比较多的表,如果有些字段的使用频率很低,可以将这些字段分离出来形成新表。因为当一个表的数据量很大时,会由于使用频率低的字段的存在而变慢。
			增加中间表, 对于需要经常联合查询的表,可以建立中间表以提高查询效率
		SQL及索引优化
	缓冲池
		在数据库中进行读取操作,首先将从磁盘中读到的页放在缓冲池中,下次再读相同的页中时,首先判断该页是否在缓冲池中。若在缓冲池中,称该页在缓冲池中被命中,直接读取该页。否则,读取磁盘上的页。
		对于数据库中页的修改操作,则首先修改在缓冲池中的页,然后再以一定的频率刷新到磁盘上。页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发,而是通过一种称为CheckPoint的机制刷新回磁盘。
	重做日志
		注:
			默认情况在数据库数据文件夹下会有两个文件,ib_logfile0/ib_logfile1,日志组中的文件大小是一致的,以循环的方式运行。一个文件写满时,切换到另外一个文件
		流程:
			1.为了保证数据的安全性,事务进行中时会不断的产生redo log
			2.在事务提交时进行一次flush操作
			3.对于写入重写日志文件的操作不是直接写,而是先写入一个重做日志缓冲（redo log buffer）中,然后按照一定的条件写入日志文件
			4.redo log是按照顺序写入的,当数据库或主机失效重启时,会根据redo log进行数据的恢复,如果redo log中有事务提交,则进行事务提交修改数据。这样实现了事务的原子性、一致性和持久性。
		从日志缓冲写入磁盘有两个时间点：
			1.主线程每秒都会将重做日志缓冲写入磁盘的重做日志文件,不论事务是否已经提交;
			2.是由参数innodb_flush_log_at_trx_commit控制,表示在事务提交时,处理重做日志;
				innodb_flush_log_at_trx_commit取值:
					0.代表当提交事务时,并不将事务的重做日志写入磁盘上的日志文件,而是等待主线程每秒的刷新。
					1.是在commit时将重做日志缓冲同步写到磁盘；
					2.是重做日志异步写到磁盘,即不能完全保证commit时肯定会写入重做日志文件,只是有这个动作。
	回滚日志
		事务开始之前,将当前的版本生成undo log
		undo 也会产生 redo 来保证undo log的可靠性
		事务提交之后,undo log并不能立马被删除,而是放入待清理的链表,由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息,决定是否可以清理undo log的日志空间。
	MVCC
		通过保存数据在某个时间点的快照(redo log)来实现的。
		这意味着一个事务无论运行多长时间,在同一个事务里能够看到数据一致的视图。
		根据事务开始的时间不同,同时也意味着在同一个时刻不同事务看到的相同表里的数据可能是不同的。
		在每一行数据中额外保存两个隐藏的列：
			当前行创建时的版本号和删除时的版本号（可能为空）。这里的版本号并不是实际的时间值,而是系统版本号。每开始新的事务,系统版本号都会自动递增。
			事务开始时刻的系统版本号会作为事务的版本号,用来和查询每行记录的版本号进行比较。
		每个事务又有自己的版本号,这样事务内执行CRUD操作时,就通过版本号的比较来达到数据版本控制的目的。
	索引
		MyISAM(B-Tree) & InnoDB(B+Tree)索引结构。MyISAM 采用非聚簇索引,而InnoDB采用聚簇索引。
			聚簇索引： 索引 和 数据文件为同一个文件(InnoDB的聚簇索引叶子结点保存的是所有数据的数据)。
			非聚簇索引： 索引 和 数据文件分开的索引(MyISAM的叶子结点保存的是数据的索引位置,然后再根据去数据文件中查询数据)。
		MyISAM索引按照B-Tree搜索,如果指定的Key存在,则取出其data域的值,然后以data域值-数据指针地址去读取相应数据记录,辅助索引和主索引在结构上没有任何区别,只是主索引要求key是唯一的,而辅助索引的key可以重复。
		InnoDB数据&索引文件为一个idb文件,表数据文件本身就是主索引,相邻的索引临近存储。 叶节点data域保存了完整的数据记录(数据[除主键id外其他列data]+主索引[索引key:表主键id])。 叶子节点直接存储数据记录,以主键id为key,叶子节点中直接存储数据记录。
		InnoDB的数据文件需要按照主键聚集,因此InnoDB要求表必须有主键(MyISAM可以没有)。如果没有指定mysql会自动选择一个可以唯一表示数据记录的列作为主键,如果不存在这样的列,mysql自动为InnoDB表生成一个隐含字段(6个字节长整型)作为主键。
		注:
			基于B+树的特性,会发现对于offset这种特性,其实是用不到索引的。比如每页显示10条数据,要展示第101页,通常会写成select xxx where xxx limit 1000, 10,从offset =1000的位置开始取10条。
	锁
		(InnoDB)共享锁:
			SELECT … LOCK IN SHARE MODE 显示加共享锁。
		(InnoDB)排他锁:
			SELECT … FOR UPDATE 显示添加排他锁。
			增删改操作默认都会加排他锁
		行锁:
			并不是直接对记录行加锁,而是对行对应的索引加锁：
			如果SQL语句操作了主键索引,MySQL就会锁定这条主键索引。
			如果SQL语句操作了非主键索引,MySQL会先锁定该非主键索引,再锁定相关的主键索引。
			如果SQL语句不涉及索引,则会通过隐藏的聚簇索引来对记录加锁。
		表锁:
			锁住整个表。
		MyISAM引擎支持表级锁,不支持行级锁。
		InnoDB引擎支持表级锁和行级锁,默认为行级锁。
	可重复度与幻读
		for update语法就是当前读，也就是查询当前已经提交的数据，并且是带悲观锁的。没有for update就是快照读，也就是根据readView读取的undolog中的数据。
		所以解决幻读还是需要在事务开始时就使用select...for update当前读来加锁,防止幻读
			事务A:
				BEGIN;
					SELECT * FROM `user` WHERE `name` = "ff" for UPDATE;
					... // 暂不提交事务
				COMMIT;
			事务B:
				BEGIN;
					SELECT * FROM `user` WHERE `name` = "ff"; // 不会阻塞
					UPDATE `user` SET `name` = "haha" WHERE `name` = "ff"; // 会阻塞
					INSERT INTO `user`(`name`,age,`value`) VALUES ("ff", 11, 55566); // 会阻塞
					DELETE FROM `user` WHERE `name` = "ff"; // 会阻塞
					... // 暂不提交事务
				COMMIT;
	事务:
		事务的原子性是通过 undo log 来实现的
		事务的持久性性是通过 redo log 来实现的
		事务的隔离性是通过 (读写锁+MVCC)来实现的
		事务的一致性是通过原子性,持久性,隔离性来实现的
	ABA问题可以怎么优化?
		ABA问题导致的原因,是CAS过程中只简单进行了“值”的校验,再有些情况下,“值”相同不会引入错误的业务逻辑（例如余额）,有些情况下,“值”虽然相同,却已经不是原来的数据了（例如堆栈）。
		因此,CAS不能只比对“值”,还必须确保是原来的数据,才能修改成功。
		常见的实践是,将“值”比对,升级为“版本号”的比对,一个数据一个版本,版本变化,即使值相
	超大页处理:
		1.如果可以把分页的ID作为参数,只查询前10条也行
		2.如果分页ID不能作为参数,这样查询
			select * from table where id in (select id from table where age > 20 limit 1000000,10)
	三范式
		第一范式: 每个列都不可以再拆分。
			一般来说"住址"设计成一个字段就行,但是如果经常访问"住址"中城市的部分,那么就非要将"住址"这个属性重新拆分为"省份"、"城市"、"地址"等多个部分进行存储
		第二范式: 非主键列完全依赖于主键,而不能是依赖于主键的一部分。(一个表只说明一个事物)
			比如学生表(姓名,年龄,课程,成绩,学分),这样虽然满足第一范式,但是包含了学生信息与课程信息两部分,拆成学生表,课程表及关系表合适
		第三范式: 非主键列只依赖于主键,不依赖于其他非主键(每列都与主键有直接关系,不存在传递依赖)
			比如学生表(学号, 姓名, 年龄, 所在学院, 学院联系电话),虽然学院电话与学号是一一对应,但是存在传递依赖,学号->所在学院->学院电话
	同步延迟
		产生原因
			MySQL的主从复制都是单线程的操作,主库对所有DDL和DML产生的日志写进binlog,由于binlog是顺序写,所以效率很高。Slave的SQL Thread线程将主库的DDL和DML操作事件在slave中重放。DML和DDL的IO操作是随即的,不是顺序的,成本高很多。另一方面,由于SQL Thread也是单线程的,当主库的并发较高时,产生的DML数量超过slave的SQL Thread所能处理的速度,或者当slave中有大型query语句产生了锁等待那么延时就产生了
		解决方法
			业务的持久层采用分库架构,mysql服务能力水平扩展,分散压力
			单个库读写分离,一主多从,主写读从,分散压力。这样从库比主库压力高,保护主库
			服务在业务和DB之间加入memcache 和 redis 的cache层,降低读的压力
			不同业务的mysql放在不同的物理机,降低压力
			使用比主库更好的硬件设备,Mqsql压力小,延迟就减少了
	count()各个区别
		区别
			count(*)：包括了所有的列,相当于行数,在统计结果的时候, 不会忽略列值为NULL
			count(1)：包括了忽略所有列,用1代表代码行,在统计结果的时候, 不会忽略列值为NULL
			count(列名)：只包括列名那一列,在统计结果的时候,会忽略列值为空（这里的空不是只空字符串或者0,而是表示null）的计数, 即某个字段值为NULL时,不统计。
		执行效率
			列名为主键,count(列名)会比count(1)快
			列名不为主键,count(1)会比count(列名)快
			如果表多个列并且没有主键,则 count（1） 的执行效率优于 count（*）
			如果有主键,则 select count（主键）的执行效率是最优的
			如果表只有一个字段,则 select count（*）最优。
	InnoDB索引和MyISAM索引的区别
		MyISAM引擎使用B+树作为索引结果，叶节点的data域存放的是数据记录的地址。
		在MyISAM中，主索引和辅助索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。
		同样是B+树，实现方式却完全不同。InnoDB表数据文件本身就是一个索引结构，树的叶节点data域保存了完整的数据记录，这种索引叫做聚集索引。
		InnoDB的所有辅助索引都引用主键作为data域。
Redis
	发布订阅
		发布:
			$redis->publish('msg','msg ' .$i);
		订阅:
			$redis->subscribe(['msg'], 'callback');
			function callback($instance,$channelName,$message)
			{
				print_log('收到频道[ '.$channelName.' ]的消息：'.$message);
			}
			// 收到频道[ msg ]的消息：msg 248
	事务
		实现:
			$redis = new Redis();
			$redis->connect('127.0.0.1',6379);
			$redis->watch(array($key1, $key2));
		    //模拟监视 key 被打断
		    //$redis->set($key1, '12345');
		    $redis->multi();
		    $redis->set($key1, '1123');
		    $redis->set($key2, '2123');
		    //执行事务块内的所有命令
		    $status = $redis->exec();
		    //失败则取消事务
		    if (!$status) {
		        $redis->discard();
		    }
	    Redis事务没有隔离级别的概念
			批量操作在发送 EXEC 命令前被放入队列缓存,并不会被实际执行,也就不存在事务内的查询要看到事务里的更新,事务外查询不能看到。
		Redis不保证原子性
			Redis保证一个事务中的所有命令要么都执行,要么都不执行。如果在发送EXEC命令前客户端断线了,则Redis会清空事务队列,事务中的所有命令都不会执行。而一旦客户端发送了EXEC命令,所有的命令就都会被执行,即使此后客户端断线也没关系,因为Redis中已经记录了所有要执行的命令,即使某个命令执行失败,事务队列中的所有其他命令仍然会执行。
		Redis事务不支持回滚
			Redis的事务没有关系数据库事务提供的回滚（rollback） 功能。为此开发者必须在事务执行出错后自己收拾剩下的摊子。
		注:
			Redis的事务只能保证commands队列中的事务全部执行或不执行,无法保证执行中如果有执行失败,进行回滚的操作
	常见问题
		1.缓存穿透
			缓存穿透是指查询一个一定不存在的数据,如果规则是从数据库中查不到数据则不写入缓存,这将导致这个不存在的数据每次请求都要到数据库中查询,失去了缓存的意义,这也是经常提的缓存命中率问题。在流量大时,可能数据库就挂掉了,也可以利用不存在的key频繁攻击应用。
		解决方案
			如果查询数据库也为空,直接设置一个默认值存放到缓存,这样第二次到缓冲中获取就有值了,而不会继续访问数据库,同时设置缓存时间；
			在数据处理层,进行数据校验,判断数据类型和数据范围；
			采用布隆过滤器,将所有可能存在的数据哈希到一个足够大的bitmap中,一个一定不存在的数据会被 这个bitmap拦截掉,从而避免了对底层存储系统的查询压力；
		2.缓存雪崩
			缓存雪崩是指由于大量原有缓存同时过期（或者数据未加载到缓存中）,所有原本应该访问缓存的请求都去查询数据库了,而对数据库CPU和内存造成巨大压力,严重的会造成数据库宕机,造成系统的崩溃。
		解决方案
			缓存过期时间差异化,避免同一时间过期；
		3.缓存击穿
			缓存击穿是指某个设置了过期时间的热门key,在某个高并发访问的时间点过期,将会有多个数据查询请求同时发到数据库,对数据库CPU和内存造成冲击,严重的会造成数据库宕机,造成系统的崩溃。
			缓存击穿和缓存雪崩的区别在于这里针对某一key缓存,前者则是很多key。
		解决方案
			热门key设置为永不过期,后台进行动态更新；
			设置互斥锁：
	淘汰策略
		定期删除
			redis默认每隔100ms就随机抽取一些设置了过期时间的key,检查其是否过期,如果有过期就删除。注意这里是随机抽取的。为什么要随机呢？假如 redis 存了几十万个 key ,每隔100ms就遍历所有的设置过期时间的 key 的话,就会给 CPU 带来很大的负载。
		惰性删除
			定期删除可能导致很多过期的key 到了时间并没有被删除掉。这时就要使用到惰性删除。当读写一个已经过期的key时,会触发redis删除这个过期key。
		主动删除
			redis可配置 maxmemory -> 当使用的内容超过了maxmemory时,会触发主动清理策略。
		(3种方式同时存在。)
		淘汰策略
			volatile-lru：在设置过期时间的数据中淘汰最少使用的数据。
			allkeys-lru：在所有的数据中淘汰最少使用的数据。
			volatile-lfu：在设置过期时间的数据中淘汰使用频率最低的数据。
			allkeys-lfu：在所有的数据中淘汰使用使用频率最低的数据。
			volatile-random：在设置过期时间的数据中淘汰任意随机数据。
			allkeys-random：在所有的数据中随机淘汰数据。
			volatile-ttl：在设置过期时间的数据中淘汰最早过期的数据。
			noeviction：默认策略,不淘汰数据,新增或者修改数据会抛异常,但是读操作正常进行,不受影响
		获取当前淘汰策略
			127.0.0.1:6379> config get maxmemory-policy
		修改淘汰策略
			通过配置文件设置淘汰策略
				maxmemory-policy allkeys-lru
			通过命令修改淘汰策略
				127.0.0.1:6379> config set maxmemory-policy allkeys-lru
	bitmap也可以模拟布隆过滤器
		// 连接redis
		$redis->connect();
		// 上线
		function online($uid) 
		{
			global $redis;
			$redis->setbit('online', $uid, 1);
		}
		// 下线
		function offline($uid) 
		{
			global $redis;
			$redis->setbit('online', $uid, 0);
		}
		// 判断是否在线
		function isonline($uid) 
		{
			global $redis;
			$redis->getbit('online', $uid);
		}
		// 在线统计
		function total() 
		{
			global $redis;
			return $redis->bitcount('online');
		}
	使用令牌桶实现流量控制
		/**
	     * 加入令牌
	     * @param  Int $num 加入的令牌数量
	     * @return Int 加入的数量
	     */
	    public function add($num=0){
	        // 当前剩余令牌数
	        $curnum = intval($this->_redis->lSize($this->_queue));
	        // 最大令牌数
	        $maxnum = intval($this->_max);
	        // 计算最大可加入的令牌数量,不能超过最大令牌数
	        $num = $maxnum>=$curnum+$num? $num : $maxnum-$curnum;
	        // 加入令牌
	        if($num>0){
	            $token = array_fill(0, $num, 1);
	            $this->_redis->lPush($this->_queue, ...$token);
	            return $num;
	        }
	        return 0;
	    }
	    /**
	     * 获取令牌
	     * @return Boolean
	     */
	    public function get(){
	        return $this->_redis->rPop($this->_queue)? true : false;
	    }
	其他类型
		HyperLogLog(用来做基数统计的算法)
			比如数据集 {1, 3, 5, 7, 5, 7, 8}, 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内,快速计算基数。
		Geo(理位置信息储存起来)
			比如实现附近的人,这个可以设置一个key然后存储(GEOADD key 116.405285 39.904989 "北京" 121.472644 31.231706 "上海")
			获取上海到北京的距离(GEODIST key 北京 上海)
			获取指定经纬度附近的(GEORADIUS key 116 121 100 km)
		流
			5.0版本新增加的数据结构,也是该版本最重要的更新,专门用于实现消息队列,事件系统
	Redis没有直接使用C字符串
		Redis字符串结构
			1. len  : 字符串长度/字符数组中已使用的字符数量
			2. alloc: 字符串已分配字节数,不同于free,记录的是为buf分配的总长度
			3. flags: 标识当前结构体的类型（0~4）
			4. buf  : 字符数组,用来保存字符串
			5. free : 记录buf数组中未使用字节的数量
		区别
			预分配(C定义字符串是定长,而Redis是在原有基础上又预分配了一定长度,这样在字符串修改的时候不必重新申请内存并进行值拷贝)
				它并不仅仅申请要使用的内存,而是额外申请了一些空间,以避免下次修改的时候又需要重新申请内存
			常数获取长度(C获取长度需要遍历一遍,而Redis有值存储字符串长度,这样就可以存储\0这样的C的结束符)
			惰性释放
				而正因如此,出现字符串缩短的时候,也没有必要直接释放内存,只需要更新字符串,记录当前使用的长度即可,你说,下次字符串又增长的时候,不就又用上了吗
	Redis集群方案有哪些
		1.主从模式
			1.优点: 主从结构具有读写分离，提高效率、数据备份，提供多个副本等优点。
			2.不足: 最大的不足就是主从模式不具备自动容错和恢复功能，主节点故障，集群则无法进行工作，可用性比较低，从节点升主节点需要人工手动干预。
		2.哨兵模式
			1.优点: 哨兵模式是基于主从模式的，解决可主从模式中master故障不可以自动切换故障的问题。
			2.不足: 
				（1）是一种中心化的集群实现方案：始终只有一个Redis主机来接收和处理写请求，写操作受单机瓶颈影响。
				（2）集群里所有节点保存的都是全量数据，浪费内存空间，没有真正实现分布式存储。数据量过大时，主从同步严重影响master的性能。
				（3）Redis主机宕机后，哨兵模式正在投票选举的情况之外，因为投票选举结束之前，谁也不知道主机和从机是谁，此时Redis也会开启保护机制，禁止写操作，直到选举出了新的Redis主机。
		在业务代码层
			起几个毫无关联的Redis实例,在代码层,对key 进行hash计算,然后去对应的Redis实例操作数据。 这种方式对hash层代码要求比较高,考虑部分包
		3.Codis
			需要管理员在管理界面上手动把从CodisRedis提升为主CodisRedis。

			如果手动处理觉得麻烦，豌豆荚也提供了一个工具Codis-ha，这个工具会在检测到主CodisRedis挂掉的时候将其下线并提升一个从CodisRedis为主CodisRedis。

			Codis中采用预分片的形式，启动的时候就创建了1024个slot，1个slot相当于1个箱子，每个箱子有固定的编号，范围是1~1024。slot这个箱子用作存放Key，至于Key存放到哪个箱子，可以通过算法“crc32(key)%1024”获得一个数字，这个数字的范围一定是1~1024之间，Key就放到这个数字对应的slot。例如，如果某个Key通过算法“crc32(key)%1024”得到的数字是5，就放到编码为5的slot（箱子）。1个slot只能放1个Redis Server Group，不能把1个slot放到多个Redis Server Group中。1个Redis Server Group最少可以存放1个slot，最大可以存放1024个slot。因此，Codis中最多可以指定1024个Redis Server Group。
		4.Redis Cluster
			自带的集群,特点在于他的分布式算法不是一致性hash,而是hash槽的概念,以及自身支持节点设置从节点。具体看官方文档介绍。
	Pipeline
		在某些场景下我们在一次操作中可能需要执行多个命令,而如果我们只是一个命令一个命令去执行则会浪费很多网络消耗时间,如果将命令一次性传输到 Redis中去再执行,则会减少很多开销时间。但是需要注意的是 pipeline中的命令并不是原子性执行的,也就是说管道中的命令到达 Redis服务器的时候可能会被其他的命令穿插
			$users = [1, 2, 3, 4];
			$predis = app('redis')->connection()->client();
			$user_values = $predis->pipeline(function ($pipe) use ($users) {
				foreach ($users as $val) {
					$pipe->get('test' . $val);
				}
			});
			dump($user_values);
	redis6.0版本多线程
		1.启用多线程 I/O 后，Redis 将会为每个 I/O 线程创建一个事件循环，并将 I/O 操作分配到不同的线程中进行处理，从而提高 Redis 在多核 CPU 系统上的性能。不同的线程之间会按需进行任务的负载均衡，以确保整体系统的稳定性和高并发能力。
		2.需要注意的是，在使用多线程 I/O 时，Redis 依然保持单线程的命令处理模型，具体的命令处理依然是在主线程中进行，多线程 I/O 仅仅是将 I/O 操作分离出来。因此，多线程 I/O 并不会对 Redis 的单线程性能带来提升，主要是提高 Redis 在多核系统上的并发处理能力。
	reids实现消息队列
		1.List的LPUSH+BRPOP实现
			1.线程阻塞过久服务器会主动断开,造成异常,需要捕获并重试
			2.消息确认ack麻烦,不能保证消息处理确认
			3.不能以广播的形式
		2.Sorted-Set实现延迟队列
			并启动一个协程来轮询查询延迟队列中已过期的任务。然后使用`addToQueue`函数向延迟队列中添加任务，将任务的过期时间作为分数添加到sorted set中。最后通过`pollQueue`函数从延迟队列中获取已过期的任务并进行处理。
			问题:需要使用轮询机制来实时查询,所以会增加内存的消耗,并且严格意义上,延迟的时间会大于设置的时间
		3.发布/订阅模式
			典型的广播模式
		4.stream实现
			```go
				import "github.com/go-redis/redis"

				func main() {
				    client := redis.NewClient(&redis.Options{
				        Addr:     "localhost:6379",
				        Password: "", // 密码
				        DB:       0,  // 选择数据库
				    })

				    _, err := client.Ping().Result()
				    if err != nil {
				        panic(err)
				    }

				    // 此处开始编写队列操作的代码
				}
				```

				接下来，可以使用Redis的`XADD`命令将数据写入Stream中：

				```go
				// 添加数据到Stream中
				streamID, err := client.XAdd(&redis.XAddArgs{
				    Stream: "myqueue", // Stream名字
				    ID:     "*",      // 自动产生的ID
				    Values: map[string]interface{}{
				        "data": "hello", // 要添加的数据
				    },
				}).Result()

				if err != nil {
				    panic(err)
				}
				```

				可以通过`XLEN`命令获取Stream中消息的数量，以判断队列是否为空：

				```go
				// 获取队列长度
				length, err := client.XLen("myqueue").Result()
				if err != nil {
				    panic(err)
				}

				fmt.Println("队列长度:", length)
				```

				使用`XREAD`命令可以从Stream中消费消息，可以使用一个阻塞的`XREAD`命令来实现长轮询，示例代码如下：

				```go
				// 阻塞读取消息
				for {
				    result, err := client.XRead(&redis.XReadArgs{
				        Streams: []string{"myqueue", "0"}, // Stream名字和最小ID
				        Count:   1,                        // 一次读取1个消息
				        Block:   0,                        // 长轮询阻塞时间，0表示阻塞直到有消息
				    }).Result()

				    if err != nil {
				        panic(err)
				    }

				    msgs := result[0].Messages
				    for _, msg := range msgs {
				        fmt.Println("接收到消息:", msg)
				        // 在此处进行消息的处理
				    }
				}
				```

				在消费完消息后，可以使用`XACK`命令将消息从Stream中删除：

				```go
				// 确认消费完消息
				ack, err := client.XAck("myqueue", "group", streamID).Result()
				if err != nil {
				    panic(err)
				}
				fmt.Println("Ack:", ack)
				```

				以上就是使用Golang实现Redis的Stream类型作为队列的代码示例。根据实际需求，可以进一步完善和优化代码，实现更复杂的队列功能。
MongoDB
	常用命令
		$m = new MongoClient(); // 连接默认主机和端口为：mongodb://localhost:27017
		$db = $m->test; // 获取名称为 "test" 的数据库
		$collection = $db->createCollection("runoob"); // 创建集合
		$collection = $db->runoob; // 选择集合
		$document = array( 
		    "title" => "MongoDB", 
		    "description" => "database", 
		    "likes" => 100,
		    "url" => "http://www.runoob.com/mongodb/",
		    "by", "菜鸟教程"
		);
		$collection->insert($document);
		$cursor = $collection->find(); // 查找文档
		$collection->update(array("title"=>"MongoDB"), array('$set'=>array("title"=>"MongoDB 教程"))); // 更新文档
		$collection->remove(array("title"=>"MongoDB 教程"), array("justOne" => true)); // 移除文档
		db.collection.createIndex({"key1":1, "key2":-1}) // 创建索引:1升序,-1降序
		db.user.getIndexes() // 获取索引
		db.user.dropIndex('key') // 删除索引
		索引的存储数据结构是B树,索引命名空间存储着对B树的根节点的指针
	副本集高可用
		副本集包括三种节点：主节点、从节点、仲裁节点。
		主节点:
			负责处理客户端请求,读、写数据, 记录在其上所有操作的oplog;
		从节点:
			定期轮询主节点获取这些操作,然后对自己的数据副本执行这些操作,从而保证从节点的数据与主节点一致。默认情况下,从节点不支持外部读取,但可以设置,副本集的机制在于主节点出现故障的时候,余下的节点会选举出一个新的主节点,从而保证系统可以正常运行。
		仲裁节点:
			不复制数据,仅参与投票。由于它没有访问的压力,比较空闲,因此不容易出故障。由于副本集出现故障的时候,存活的节点必须大于副本集节点总数的一半,否则无法选举主节点,或者主节点会自动降级为从节点,整个副本集变为只读。因此,增加一个不容易出故障的仲裁节点,可以增加有效选票,降低整个副本集不可用的风险。仲裁节点可多于一个。也就是说只参与投票,不接收复制的数据,也不能成为活跃节点。
	选举过程
		1.得到每个服务器节点的最后操作时间戳。每个 mongodb都有oplog机制会记录本机的操作,方便和主服务器进行对比数据是否同步还可以用于错误恢复。
		2.如果集群中大部分服务器down机了,保留活着的节点都为secondary状态并停止,不选举了。
		3.如果集群中选举出来的主节点或者所有从节点最后一次同步时间看起来很旧了,停止选举等待人来操作。
		4.如果上面都没有问题就选择最后操作时间戳最新(保证数据是最新的)的服务器节点作为主节点。
	同步延迟问题
		在MongoDB中,所有写操作都会产生 oplog,oplog 是每修改一条数据都会生成一条,如果你采用一个批量update命令更新了 N 多条数据,那么oplog 会有很多条,而不是一条。所以同步延迟就是写操作在主节点上执行完后,从节点还没有把 oplog 拿过来再执行一次。而这个写操作的量越大,主节点与从节点的差别也就越大,同步延迟也就越大了。
Docker
	Docker是一个容器化平台，它以容器的形式将你的应用程序及所有的依赖项打包在一起，以确保你的应用程序在任何环境中无缝运行。
	网络模式
		docker network create --driver bridge my-bridge-network
		桥接模式(默认)
			当docker服务启动后,会创建一个名字叫docker0的虚拟网桥,然后选一个与宿主机不一样的网络ip地址以及子网分配给docker0。
			另外每创建一个容器就会新增一个容器网卡,然后以桥接方式架到docker0网桥中,docker0会以NAT地址转换的方式通过宿主机的网卡,从而与公网进行通信。
		host主机模式
			主机模式是指docker容器与公网通信时使用的是宿主机的ip与端口,同时容器自己不会有ip地址,所以在这模式下容器与宿主机之间并没有隔离很分明。
		container网络模式
			创建新容器的时候,通过–net container参数,指定其和已经存在的某个容器共享一个 Network Namespace。
		none无网络模式
			无网络模式下相当于容器处于断网状态下,同样没有自己的ip地址。 创建容器时通过参数 –net=none 设置,这比较少使用。
		注
			1.在docker中容器间直接通过ip进行服务访问是存在弊端的。假如上面例子中mysql的突然挂掉重启也失败,只能重新run一个。这时ip可能会发生变化,那就需要进去直接跟mysql通信的服务修改相关配置信息,就很不友好。 因此Docker也提供了基于容器名来与其它容器通信。
			2.Docker1.10 以后,docker daemon 实现了一个内嵌的 docker dns server,使容器可以直接通过“容器名”通信。不过不能使用默认bridge,需要自定义网桥(还是bridge模式)。
	存储卷
		数据卷
			# docker volume inspect my_volume
				[
				    {
				        "CreatedAt": "2019-07-28T13:01:27+08:00",
				        "Driver": "local",
				        "Labels": {},
				        "Mountpoint": "/var/lib/docker/volumes/my_volume/_data",
				        "Name": "my_volume",
				        "Options": {},
				        "Scope": "local"
				    }
				]
			# docker run -it --rm --name my_app -v my_volume:/data/apps busybox
			# docker run -it --rm --name my_app --mount source=my_volume,target=/data/apps busybox
		挂载目录
			# docker run -it --rm --name my_app -v /tmp/my_app:/data/apps busybox
			# docker run -it --rm --name my_app --mount type=bind,source=/tmp/my_app,target=/data/apps busybox
	注
		1.镜像文件都存于docker相关的本地资源存在/var/lib/docker/目录下，其中container目录存放容器信息，graph目录存放镜像信息，aufs目录下存放具体的镜像底层文件。
		2.$()与反引号``:都是命令替换清理批量后台停止容器docker rm $(sudo docker ps -a -q)
		3.docker的默认存储设置Docker的默认存放位置是/var/lib/docker，如果希望将docker的本地文件存储到其他分区，可以使用Linux软连接的方式来做。
HAProxy
	一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件
	4层负载均衡（通常是针对连接）
		将网络流量负载平衡到多个服务器的最简单方法是使用第4层（传输层）负载平衡。以这种方式进行负载均衡将根据IP范围和端口转发用户流量。
	7层负载均衡（通常是针对请求，可以对请求头进行修改）
		7层负载平衡是更复杂的负载均衡网络流量的方法是使用第7层（应用层）负载均衡。
		使用第7层允许负载均衡器根据用户请求的内容将请求转发到不同的后端服务器。
		这种负载平衡模式允许您在同一域和端口下运行多个Web应用程序服务器。
	Nginx的优点：
		1.优点工作在OSI第4/7层,可以针对http应用做一些分流的策略
		2.Nginx对网络的依赖非常小,理论上能ping通就能进行负载功能
		3.Nginx安装和配置比较简单
		4.可以承担高的负载压力且稳定
		5.Nginx可以通过端口检查到服务器内部的故障
		6.Nginx不仅仅是一款优秀的负载均衡/反向代理软件,它同时也是功能强大的Web应用服务器
	Nginx的缺点：
		1.Nginx不支持url来检测
		2.Nginx仅能支持http、https和Email,这个它的弱势
		3.Nginx的Session的保持,Cookie的引导能力相对欠缺
	HaProxy的优点：
		1.HaProxy是支持虚拟主机的
		2.支持Url检测后端的服务器
		3.它跟LVS一样,本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HaProxy更会比Nginx有更出色的负载均衡速度,在并发处理上也是优于Nginx的；
		4.HaProxy可以对Mysql读进行负载均衡,节点检测
		5.HaProxy的算法较多,支持8种负载均衡算法,同时支持session会话保持
		6.HaProxy有免费开源的管理后台,Nginx的管理后台要收费
	haproxy.cfg配置文件
		global
			log 127.0.0.1 local0 info maxconn 4096
				log：全局的日志配置,local0 是日志设备,info 表示日志级别。其中日志级别有err、warning、info、debug 四种可选。这个配置表示使用 127.0.0.1 上的 rsyslog 服务中的local0 
				maxconn：设定每个 haproxy 进程可接受的最大并发连接数,此选项等同于 Linux命令行选项“ulimit -n”。日志设备,记录日志等级为info。
			user nobody 
			group nobody 
				user/ group：设置运行 haproxy 进程的用户和组,也可使用用户和组的 uid 和gid 值来替代。
			daemon 
				daemon：设置 HAProxy 进程进入后台运行。这是推荐的运行模式。
			nbproc 1
				nbproc：设置 HAProxy 启动时可创建的进程数,此参数要求将HAProxy 运行模式设置为“daemon”,默认只启动一个进程。根据使用经验,该值的设置应该小于服务器的 CPU 核数。创建多个进程,能够减少每个进程的任务队列,但是过多的进程可能会导致进程的崩溃。
			pidfile /usr/local/haproxy/logs/haproxy.pid
				pidfile：指定 HAProxy 进程的 pid 文件。启动进程的用户必须有访问此文件的权限。
		defaults
			mode http
				mode：设置 HAProxy 实例默认的运行模式,有 tcp、http、health 三个可选值。
					tcp:客户端和服务器端之间将建立一个全双工的连接,不会对七层报文做任何类型的检查,默认为 tcp 模式,经常用于 SSL、SSH、SMTP 等应用
					http:客户端请求在转发至后端服务器之前将会被深度分析,所有不与 RFC 格式兼容的请求都会被拒绝
					health:废弃
			retries 3
				retries：设置连接后端服务器的失败重试次数,连接失败的次数如果超过这里设置的值,HAProxy 会将对应的后端服务器标记为不可用。此参数也可在后面部分进行设置。
			timeout connect 10s 
				timeout connect：设置成功连接到一台服务器的最长等待时间,默认单位是毫秒,但也可以使用其他的时间单位后缀。
			timeout client 20s 
				timeout client：设置连接客户端发送数据时最长等待时间,默认单位是毫秒,也可以使用其他的时间单位后缀。
			timeout server 30s 
				timeout server：设置服务器端回应客户度数据发送的最长等待时间,默认单位是毫秒,也可以使用其他的时间单位后缀。
			timeout check 5s
				timeout check：设置对后端服务器的检测超时时间,默认单位是毫秒,也可以使用其他的时间单位后缀。
		frontend www
			bind *:80 
				bind：此选项只能在 frontend 和 listen 部分进行定义,用于定义一个或几个监听的套接字。bind 的使用格式为:bind [:<port_range>] interface 其中,address 为可选选项,其可以为主机名或IP 地址,如果将其设置为“*”或“0.0.0.0”,将监听当前系统的所有 IPv4 地址。port_range 可以是一个特定的 TCP 端口,也可是一个端口范围,小于 1024 的端口需要有特定权限的用户才能使用。interface 为可选选项,用来指定网络接口的名称,只能在 Linux 系统上使用。
			mode	http
			option	httplog 
				option httplog：在默认情况下,haproxy 日志是不记录 HTTP 请求的,这样很不方便 HAProxy 问题的排查与监控。通过此选项可以启用日志记录 HTTP 请求。
			option	forwardfor 
				option forwardfor：如果后端服务器需要获得客户端的真实 IP,就需要配置此参数。由于 HAProxy 工作于反向代理模式,因此发往后端真实服务器的请求中的客户端 IP 均为 HAProxy 主机的 IP,而非真正访问客户端的地址,这就导致真实服务器端无法记录客户端真正请求来源的 IP,而“X-Forwarded-For”则可用于解决此问题。通过使用“forwardfor”选项,HAProxy 就可以向每个发往后端真实服务器的请求添加“X-Forwarded-For”记录,这样后端真实服务器日志可以通过“X-Forwarded-For”信息来记录客户端来源 IP。
			option	httpclose 
				option httpclose：此选项表示在客户端和服务器端完成一次连接请求后,HAProxy 将主动关闭此 TCP 连接。这是对性能非常有帮助的一个参数。
			log	global
				log global：表示使用全局的日志配置,这里的“ global”表示引用在HAProxy 配置文件 global 部分中定义的 log 选项配置格式。
			default_backend htmpool
				default_backend：#指定默认的后端服务器池,也就是指定一组后端真实服务器,而这些真实服务器组将在 backend 段进行定义。这里的htmpool 就是一个后端服务器组。
		backend htmpool
			mode	http 
			option	redispatch
				option redispatch：此参数用于 cookie 保持的环境中。在默认情况下,HAProxy会将其请求的后端服务器的 serverID 插入到 cookie 中,以保证会话的 SESSION 持久性。而如果后端的服务器出现故障,客户端的 cookie 是不会刷新的,这就出现了问题。此时,如果设置此参数,就会将客户的请求强制定向到另外一个健康的后端服务器上,以保证服务的正常。
			option	abortonclose 
				option abortonclose：如果设置了此参数,可以在服务器负载很高的情况下, 自动结束掉当前队列中处理时间比较长的链接。
			balance	roundrobin 
				balance：此关键字用来定义负载均衡算法。目前 HAProxy 支持多种负载均衡算法,常用的有如下几种：
					roundrobin
						基于权重进行轮询调度的算法,在服务器的性能分布比较均匀的时候,这是一种最公平、最合理的算法。此算法经常使用。
					static-rr
						基于权重进行轮询的调度算法,不过此算法为静态方法,在运行时调整其服务器权重不会生效。
					source
						请求源 IP 的算法。此算法先对请求的源 IP 进行 hash 运算, 然后将结果与后端服务器的权重总数相除后转发至某个匹配的后端服务器。这种方式可以使同一个客户端 IP 的请求始终被转发到某特定的后端服务器。
					leastconn
						会将新的连接请求转发到具有最少连接数目的后端服务器。在会话时间较长的场景中推荐使用此算法,例如数据库负载均衡等。此算法不 适合会话较短的环境中,例如基于 HTTP 的应用。
					uri
						对部分或整个 URI 进行 hash 运算,再经过与服务器的总权重相除,最后转发到某台匹配的后端服务器上。
					uri_param
						会根据 URL 路径中的参数进行转发,这样可保证在后端真实服务器数量不变时,同一个用户的请求始终分发到同一台机器上。
					hdr():
						根据 http 头进行转发,如果指定的 http 头名称不存在,则使用 roundrobin 算法进行策略转发。
			cookie	SERVERID
				cookie：表示允许向 cookie 插入 SERVERID,每台服务器的 SERVERID 可在下面的 server 关键字中使用 cookie 关键字定义。
			option	httpchk GET /index.php
				option httpchk：此选项表示启用 HTTP 的服务状态检测功能。HAProxy 作为一款专业的负载均衡器,它支持对 backend 部分指定的后端服务节点的健康检查,以保证在后端 backend 中某个节点不能服务时,把从 frotend 端进来的客户端请求分配至 backend 中其他健康节点上,从而保证整体服务的可用性。“option httpchk”的用法如下：
					method	表示 HTTP 请求的方式,常用的有 OPTIONS、GET、HEAD 几种方式。一般的健康检查可以采用 HEAD 方式进行,而不是才采用 GET 方式,这是因为 HEAD 方式没有数据返回,仅检查 Response 的 HEAD 是不是 200 状态。因此相对与 GET 来说,HEAD 方式更快,更简单。
					uri	表示要检测的 URL 地址,通过执行此 URL,可以获取后端服务器的运行状态。在正常情况下将返回状态码 200,返回其他状态码均为异常状态。
					version	指定心跳检测时的 HTTP 的版本号。
			server	web1 10.200.34.181:80	cookie server1 weight 6 check inter 2000 rise 2 fall 3
			server	web2 10.200.34.182:8080 cookie server2 weight 6 check inter 2000 rise 2 fall 
				server：这个关键字用来定义多个后端真实服务器,不能用于 defaults 和frontend部分。使用格式为：server[:port] [param*] 其中,每个参数含义如下：
					check：表示启用对此后端服务器执行健康状态检查。
					inter：设置健康状态检查的时间间隔,单位为毫秒。
					rise：设置从故障状态转换至正常状态需要成功检查的次数,例如。“rise 2”表示 2 次检查正确就认为此服务器可用。
					fall：设置后端服务器从正常状态转换为不可用状态需要检查的次数,例如,“fall 3”表示 3 次检查失败就认为此服务器不可用。
					cookie：为指定的后端服务器设定 cookie 值,此处指定的值将在请求入站时被检查,第一次为此值挑选的后端服务器将在后
		listen admin_stats : 名为admin_stats的Haproxy监控页面，监听端口为8080，可以访问:http://xxx:9188/admin_stats查看web监控页面。
			bind 0.0.0.0:9188
			mode http
			log 127.0.0.1 
			local0 err stats 
			refresh 30s
				stats refresh：设置 HAProxy 监控统计页面自动刷新的时间。
			stats uri /haproxy-status
				stats uri：设置 HAProxy 监控统计页面的URL 路径,可随意指定。例如、指定“stats uri /haproxy-status”,就可以过 http://IP:9188/haproxy-status 查看。
			stats realm welcome login\ Haproxy
				stats realm：设置登录 HAProxy 统计页面时密码框上的文本提示信息。
			stats auth admin:admin123
				stats auth：设置登录 HAProxy 统计页面的用户名和密码。用户名和密码通过冒号分割。可为监控页面设置多个用户名和密码,每行一个。
			stats hide-version 
				stats hide-version：用来隐藏统计页面上 HAProxy 的版本信息。
			stats admin if TRUE
				stats admin if TRUE：通过设置此选项,可以在监控页面上手工启用或禁用后端真实服务器,仅在 haproxy1.4.9 以后版本有效
nginx
	Location表达式类型
		~ 表示执行一个正则匹配,区分大小写
		~* 表示执行一个正则匹配,不区分大小写
		^~ 表示普通字符匹配。使用前缀匹配。如果匹配成功,则不再匹配其他location
		= 进行普通字符精确匹配。也就是完全匹配
		/ 通用匹配,任何请求都会匹配到。
	Location优先级(匹配和在配置文件中定义的顺序无关)
		1.等号类型（=）的优先级最高。一旦匹配成功,则不再查找其他匹配项。
		2.^~类型表达式。一旦匹配成功,则不再查找其他匹配项。
		3.正则表达式类型（~ ~*）的优先级次之。如果有多个location的正则能匹配的话,则使用正则表达式最长的那个。
		4.常规字符串匹配类型。按前缀匹配。
	使用=、!= 比较的一个变量和字符串,true/false
	使用~、~*、!~、!~*区分大小写/不区分大小写(及不匹配区分大小写/不区分大小写)的正则匹配
	使用-f、!-f 检查一个文件是否存在
	使用-d、!-d 检查一个目录是否存在
	使用-e、!-e 检查一个文件、目录、符号链接是否存在
	使用-x、!-x 检查一个文件是否可执行
	灰度发布
		当用户请求到达前端web（代理）服务器Openresty,内嵌的lua模块解析Nginx配置文件中的lua脚本代码；
		Lua获取客户端IP地址,去查询Redis中是否有该键值,如果有返回值执行@clien2,否则执行@client1;
		Location @client2把请求转发给预发布服务器,location @client1把请求转发给生产服务器,服务器返回结果,整个过程完成;
	Openresty配置
		upstream client1 { 
		    server 127.0.0.1:8080;  #模拟生产服务器
		}
		upstream client2 {
		    server 127.0.0.1:8090;  #模拟预发布服务器
		}
		server {
		    listen       80;
		    server_name  localhost;
		    
		    location ^~ /test {
		        content_by_lua_file ab.lua
		    }
		    
		    location @client1{
		            proxy_pass http://client1;
		    }
		    location @client2{
		            proxy_pass http://client2;
		    }
		}
 	lua代码(ab.lua)
	 	local redis = require "resty.redis" 
		local cache = redis.new() 
		cache:set_timeout(60000)
		local ok, err = cache.connect(cache, '127.0.0.1', 6379) 
		if not ok then 
		    ngx.say("failed to connect:", err) 
		    return 
		end 
		local local_ip = ngx.req.get_headers()["X-Real-IP"]
		if local_ip == nil then
		    local_ip = ngx.req.get_headers()["x_forwarded_for"]
		end
		if local_ip == nil then
		    local_ip = ngx.var.remote_addr
		end
		--ngx.say("local_ip is : ", local_ip)
		local intercept = cache:get(local_ip) 
		if intercept == local_ip then
		    ngx.exec("@client2")
		    return
		end
		ngx.exec("@client1")
		local ok, err = cache:close() 
		if not ok then 
		    ngx.say("failed to close:", err) 
		    return 
		end
	为什么不采用多线程模型管理连接？
		无状态服务,没有必要进行共享进程内存
		采用独立的进程,可以让互相之间不会影响。一个进程异常崩溃,其它进程的服务不会中断,提升了可靠性
		进程之间不共享资源,不需要加锁,所以省掉了锁带来的开销
	限速模块
		使用ngx_http_limit_req_module模块来实现
		http {
		    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;
		    limit_conn_log_level error;
		    limit_conn_status 503;
		    ...
		    server {
		    ...
		    location /limit {
		        limit_req zone=one burst=5 nodelay;
		    }
RabbitMQ
	消息可靠性投递
		出现问题的点
			1.在生产者投递消息过程中(还未投递到服务端)就宕机
			2.在消息发送到服务端,但是还没有持久化宕机
			3.消息消费过程中宕机(服务端认为消息已经投递成功)
		解决方法
			1.channel设置为confirm,这样就可以使用ack/nack机制(这样可能还是会出现2的问题)
			2.服务端开启持久化
			3.进行手动确认(手动ack机制),这样就可以确认消息持久化后再进行ack
	消息队列丢失数据
		一般开启持久化就可以解决
		1.durable设置为true
		2.deliveryMode = 2
	重复消费问题
		在消费者接收到消息,还未发送确认机制时断开连接或取消订阅,RabbitMQ会认为消息没有被分发,就会重新分发给下一个订阅的消费者,就出现了重复消费问题
		可使用数据库一个表来记录消息的状态（或者用redis来记录也可以）。每次消费之前,都查询判断消息的状态,是否已经被消费了。这个状态可以是id。
	高可用的RabbitMQ集群
		最好是镜像集群模式,与普通集群不一样的是,创建的queue,无论是原数据还是queue例的消息都会存在与多个实例上
	消息队列延时问题
		临时扩大消费者数量,当消费的差不多再重新使用原来的,并排查问题
	消息队列满了问题
		RabbitMQ可以设置TTL,这样queue中积压超过一定的时间就会被清理掉,当然清理掉的队列还是需要在低峰期重新灌入
	事务模式
	存在一个问题：当生产者将消息发送出去之后，如何去确认消息到底有没有到达服务器。
		在发送消息前开启事务：channel.txSelect;
		消息发送之后提交事务：channel.txCommit;
		发生异常组要回滚：channel.txRollback;
	1.发送多条消息时，只要用channel.txSelect();channel.txCommit();将发送消息包裹起来即可
	2.只有消息成功被RabbitMQ 接收，事务才能提交成功，否则便可在捕获异常之后进行事务回滚，与此同时可以进行消息重发。
	3.但是使用事务机制会"吸干" RabbitMQ所以RabbitMQ提供了一个改进方案，即发送方确认机制。
分布式唯一ID实现方式
	数据库自增ID
		以MySQL举例,利用给字段设置 auto_increment_increment和 auto_increment_offset来保证ID自增。
		优点
			数字ID天然排序,对分页或者需要排序的结果很有帮助。
		缺点
			在单个数据库或读写分离或一主多从的情况下,只有一个主库可以生成。有单点故障的风险。
			分表分库的时候会有麻烦。
		优化方案
			针对主库单点,如果有多个Master库,则每个Master库设置的起始数字不一样,步长一样,可以是Master的个数,这样就可以有效生成集群中的唯一ID,也可以大大降低ID生成数据库操作的负载,但一旦把步长定好后,就无法扩容。
	UUID
		UUID (Universally Unique Identifier) 的标准型式包含 32 个 16 进制数字,以连字号分为五段,形式为 8-4-4-4-12 的 36 个字符,示例：550e8400-e29b-41d4-a716-446655440000,到目前为止业界一共有 5 种方式生成 UUID。
		优点
			本地生成,性能非常高。
			全球唯一,在遇见数据迁移,系统数据合并,或者数据库变更等情况下,可以从容应对。
		缺点
			UUID 太长,16 字节 128 位,通常以36长度的字符串表示,不易于存储和传输。
			没有排序无法保证趋势递增。
			UUID往往是使用字符串存储,查询的效率比较低。
	Redis实现
		Redis实现分布式唯一ID主要是通过提供像 INCR 和 INCRBY 这样的自增原子命令,由于Redis自身的单线程的特点所以能保证生成的 ID 肯定是唯一有序的。一般算法为：
		年份 + 当天距当年第多少天 + 天数 + 小时 + redis自增
		优点
			不依赖于数据库,灵活方便,且性能优于数据库。
			数字ID天然排序,对分页或者需要排序的结果很有帮助。
		缺点
			占用带宽,每次要向redis进行请求
	snowflake算法(雪花算法)
		snowflake是Twitter开源的分布式ID生成算法,结果是一个long型的ID。雪花算法是64比特位大小的long类型数字,多用于分布式环境的数据主键。
		1bit:符号位(因为是ID不会存在负数,所以是0)
		41bit:系统时间戳(毫秒级别)
		10bit:工作机器ID(如果是多机房,可以分成5bit机房,5bit机器号)
		12bit:作为毫秒内的流水号,可以设置为递增（意味着每个节点在每毫秒可以产生 4096 个 ID）
		snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数,每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。
		优点
			毫秒数在高位,自增序列在低位,整个ID都是趋势递增的。
			不依赖于数据库,灵活方便,且性能优于数据库。
		缺点
			强依赖机器时钟,如果机器上时钟回拨,会导致发号重复或者服务会处于不可用状态,如果涉及到分布式环境,每台机器上的时钟不可能完全同步,也许有时候也会出现不是全局递增的情况。
	zookeeper
		根据zookeeper的有序递增临时节点的功能特性,可以保证某个znode节点下的所有序号递增,但是需要依赖zookeeper服务,而且高并发的时候,需要考虑分布式锁,这个时候性能就下降了。
	如何选择
		在分布式下,考虑到性能,存储效率和使用方便性,一般不会直接用UUID来做表唯一字段的ID的。另外UUID有可能泄露MAC地址。
		如果没有分库的话,用数据库自增ID是不错的选择。
		如果有分库可以使用不同步长的自增ID来避免冲突,如果还有继续扩容的可能的话,建议直接使用Redis或Snowflake的方案。
		如果对连续性有要求的话,建议使用Redis生成方案,如果对连续性没有要求或者要求干净轻爽的方式的话,建议使用Snowflake方案。
		另外连续ID有可能泄露业务信息,根据早晚的ID号,很容易推算出一天的业务量。
分布式锁实现
	Redis实现
		SETNX 命令,表示设置一个 key 的值当且进度 Key 不存在的时候才能设置成功
		2.6.12版本开始,redis为SET命令增加了一系列选项(set [key] NX/XX EX/PX [expiration]):
		不管我们定多少过期时间,都不能保证,在这段时间内锁住的代码执行完成了,所以这个时间定多少都不好；
		如果不定时间,当执行完成后释放锁,问题就是如果执行到一半机器宕机,那这把锁就永远放不掉了
	Zookeeper实现
		对于 ZK 来说,实现分布式锁的核心是临时顺序节点。
		使用子节点,每个线程获取锁时,都在固定节点下创建临时顺序的子节点,默认最小节点线程获得锁,当释放锁时,删除对应的子节点即可,如果线程出现意外,失去zk连接之后,相对应的子节点也会自动清除
Gossip协议
	基于Gossip协议的一些有名的系统：Apache Cassandra,Redis Cluster模式,Consul等。
	Gossip数据分发协议实现了两种数据传输方式：推送模式和拉取模式
	推送模式
		网络中的某个节点随机选择N个节点作为数据接收对象
		该节点向其选中的N个节点传输相应的信息
		接收到信息的节点处理它接收到的数据
		接收到数据的节点再从第一步开始重复执行
	拉取模式
		某个节点周期性地选择随机N个节点询问有没有最新的信息
		收到请求的节点回复请求节点其最近未收到的信息
一致性Hash原理(对2^32取模)
	求余算法: (hash(Key)%N)
		一个 Redis 服务器挂掉了,这样所有映射到这台redis服务器的对象都会失效。
		如果需要把这台Redis服务器 从Redis集群中移除,这时候Redis服务器是 N-1 台,那么对应映射公式变成了 hash(Key)%(N-1);
		访问量增多,需要添加Redis服务器,这时候Redis是N+1台,映射公式变成了 hash(Key)%(N+1)
	Hash环
		hash（服务器IP地址） % 2^32
		将整个哈希值空间组织成一个虚拟的圆环,确定此数据在环上的位置,从此位置沿环顺时针“行走”,遇到的第一台服务器就是该数据应该映射到的服务器
	虚拟节点
		一致性Hash算法在服务节点太少时,容易因为节点分部不均匀而造成数据倾斜
		对每一个服务节点计算多个哈希,每个计算结果位置都放置一个此服务节点,称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。同时数据定位算法不变,只是多了一步虚拟节点到实际节点的映射
微服务架构
	<span class="image featured"><img src="{{ 'assets/images/other/ServerDesign.png' | relative_url }}" alt="" /></span>
	PHPsocket模拟rpc
		服务器代码(省了很多判断):
			$this->socket = stream_socket_server("tcp://{$host}:{$port}", $errno, $errstr);
	        // 判断RPC程序目录是否存在
	        $realpath = realpath($path);
	        while (true) {
	            $client = stream_socket_accept($this->socket);
	            $buf = fread($client, 2048);
	            //从buf中匹配出参数(比如调用的类名,方法名,参数等)
	            $file = $realpath . '/' . $class . '.php';
	            require_once $file;
	            //实例化类,并调用客户端指定的方法
	            $obj = new $class();
	            //把运行后的结果返回给客户端
	            fwrite($client, $data);
	        }
	    客户端代码:
	    	$client = stream_socket_client("tcp://{$this->urlInfo['host']}:{$this->urlInfo['port']}", $errno, $errstr);
	        //根据调用的URL拼凑指定格式的参数
	        $proto = 'Rpc-Class:...Rpc-Method:...Rpc-Params:...';
	        //向服务端发送我们自定义的协议数据
	        fwrite($client, $proto);
	        //读取服务端传来的数据
	        $data = fread($client, 2048);
	        //关闭客户端
	        fclose($client);
	        返回服务器返回的结果
	        return $data;
	gRPC
		安装protobuf
		PHP gRPC扩展
			vim /usr/local/php7/etc/php.ini
			extension=rpc.so
PHP运行的几种模式
	1.cgi全称“通用网关接口”(Common Gateway Interface), 它可以让一个客户端,从浏览器向Web服务器上的程序请求数据,是客户端和程序之间传输数据的一种标准,另外CGI独立于任何语言,所以可以用任何一种语言编写,只要这种语言具有标准输入、输出和环境变量。如php,perl,tcl等。CGI针对每个用户请求都要开单独的子进程去维护,执行结束处理掉这个进程。典型的fork-and-execute方式
	2.fastcgi,根据1中cgi的特性,可以知道消耗很大,如果很多用户请求,则会申请很多个子进程。。这时候出现了FastCGI。FastCGI 像是一个常驻 (long-live) 型的 CGI,它可以一直执行着,只要激活后,不会每次都要花费时间去 fork 一次 (这是 CGI 最为人诟病的 fork-and-execute 模式)。这个是当下用的最多的了。。linux+nginx+php+mysql
	3.module形式一般用于apache,模块模式是以mod_php5模块的形式集成,此时mod_php5模块的作用是接收Apache传递过来的PHP文件请求,并处理这些请求,然后将处理后的结果返回给Apache。
	4.cli模式。命令行执行php,一般不用。我们在linux下经常使用 "php -m"查找PHP安装了那些扩展就是PHP命令行运行模式；也可以直接命令行执行php xxx.php
OpenResty
	OpenResty是一个基于 Nginx 与 Lua 的高性能 Web 平台,其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。
SYN Flood攻击
	最为常见的DDoS攻击,首先伪造地址对服务器发起SYN请求（我可以建立连接吗？）,服务器就会回应一个ACK+SYN（可以+请确认）。而真实的IP会认为,我没有发送请求,不作回应。服务器没有收到回应,会重试3-5次并且等待一个SYN Time（一般30秒-2分钟）后,丢弃这个连接。
IO模型
	阻塞IO模型(同步IO操作)
		网络编程中,读取客户端的数据需要调用recvfrom。在默认情况下,这个调用会一直阻塞直到数据接收完毕,就是一个同步阻塞的IO方式。
	非阻塞IO模型(同步IO操作)
		进程发出read操作时、如果内核中的数据还没有准备好、那么它并不会阻塞用户进程、而是立刻返回一个error
	IO复用模型(同步IO操作)
		一个线程,通过记录I/O流的状态来同时管理多个I/O,可以提高服务器的吞吐能力。
		select/poll
			老李去火车站买票,委托黄牛,然后每隔6小时电话黄牛询问,黄牛三天内买到票,然后老李去火车站交钱领票。 耗费：打电话
			select
				单个进程能够监视的文件描述符的数量存在最大限制,通常是1024,当然可以更改数量,但由于select采用轮询的方式扫描文件描述符,文件描述符数量越多,性能越差；(在linux内核头文件中,有这样的定义：#define __FD_SETSIZE 1024)；
			poll
				与select轮询所有待监听的描述符机制类似,但poll使用pollfd结构表示要监听的描述符,poll使用链表保存文件描述符,因此没有了监视文件数量的限制,但其他select的缺点依然存在
		epoll
			老李去火车站买票,委托黄牛,黄牛买到后即通知老李去领,然后老李去火车站交钱领票。 耗费：无需打电话
			epoll使用一个文件描述符管理多个描述符,将用户关系的文件描述符的事件存放到内核的一个事件表中,这样在用户空间和内核空间的copy只需一次
	信号驱动IO模型(同步IO操作)
		信号驱动式IO就是指进程预先告知内核、向内核注册一个信号处理函数、然后用户进程返回不阻塞、当内核数据就绪时会发送一个信号给进程、用户进程便在信号处理函数中调用IO读取数据、从图中明白实际IO内核拷贝到用户进程的过程还是阻塞的、信号驱动式IO并没有实现真正的异步、因为通知到进程之后、依然是由进程来完成IO操作。
		模拟举例：
			老李去火车站买票,给售票员留下电话,有票后,售票员电话通知老李,然后老李去火车站交钱领票。 耗费：无需打电话
	异步IO模型(异步IO操作)
		当内核中有数据报就绪时,由内核将数据报拷贝到应用程序中,返回aio_read中定义好的函数处理程序。
		模拟举例：
			老李去火车站买票,给售票员留下电话,有票后,售票员电话通知老李并快递送票上门。 耗费：无需打电话
长短连接
	短连接的操作步骤是：
		建立连接——数据传输——关闭连接…建立连接——数据传输——关闭连接
	长连接的操作步骤是：
		建立连接——数据传输…（保持连接）…数据传输——关闭连接
	HTTP协议是无状态的,在HTTP/1.0中默认使用短连接,客户端和服务器每进行一次HTTP操作,浏览器就会重新建立一个HTTP会话。
	而从HTTP/1.1起,默认使用长连接,用以保持连接特性,使用长连接的HTTP协议,会在响应头加入这行代码：
	Connection:keep-alive
算法
	图的表示
		邻接列表
			每一个顶点会存储一个从它这里开始的边的列表。比如,如果顶点A 有一条边到B、C和D,那么A的列表中会有3条边。
			<span class="image featured"><img src="{{ 'assets/images/other/mapList.jpg' | relative_url }}" alt="" /></span>
		邻接矩阵
			在邻接矩阵实现中,由行和列都表示顶点,由两个顶点所决定的矩阵对应元素表示这里两个顶点是否相连。
			<span class="image featured"><img src="{{ 'assets/images/other/mapTable.jpg' | relative_url }}" alt="" /></span>
	图的遍历
		广度优先搜索(有些类似树的前序遍历)
			// 初始化所有顶点,标记为未被访问状态
			this.initFlags = function() {
				var flags = [];
				for(var i = 0; i < vertices.length; i++) {
					flags[vertices[i]] = 0;
				}
				return flags;
			}
			this.bfs = function(v) {
				var flags = initFlags(), queue = new Queue();
				// 将未访问顶点压入栈
				queue.enqueue(v);
				while(!queue.isEmpty()) {
					var u = queue.dequeue();
					var neighbors = adjList[u];
			  		// 将顶点标记为已访问但未探索
					flags[u] = 1;
					for (var i = 0; i < neighbors.length; i++) {
						var w = neighbors[i];
						if (flags[w] == 0) {
			      			flags[w] = 1;
							queue.enqueue(w);
						}
					}
			  		// 将顶点标记为已访问且完成探索
					flags[u] = 2;
				}
			}
		深度优先搜索
			this.initFlags = function() {
				var flags = [];
				for(var i = 0; i < vertices.length; i++) {
					flags[vertices[i]] = 0;
				}
				return flags;
			}
			this.dfs = function() {
				var flags = this.initFlags();
				for (var i = 0; i < vertices.length; i++) {
					if (flags[vertices[i]] == 0) {
						this.dfsvisit(vertices[i], flags);
					}
				}
			}
			this.dfsvisit = function(u, flags) {
				flags[u] = 1;
				var neighbors = adjList[u];
				for (var i = 0; i < neighbors.length; i++) {
					var w = neighbors[i];
					if (flags[w] == 0) {
						this.dfsvisit(w, flags);
					}
				}
				flags[u] = 2;
			}
散列函数(最有效的哈希函数之一)
	function times33($str) {
	    $hash = 0;
	    $s    = md5($str);
	    $len  = 32;
	    for ($i = 0; $i < $len; $i++) {
	        $hash = ($hash * 33 + ord($s[$i])) & 0x7FFFFFFF;
	    }
	    return $hash;
	}
LRU算法
	是基于双向链表实现的,下面的图演示了它的原理。其中 head 代表双向链表的表头,tail 代表尾部。首先预先设置 LRU 的容量,如果存储满了,可以通过 O(1) 的时间淘汰掉双向链表的尾部,每次新增和访问数据,都可以通过 O(1)的效率把新的节点增加到队头,或者把已经存在的节点移动到队头。
	<span class="image featured"><img src="{{ 'assets/images/other/lru.jpg' | relative_url }}" alt="" /></span>
网络
	TCP
		协议是一种面向连接,可靠,基于字节流的传输层通信协议；TCP 是全双工模式（同一时刻可以同时发送和接收）
	粘包的问题的解决思路
		粘包问题的最本质原因在与接收对等方无法分辨消息与消息之间的边界在哪。我们通过使用某种方案给出边界,例如：
			1.发送定长包。如果每个消息的大小都是一样的,那么在接收对等方只要累计接收数据,直到数据等于一个定长的数值就将它作为一个消息。
			2.包尾加上\r\n标记。FTP协议正是这么做的。但问题在于如果数据正文中也含有\r\n,则会误判为消息的边界。
			3.包头加上包体长度。包头是定长的4个字节,说明了包体的长度。接收对等方先接收包体长度,依据包体长度来接收包体。
			4.使用更加复杂的应用层协议。
	GET与POST区别
		1.从功能上讲,GET一般用来从服务器上获取资源,POST一般用来更新服务器上的资源；
		2.从REST服务角度上说,GET是幂等的,即读取同一个资源,总是得到相同的数据,而POST不是幂等的,因为每次请求对资源的改变并不是相同的；进一步地,GET不会改变服务器上的资源,而POST会对服务器资源进行改变；
		3.从请求参数形式上看,GET请求的数据会附在URL之后,即将请求数据放置在HTTP报文的 请求头 中,以?分割URL和传输数据,参数之间以&相连。特别地,如果数据是英文字母/数字,原样发送；否则,会将其编码为 application/x-www-form-urlencoded MIME 字符串(如果是空格,转换为+,如果是中文/其他字符,则直接把字符串用BASE64加密,得出如：%E4%BD%A0%E5%A5%BD,其中％XX中的XX为该符号以16进制表示的ASCII)；而POST请求会把提交的数据则放置在是HTTP请求报文的 请求体 中。
		4.就安全性而言,POST的安全性要比GET的安全性高,因为GET请求提交的数据将明文出现在URL上,而且POST请求参数则被包装到请求体中,相对更安全。
		5.从请求的大小看,GET请求的长度受限于浏览器或服务器对URL长度的限制,允许发送的数据量比较小,而POST请求则是没有大小限制的。
	浏览器中输入网址后整体流程
		1.由域名→IP地址:
			寻找IP地址的过程依次经过了浏览器缓存、系统缓存、hosts文件、路由器缓存、 递归搜索根域名服务器。
		2.建立TCP/IP连接（三次握手具体过程）
		3.由浏览器发送一个HTTP请求
		4.经过路由器的转发,通过服务器的防火墙,该HTTP请求到达了服务器
		5.服务器处理该HTTP请求,返回一个HTML文件
		6.浏览器解析该HTML文件,并且显示在浏览器端
		这里需要注意：
			HTTP协议是一种基于TCP/IP的应用层协议,进行HTTP数据请求必须先建立TCP/IP连接
			可以这样理解：HTTP是轿车,提供了封装或者显示数据的具体形式；Socket是发动机,提供了网络通信的能力。
			两个计算机之间的交流无非是两个端口之间的数据通信,具体的数据会以什么样的形式展现是以不同的应用层协议来定义的。
	OSI七层协议
		1.物理层:
			解决硬件之间怎么通信的问题,常见的物理媒介有电缆、光纤、无线电波等,实现了相邻计算机节点之间比特流的透明传送,并尽可能地屏蔽掉具体传输介质和物理设备的差异,使其上层(数据链路层)不必关心网络的具体传输介质。
		2.数据链路层:
			接收来自物理层的位流形式的数据,并封装成帧,传送到上一层；同样,也将来自上层的数据帧,拆装为位流形式的数据转发到物理层。由于各种干扰的存在,物理链路是不可靠的,这一层在物理层提供的比特流的基础上通过差错控制、流量控制方法,使有差错的物理线路变为无差错的数据链路,即提供可靠的通过物理介质传输数据的方法。
		3.网络层:IP/ICMP/IGMP
			将网络地址翻译成对应的物理地址,通过路由选择算法,为报文（该层的数据单位,由上一层数据打包而来）通过通信子网选择最适当的路径。这一层定义的是IP地址,通过IP地址寻址,所以产生了IP协议。
		4.传输层:TCP/UDP
			当发送大量数据时，很可能会出现丢包的情况，另一台电脑要告诉是否完整接收到全部的包。如果缺了，就告诉丢了哪些包，然后再发一次，直至全部接收为止。
			简单来说，传输层的主要功能就是：监控数据传输服务的质量，保证报文的正确传输
		5.会话层:
			建立和管理应用程序之间的通信,用户应用程序和网络之间的接口,建立通信链接,保持会话过程通信链接的畅通,同步两个节点之间的对话,决定通信是否被中断以及通信中断时决定从何处重新发送。
		6.表示层:
			不同系统之间的通信语法问题(比如windows与Linux通信),数据的编码,压缩和解压缩,数据的加密和解密,对来自应用层的命令和数据进行解释,以确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。
		7.应用层:HTTP/HTTPS/FTP/SSH/SMTP/TELNET
			负责完成网络中应用程序与网络操作系统之间的联系,建立与结束使用者之间的联系,并完成网络用户提出的各种网络服务及应用所需的监督、管理和服务等各种协议。此外,该层还负责协调各个应用程序间的工作
		<span class="image featured"><img src="{{ 'assets/images/other/osi_netmodel.png' | relative_url }}" alt="" /></span>
	IP地址分类
		A类地址:以0开头,第一个字节范围:0~127,网络号8位/主机号24位
		B类地址:以10开头,第一个字节范围:128~191,网络号16位/主机号16位
		C类地址:以110开头,第一个字节范围:192~223,网络号24位/主机号8位
		D类地址:以1110开头,第一个字节范围为224~239
		E类地址:以1111开头,保留地址
		相同点：
		（1）都是建立在TCP之上,通过TCP协议来传输数据。
		（2）都是可靠性传输协议。
		（3）都是应用层协议。
		不同点：
		（1）WebSocket支持持久连接,HTTP不支持持久连接。
		（2）WebSocket是双向通信协议,HTTP是单向协议,只能由客户端发起,做不到服务器主动向客户端推送信息。
Go
	defer理解
		如果包含return,则执行顺序为
			给返回值赋值 (rval)
			调用 defer 表达式
			返回给调用函数(ret)
		func main() {
		    fmt.Println(increase(1)) // 返回值是2
		}
		func increase(d int) (ret int) {
			defer func() {
				ret++
			}()
			return d
		}
	如何高效地拼接字符串
		1."+"
			使用+操作符进行拼接时,会对字符串进行遍历,计算并开辟一个新的空间来存储原来的两个字符串。
		2.fmt.Sprintf
			采用了接口参数,必须要用反射获取值,因此有性能损耗
		3.strings.Builder
			用WriteString()进行拼接,内部实现是指针+切片,同时String()返回拼接后的字符串,它是直接把[]byte转换为string,从而避免变量拷贝
				func main() {
				    ss := []string{
				        "A",
				        "B",
				        "C",
				    }
				    var b strings.Builder
				    for _, s := range ss {
				        fmt.Fprint(&b, s)
				    }
				    print(b.String())
				}
		4.bytes.Buffer
			是一个一个缓冲byte类型的缓冲器,这个缓冲器里存放着都是byte
				func main() {
				    ss := []string{
				        "A",
				        "B",
				        "C",
				    }
				    var b bytes.Buffer
				    for _, s := range ss {
				        fmt.Fprint(&b, s)
				    }
				    print(b.String())
				}
		5.strings.join
			strings.join也是基于strings.builder来实现的,并且可以自定义分隔符
				func main(){
			        var s = []string{"11","22","33"}
			        ret := strings.Join(s,"|")
			        fmt.Println(ret) //11|22|33
			    }
		总结:
			strings.Join ≈ strings.Builder > bytes.Buffer > "+" > fmt.Sprintf
	tag的用处
		json序列化或反序列化时字段的名称
		db: sqlx模块中对应的数据库字段名
		form: gin框架中对应的前端的数据字段名
		binding: 搭配 form 使用, 默认如果没查找到结构体中的某个字段则不报错值为空, binding为 required 代表没找到返回错误给前端
	如何知道一个对象是分配在栈上还是堆上
		Go局部变量会进行逃逸分析。如果变量离开作用域后没有被引用,则优先分配到栈上,否则分配到堆上.值类型,通常在栈中分配,引用类型,通常在堆上分配
	简述Go语言GC(垃圾回收)的工作原理
		触发
			触发GC有俩个条件,一是堆内存的分配达到控制器计算的触发堆大小,初始大小环境变量GOGC,之后堆内存达到上一次垃圾收集的 2 倍时才会触发GC。二是如果一定时间内没有触发,就会触发新的循环,该触发条件由runtime.forcegcperiod变量控制,默认为 2 分钟。
		三色标记+混合写屏障:
			所有对象最开始都是白色。
			从main函数开始,对栈与堆进行标色
			GC开始时将栈上可达对象全部标记为黑色（不需要二次扫描,无需STW）
			GC期间,任何栈上创建的新对象均为黑色
			被删除引用的对象标记为灰色
			被添加引用的对象标记为灰色
		<span class="image featured"><img src="{{ 'assets/images/other/go_gc.jpg' | relative_url }}" alt="" /></span>
	函数返回局部变量的指针是否安全？
		在Go里面返回局部变量的指针是安全的。因为Go会进行逃逸分析,如果发现局部变量的作用域超过该函数则会把指针分配到堆区,避免内存泄漏。
	切片是怎么扩容的
		如果当前容量小于1024,则判断所需容量是否大于原来容量2倍,如果大于,当前容量加上所需容量；否则当前容量乘2。
		如果当前容量大于1024,则每次按照1.25倍速度递增容量,也就是每次加上cap/4。
	无缓冲的channel和有缓冲的channel的区别
		对于无缓冲区channel,一直是阻塞的；有缓冲区channel只有缓冲区满之后才会阻塞。
		有缓冲的channel是异步的,而无缓冲channel是同步的。
		channel的机制是先进先出，如果你给channel赋值了，那么必须要读取它的值，不然就会造成阻塞，当然这个只对无缓冲的channel有效。对于有缓冲的channel，发送方会一直阻塞直到数据被拷贝到缓冲区；如果缓冲区已满，则发送方只能在接收方取走数据后才能从阻塞状态恢复。
	控制协程的数目
		可以配合有缓冲的管道来设置
	new和make的区别？
		new只用于分配内存,返回一个指向地址的指针。它为每个新类型分配一片内存,初始化为0且返回类型*T的内存地址,它相当于&T{}
			a := new(int)
			*a = 46
			fmt.Println(*a)
		make只可用于slice,map,channel的初始化,返回的是引用。
	切片赋值与copy
		使用等号赋值,指向同一段内存地址,使用copy()赋值,指向不同的内存地址
		等号赋值会影响新切片的值,使用copy()赋值改变源切片的值不会影响新切片的值
	mutex有几种模式
		正常模式
			当 mutex 调用 Unlock() 方法释放锁资源时,如果发现有等待唤起的 Goroutine 队列时,则会将队头的 Goroutine 唤起。队头的 goroutine 被唤起后,会调用 CAS 方法去尝试性的修改 state 状态,如果修改成功,则表示占有锁资源成功。如果此时有新来的 Goroutine,那么它也会调用 CAS 方法去尝试性的占有资源。但对于 Go 的调度机制来讲,会比较偏向于 CPU 占有时间较短的 Goroutine 先运行,而这将造成一定的几率让新来的 Goroutine 一直获取到锁资源,此时队头的 Goroutine 将一直占用不到,导致饿死
			(注：CAS 在 Go 里用 atomic.CompareAndSwapInt32(addr *int32, old, new int32) 方法实现,CAS 类似于乐观锁作用,修改前会先判断地址值是否还是 old 值,只有还是 old 值,才会继续修改成 new 值,否则会返回 false 表示修改失败。)
		饥饿模式
			判断队头 Goroutine 在超过一定时间后还是得不到资源时,会在 Unlock 释放锁资源时,直接将锁资源交给队头 Goroutine,并且将当前状态改为饥饿模式。
	如何进行调度的。GMP中状态流转
		某个线程尝试创建一个新的G,那么这个G就会被安排到这个线程的G本地队列LRQ中,如果LRQ满了,就会分配到全局队列GRQ中；
		尝试获取当前线程的M,如果无法获取,就会从空闲的M列表中找一个,如果空闲列表也没有,那么就创建一个M,然后绑定G与P运行。
		进入调度循环：
			找到一个合适的G
			执行G,完成以后退出
	字符串调用函数
		// 关键代码
		animal := Animal{}
		reflect.ValueOf(&animal).MethodByName("Eat").Call([]reflect.Value{})
	有三个函数,分别打印"cat", "fish","dog"要求每一个函数都用一个goroutine,按照顺序打印100次
		func Dog() {
			<-fish
			fmt.Println("dog")
			dog <- struct{}{}
		}
		func Cat() {
			<-dog
			fmt.Println("cat")
			cat <- struct{}{}
		}
		func Fish() {
			<-cat
			fmt.Println("fish")
			fish <- struct{}{}
		}
		func main() {
			for i := 0; i < 100; i++ {
				go Dog()
				go Cat()
				go Fish()
			}
			fish <- struct{}{}
			time.Sleep(10 * time.Second)
		}
	go中使用chan要注意什么
		1.当需要不断从channel读取数据时,最好使用for-range读取channel,这样既安全又便利,当channel关闭时,for循环会自动退出
		2.读已关闭的channel会造成零值 ,如果不确定channel,需要使用ok进行检测。
			if v, ok := <-chan;ok{...}
	defer执行顺序
		(注意,是全局变量, 还是局部变量)
		先给返回值赋值,然后调用defer表达式,最后才是返回到调用函数中。
			func f2() (r int) {
				t := 5
				defer func() {
					t = t+5
				}()
				return t
			}
		相当于
			func f22() (r int) {
				t := 5
				r = t //赋值指令
				func() {  //defer 函数被插入到赋值与返回之间执行,这个例子中返回值r没有被修改
					t = t+5
				}
				return   //返回
			}
		返回值为5
线程与子进程
	你用浏览器去打开一个pdf, IE就去调用Acrobat去打开, 这时Acrobat是一个独立的进程, 就是IE的子进程.
	而IE自己本身同时用同一个进程开了2个网页, 并且同时在跑两个网页上的脚本, 这两个网页的执行就是IE自己通过两个线程实现的.
接口安全性
	<span class="image featured"><img src="{{ 'assets/images/other/api_safe.jpg' | relative_url }}" alt="" /></span>
数据库与缓存一致
	要求强一致性，那就不要用缓存
	1.日常推荐,先更新,后删除
		但是写操作基本不会快于读操作，我们做读写分离的意义也是为了让读操作更快！
	2.延迟双删
		读的时候先从Redis读取，如果Redis中没有，那么再去数据库中读，读完之后放回Redis，然后返回响应。写的时候先删除缓存，然后再去写入数据库，然后等待100毫秒再次删除缓存。
	3.rabbitMQ/Kafka订阅MySQL的BinLog动态变化
订单分表原则
	那么订单号里面，最好是要有分库分表信息。淘宝的是在订单号里面添加了卖家id末2位、买家id末2位。
fmt
	Print
		Print系列函数会将内容输出到系统的标准输出，区别在于Print函数直接输出内容，Printf函数支持格式化输出字符串，Println函数会在输出内容的结尾添加一个换行符。
	Fprint
		Fprint系列函数会将内容输出到一个io.Writer接口类型的变量w中，我们通常用这个函数往文件中写入内容。
	Sprint
		Sprint系列函数会把传入的数据生成并返回一个字符串。
重复消费问题
	数据库/Redis存储ID去重
Redis执行lua
	1.直接执行lua命令
		eval 'return "hello" .. KEYS[1] .. ARGV[1]' 1 redis world
	2.直接执行lua文件
		执行命令： redis-cli -a 密码 --eval Lua脚本路径 key [key …] ,  arg [arg …] 
		如：redis-cli -a 123456 --eval ./Redis_CompareAndSet.lua userName , zhangsan lisi
	3.先加载文件,再执行
		script load
		例子：

		redis-cli script load "$(cat del-batch.lua)"
		"e812abcb57c0360287ff97f74e444c04144382c9"
		执行evalsha

		evalsha 脚本sha值 key个数 key列表 参数列表
		如：

		127.0.0.1:6379> evalsha e812abcb57c0360287ff97f74e444c04144382c9 1 A*
		"del pattern is : A*, count is:0"
</pre>