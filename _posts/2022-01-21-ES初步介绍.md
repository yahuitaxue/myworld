---
title: ES初识
author: Yahui
layout: sql
category: SQL
---

书名：《-》

<pre style="text-align: left;">
	提示:
		默认端口9200
	1.核心
		1.搜索,聚合分析,大数据存储
		2.分布式,高性能,高可用,易扩展,易维护
		3.支持文本搜索,结构化数据,非结构化数据,地理位置搜索等(全文检索只是全球众多公司利用ES解决各种挑战的一小部分)
	2.下载
		1.安装Java
		2.安装ES(https://www.elastic.co/cn/downloads/elasticsearch)
			解压后,直接执行bin/elasticsearch.bat即可
			访问http://localhost:9200/
		3.安装kibana(ES的客户端工具https://www.elastic.co/cn/downloads/kibana)
			解压后,直接执行bin/kibana.bat即可
			访问http://localhost:5601
			配置ES服务地址:kibana
			(可以配置中文插件i18n.locale: "zh-CN")
		4.安装Head插件(界面插件git://github.com/mobz/elasticsearch-head.git)
			下载并配置
				// README.textile内容
				git clone git://github.com/mobz/elasticsearch-head.git
				cd elasticsearch-head
				npm install
				npm run start
				open http://localhost:9100
			ES的配置文件(elasticsearch.yml)
				// 如果需要修改服务地址
				network.host: 192.168.0.1
				cluster.initial_master_nodes: ["node-1", "node-2"]
				// 如果访问跨域报错
				http.cors.enabled: true
				http.cors.allow-origin: "*"
		5.安装IK中文分词器插件(https://github.com/medcl/elasticsearch-analysis-ik/releases)
			下载后直接放入ES的插件目录中即可(不是下载的源码,而是jar包)
	3.理解
		1.ES是面向文档,关系型数据库进行对比
			数据库 -> 索引(indices)
			表 -> types(逐渐就被废弃掉)
			行 -> document
			字段 -> fields
		2.一个分片是一个Lucene索引, 一个包含倒排索引的文件目录
		3.查看ik分词
			GET _analyze
			{
			  "analyzer": "ik_smart", // 
			  "text": ["中国人民好幸福"]
			}
			GET _analyze
			{
			  "analyzer": "ik_max_word", // 最大粒度分词
			  "text": ["中国人民好幸福"]
			}
			如果分词并不是想要的, 可以进行手动修改(注意,修改的时候编码必须为utf-8)
			1.在ik插件config目录中,可以看到很多dic的分词文档
			2.创建自定义dic文档
			3.想要认为是一个词的写入文档的一行保存(test.dic, 首行写入"八重神子")
			4.修改配置文件(IKAnalyzer.cfg.xml),将新增的dic文档添加进去
			5.重启ES("八重神子"就会被当做一个完整的词)
	4.操作(Rest风格)
		(同理,这样也是可以使用postman等工具发送请求)
		1.PUT
			声明:
				(增加,如果已经存在则会更新(注意的是,如果是更新,没有的字段则会被删除,所以一般还是处理新增操作))
			模式:
				PUT /index_name(索引名)/type_name(类型(未来就不用了,默认是_doc))/1(文档id)
				{
					(请求体)
				  "name":"heihei",
				  "age":10086
				}
			返回结果:
				{
					"_index" : "index_name",
					"_type" : "type_name",
					"_id" : "1",
					"_version" : 1, // 如果修改的话,版本号会增加
					"result" : "created",
					"_shards" : {
						"total" : 2,
						"successful" : 1,
						"failed" : 0
					},
					"_seq_no" : 0,
					"_primary_term" : 1
				}
			例:
				PUT /test2
				{
					"mappings" : { // 规则
						"properties" : { // 属性
							"name" :{
								"type" : "text"
							},
							"age" :{
								"type" : "long" // 如果类型是keyword,则不会被分词(可以用_analyze来查看)
							}
						}
					}
				}
		2.POST
			1./索引名/类型 (创建)
				POST /index_name/_doc/
				{
				    "name": "hahaha"
				}
			2./索引名/类型/文档id/_update (更新)
				POST /index_name/_doc/1/_update
				{
				  "doc": {
				    "name": "hahaha"
				  }
				}
			3./索引名/类型/_search (查询所有)
				POST /index_name/_doc/_search?q=name:haha
				{
					"took" : 0,
					"timed_out" : false,
					"_shards" : {
						"total" : 1,
						"successful" : 1,
						"skipped" : 0,
						"failed" : 0
					},
					"hits" : {
						"total" : {
						  "value" : 5,
						  "relation" : "eq"
						},
						"max_score" : 0.08701137, // 匹配度
						"hits" : [
							{
								"_index" : "index_name",
								"_type" : "_doc",
								"_id" : "1",
								"_score" : 0.08701137, // 匹配度
								"_source" : {
									"name" : "hahaha",
									"age" : 100089
								}
							},
							{...}
						]
					}
				}
		3.DELETE
			1./索引名称 (删除索引)
			2./索引名称/类型/文档id (删除文档)
		4.GET
			/索引名称/类型/文档id (根据ID查询)
			/索引名称(/类型,也可以不加)/_search (根据条件查询,与POST一样)
				GET /index_name/_doc/_search
				{
				  "query": {
				    "bool": { // 组合查询,过滤多个条件
				      "must": [ // 相当于and查询 -> "must_not"
				      "should": [ // 相当于or查询 -> "should_not"
				        {
				          "match": { // 会使用分词器进行查找,如果用term则是精确查找
				            "name": "hahaha",
				            "tag":"男 技术" // 多个条件查询,只用空格隔开即可
				          },
				          {
				            ...
				          }
				        }
				      ],
				      "filter":{
				        "terms":{
				          "age": [10, 50] // or查询
				        }
				      },
				      "filter":{
				        "range":{ // 区间查找
				          "age":{
				            "gte":10,
				            "let":50
				          }
				        }
				      }
				    }
				  },
				  "_source": [
				    "name"
				  ],
				  "sort": [
				    {
				      "age": {
				        "order": "desc"
				      }
				    }
				  ],
				  "highlight":{ // 高亮查询
				    "pre_tags":"<p class='key' style 'color:red'>", // 自定义标签
				    "post_tags":"</p>",
				      "fields": {
				        "name": {}
				      }
				  },
				  "from": 0, // 分页查询
				  "size": 2
				}
	集群搭建
	1.下载ES,复制多个
	2.配置文件修改
		cluster.name: my-els                               # 集群名称
		node.name: els-node1                               # 节点名称，仅仅是描述名称，用于在日志中区分

		path.data: /opt/elasticsearch/data                 # 数据的默认存放路径
		path.logs: /opt/elasticsearch/log                  # 日志的默认存放路径

		network.host: 192.168.60.201                       # 当前节点的IP地址
		http.port: 9200                                    # 对外提供服务的端口，9300为集群服务的端口

		#添加如下内容
		#culster transport port
		transport.tcp.port: 9300
		transport.tcp.compress: true

		discovery.zen.ping.unicast.hosts: ["192.168.60.201", "192.168.60.202","192.168.60.203"]       
		# 集群个节点IP地址，也可以使用els、els.shuaiguoxia.com等名称，需要各节点能够解析

		discovery.zen.minimum_master_nodes: 2              # 为了避免脑裂，集群节点数最少为 半数+1
	3.倒排索引原理
		term:
			在ES中，关键词被称为term。
		postings list:
			文档列表，作为文档的唯一标识的，ES 会对这些存入的文档进行处理，转化成一个唯一的整型 id，每个文档被分配一个唯一的 id，从0到(2^31)-1。
		term dictionary:
			如何快速的在海量 term 中查询到需要的 term 呢？遍历显然是不够的，于是乎就有了term dictionary，ES 为了能快速查找到 term，将所有的 term 排了一个序，二分法查找。是不是感觉有点眼熟，这不就是 MySQL 的索引方式的，直接用 B+树建立索引词典指向被索引的数据。
		term index:
			那问题又来了，Term Dictionary 应该放在哪里？肯定是放在内存里面吧？磁盘 io 那么慢。就像 MySQL 索引就是存在内存里面了。重点是 ES 默认可是会对全部 字段进行索引，必然会消耗巨大的内存，此时还能放内存吗？内存会爆。于是乎就有了term index 从数据结构上分类算是一个“Trie 树”，也就是我们常说的字典树（这是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题）。这棵树不会包含所有的 term，它包含的是 term 的一些前缀（这也是字典树的使用场景，公共前缀）。通过 term index 可以快速地定位到 term dictionary 的某个 offset，然后从这个位置再往后顺序查找。是不是想查字典，先查偏旁，在到这个偏旁的所有字，再到具体的字。
		Cluster
			代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。
		Shards
			代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。
		replicas
			代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。
		Recovery
			代表数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。
		<span class="image featured"><img src="{{ 'assets/images/other/esBase.jpg' | relative_url }}" alt="" /></span>
		1、每个索引会被分成多个分片shards进行存储，默认创建索引是分配5个分片进行存储。每个分片都会分布式部署在多个不同的节点上进行部署，该分片成为primary shards。
			注意：索引的主分片primary shards定义好后，后面不能做修改。
	　　2、为了实现高可用数据的高可用，主分片可以有对应的备分片replics shards，replic shards分片承载了负责容错、以及请求的负载均衡。
			注意: 每一个主分片为了实现高可用，都会有自己对应的备分片，主分片对应的备分片不能存放同一台服务器上。主分片primary shards可以和其他replics shards存放在同一个node节点上。
	　　3、documnet routing（数据路由）
	 　　　　当客户端发起创建document的时候，es需要确定这个document放在该index哪个shard上。这个过程就是数据路由。
	 　　　　路由算法：shard = hash(routing) % number_of_primary_shards
	 　　　　如果number_of_primary_shards在查询的时候取余发生的变化，无法获取到该数据
	 　　　　注意：索引的主分片数量定义好后，不能被修改
</pre>