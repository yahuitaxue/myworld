---
title: Kafka教程
author: Yahui
layout: Other
category: Other
---

书名:《-》

<pre style="text-align: left;">
<span class="image featured"><img src="{{ 'assets/images/other/kafkaAll.jpg' | relative_url }}" alt="" /></span>
<span class="image featured"><img src="{{ 'assets/images/other/kafkaLine.jpg' | relative_url }}" alt="" /></span>
1.基础概念
	topic：主题,同一类消息抽象的一个概念,Kafka消息发布的所在,kakfa为每个主题(topic)维护了一个分区（partition)的日志结构。每个主题的数据包含一个或多个分区(partiton),每个分区以一个提交日志文件(夹)的形式存在。
	producer：发布者,负责发布消息到kafka集群/服务器
	consumer：订阅者,负责订阅消费kafka集群/服务器中的消息
	consumer group：订阅者组,同一个topic的消息可以被多个consumer订阅消费,这一类consumer就是consumer group
	broker：代理者,单个kafka服务器节点称为broker
	partitionL：分区,一个topic的所有消息数据,被分开存储在不同的地方,这个存储单位称为partition
2.分区原则
	1.如果指定partition,则优先级最高
	2.根据key进行Hash后得出数值,在根据topic的partition数进行求余
	3.没有partition,也没有key则采用粘性分区(随机选择一个分区,然后一直使用该分区,直到分区满了再使用下一个分区)
3.根据实际情况调整生产者分区大小/批次大小(默认16k)
	// 缓冲区大小
	properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,33554432)
	// 批次大小(越大,那么一次提交数据越多,效率越好,但是同步效率越低)(linger.ms:等待时间,如果超过则自动推送,所以过小会造成还未达到指定批次就发送)
	properties.put(ProducerConfig.BATCH_SIZE_CONFIG,16384);
4.数据可靠性
	1.设置应答acks为-1,保证数据的可靠性,牺牲的是效率(0:很少用,1:日志级别,可容忍数据丢失,-1(all,默认):金额级别严谨,不容忍数据丢失)
	2.重试次数为int值的最大值-也就是无限制重试
	3.不同场景
		1.至少一次 (AtLeast Once) = ACK级别设置为1 + 分区副本大于等于2 +ISR里应答的最小副本数量大于等于2
		2.最多一次 (At Most nce) = ACK级别设置为0。
			总结:
				At Least Once可以保证数据不丢失，但是不能保证数据不重复
				At Most Once可以保证数据不重复，但是不能保证数据不丢失。
		3.精确一次 (Exactly One:对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失Kafka 0.11版本以后，引入了一项重大特性:幂等性和事务。
			(幂等性开启配置:enable.idempotence : true(默认)/false)
			1.概念
				1.幂等性就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。
				2.精确一次 (Exactly Once) =幂等性+ 至少一次 ( ack=-1+ 分区副本数=2 + ISR最小副本数量>=2)
				3.重复数据的判断标准:具有<PID,Partition,SegNumber>相同主键的消息提交时，Broker只会持久化一条。
					PID:Kafka每次重启都会分配一个新的
					Partition:表示分区号
					SegNumber:单调自增的序列号
				4.所以幂等性只能保证的是在单分区单会话内不重复。
			2.生产者事务(如果开启幂等,但是kafka重启后,还是会造成重复推送,解决方法只有生产者事务)
				<span class="image featured"><img src="{{ 'assets/images/other/kafkaTransfer.jpg' | relative_url }}" alt="" /></span>
				代码
					package main

					import (
						"fmt"
						"github.com/Shopify/sarama"
					)

					func main() {
						// 配置 Kafka 生产者
						config := sarama.NewConfig()
						config.Producer.RequiredAcks = sarama.WaitForAll
						config.Producer.Retry.Max = 5
						config.Producer.Return.Successes = true

						producer, err := sarama.NewSyncProducer([]string{"localhost:9092"}, config)
						if err != nil {
							fmt.Println("Failed to create producer:", err)
							return
						}
						defer producer.Close()

						// 开启事务
						err = producer.InitTransactions()
						if err != nil {
							fmt.Println("Failed to initialize transactions:", err)
							return
						}

						err = producer.BeginTransaction()
						if err != nil {
							fmt.Println("Failed to begin transaction:", err)
							return
						}

						// 发送消息
						msg := &sarama.ProducerMessage{
							Topic: "test_topic",
							Value: sarama.StringEncoder("Hello, Kafka!"),
						}

						_, _, err = producer.SendMessage(msg)
						if err != nil {
							fmt.Println("Failed to send message:", err)

							// 回滚事务
							err = producer.AbortTransaction()
							if err != nil {
								fmt.Println("Failed to abort transaction:", err)
							}

							return
						}

						// 提交事务
						err = producer.CommitTransaction()
						if err != nil {
							fmt.Println("Failed to commit transaction:", err)
							return
						}

						fmt.Println("Message sent and transaction committed successfully")
					}
					1.在这个例子中，我们使用了Sarama的`NewConfig()`函数来创建一个配置对象，并设置了适当的属性来启用事务。我们还设置了一个唯一的事务ID，以确保幂等性。
					2.然后，我们使用Sarama的`NewSyncProducer()`函数创建一个生产者，并通过传入Kafka集群的地址来初始化它。我们还调用了`BeginTransaction()`函数来开始一个新的事务。
					3.接下来，我们创建了一个`ProducerMessage`对象，并将其发送到当前事务中。您可以根据需要发送多个消息。
					4.最后，我们使用`Commit()`函数提交事务。如果发生错误，我们使用`panic()`函数将其抛出。否则，我们打印一个消息表示事务已成功提交。
					5.注意，在这个例子中，我们使用了`NewSyncProducer()`函数来创建一个同步的生产者，这意味着`Send()`函数将在消息成功发送或发送失败时返回。如果您希望使用异步的生产者，请使用`NewAsyncProducer()`函数，并在需要时设置相应的回调函数。
			3.数据有序
				(max.in.flight.requests.per.connection每个网络连接上可以发送的未经确认的请求的最大数量。)
				1.kafka中1.x版本前单分区内,有序
					// 表示每个broker最多缓存1个请求,类似滑动窗口大小为1
					max.in.flight.requests.per.connection = 1 (不需要考虑是否开启幂等性)
				2.kafka中1.x版本后,max.in.flight.requests.per.connection可以设置小于等于5就可以保证顺序性
					1.未开启幂等性
						max.in.flight.requests.per.connection = 1
					2.开启幂等性
						max.in.flight.requests.per.connection = 5
						原因说明:
							因为在kafkal.x以后，启用幂等后，kafka服务端会缓存producer发来的最近个request的元数据.故无论如何，都可以保证最近5个request的数据都是有序的。
						过程
							1.滑动窗口大小为5
							2.顺序发送过来request1,request2,request3,request4,request5
							3.由于request1,request2返回,进行落盘,request3请求长时间未响应,导致request4,request5已经响应
							4.此时request4,request5不会落盘,而是等待request3响应后,重新进行排序再顺序落盘
			注:
				如果幂等性相同,则内存就会直接丢弃,不会持久化
5.消费模型
	消息由生产者(producer)发送到kafka集群后,会被消费者(consumer)消费。一般来说我们的消费模型有两种:推送模型(psuh)和拉取模型(pull)。
	Kafka采取拉取模型(poll),由自己控制消费速度,以及消费的进度,消费者可以按照任意的偏移量进行消费。比如消费者可以消费已经消费过的消息进行重新处理,或者消费最近的消息等等。
6.工作流程
	<span class="image featured"><img src="{{ 'assets/images/other/kafkaBase.jpg' | relative_url }}" alt="" /></span>
	生产者定期向主题发送消息。
	Kafka代理存储为该特定主题配置的分区中的所有消息。 它确保消息在分区之间平等共享。 如果生产者发送两个消息并且有两个分区,Kafka将在第一分区中存储一个消息,在第二分区中存储第二消息。
	消费者订阅特定主题。
	一旦消费者订阅主题,Kafka将向消费者提供主题的当前偏移,并且还将偏移保存在Zookeeper系综中。
	消费者将定期请求Kafka(如100 Ms)新消息。
	一旦Kafka收到来自生产者的消息,它将这些消息转发给消费者。
	消费者将收到消息并进行处理。
	一旦消息被处理,消费者将向Kafka代理发送确认。
	一旦Kafka收到确认,它将偏移更改为新值,并在Zookeeper中更新它。 由于偏移在Zookeeper中维护,消费者可以正确地读取下一封邮件,即使在服务器暴力期间。
	以上流程将重复,直到消费者停止请求。
	消费者可以随时回退/跳到所需的主题偏移量,并阅读所有后续消息。
7.存储策略
	1、 基于时间,默认配置(log.retention.hours)是168小时（7天）。
		log.retention.check.interval.ms，负责设置检查周期，默认5分钟
		delete 日志删除
			将过期数据删除
			log.cleanup.policy = delete 所有数据启用删除策略
	2、 基于大小,默认配置(log.retention.bytes一般不打开,默认是-1)是1073741824。
8.消费者组
	kafka在发布/订阅模式之上,加入了组group的概念,每一个消费者consumer都属于一个消费组consumer group,每个组group可以有多个消费者consumer,每个消费者也可以加入多个消费组consumer group。发送到主题topic下的消息,会被订阅了这个主题topic的每个消费组consumer group消费。但是注意,一条消息只能被一个消费者组consumer group内的一个消费者consumer消费。 也就是说,假设所有的消费组consumer group都订阅了主题topic,如果所有的消费者consumer都在同一个消费组consumer group中, 那么是P2P模式,消息会在组内所有的消费者consumer之间负载均衡；相反,如果所有的消费者consumer都在自己单独的消费组consumer group中,那么每个消费者consumer都可以同时消费这个主题topic下的消息
9.流程
	1. producer 先从 zookeeper 的 "/brokers/.../state" 节点找到该 partition 的 leader
	2. producer 将消息发送给该 leader
	3. leader 将消息写入本地 log
	4. followers 从 leader pull 消息，写入本地 log 后向leader 发送 ACK
	5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset）并向 producer 发送 ACK
10.扩容
	1.新服务搭建启动kafka
	2.修改配置文件,进行重新分配topic
		[atguigu@hadoop102 kafka]$ vim topics-to-move.json
		{
			"topics": [
				{"topic":"first", "partition":1,"replicas":[0,1]}, // 手动调整话题first为分区1,副本主要分布在broker-id为0与1上
				{"topic":"two"},
				...
			],
			"version": 1
		}
	3.生成计划
		[atguigu@hadoop102 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --topics-to-move-json-file topics-to-move.json --broker-list "0,1,2,3"(这里是每个的brokerID) --generate
	4.将3返回结果(json格式)写入一个自定义的json后缀文件中
	5.执行json存储计划
		[atguigu@hadoop102 kafka]$ bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increase-replication-factor.json --execute
11.缩容
	根据扩容同理修改即可
12.故障处理
	(注意颜色区分先后顺序)
	1.follower宕机
	<span class="image featured"><img src="{{ 'assets/images/other/kafkaBrokenFollower.jpg' | relative_url }}" alt="" /></span>
	1.leader宕机
	<span class="image featured"><img src="{{ 'assets/images/other/kafkaBrokenLeader.jpg' | relative_url }}" alt="" /></span>
13.手动调整副本
	与扩容/收缩相同
14.自动平衡
	一般不开启
15.文件机制
	broker -> topic -> partition -> log(形式上叫log,实际存储就是多个segment) -> segment(默认1G)
	每个segment文件夹包括
		.index
		.log
		.timeindex
16.高效读写
	1.分布式集群,采用分区技术,增加并行
	2.采用稀疏索引,可以快速定位消费的数据
	3.顺序写入磁盘(log追加写入)
	4.页缓存+0拷贝
		(零拷贝（Zero-copy）是一种数据传输技术，它允许数据从生产者端直接传输到消费者端，而无需在中间进行数据拷贝操作。)
		<span class="image featured"><img src="{{ 'assets/images/other/kafkaZeroCopy.jpg' | relative_url }}" alt="" /></span>
		Kafka可以直接在生产者端的发送缓冲区和消费者端的接收缓冲区之间进行数据传输。这种方式可以显著减少数据拷贝操作，提高数据传输的效率和性能。具体来说，在生产者端将数据写入磁盘或网络之前，它可以在内存中保持数据的布局，并且不需要进行中间的内存拷贝操作，直接将数据传输到消费者端。这样可以减少数据拷贝所引入的CPU和内存开销，提高传输速度和系统吞吐量。
17.消费(kafka是采取pull(拉)模式)
	因为kafka是多个消费者可以消费同一数据,所以按照(push(推)模式),不能保证最优的推送速度,所以采用拉模式
	记录消费者消费的偏移量是存储在 offset中(存储在topic中)
	1.消费者组
		1.所有消费者的groupid相同
		2.同一消费者组内消费不同的partition,同一partition不会重复消费
		3.消费者组之间互不影响
		4.如果消费者组的消费者数量多于partition,那么会有消费者不会消费
	2.offset维护
		1. 0.9版本以前是记录在zk中
		2. 0.9后存储在系统主机中topic
		3. 是否自动提交
			1.enable.auto.commit: 是否开启自动提交offset功能，默认是true
			2.auto.commit.interval.ms :自动提交offset的时间间隔，默认是5s
		4. 手动提交(就相当于手动ack)
			commitSync(同步提交) : 必须等待offset提交完毕，再去消费下一批数据。
			commitAsync (异步提交) : 发送完提交offset请求后，就开始消费下一批数据了。
			相同点:都会将本次提交的一批数据最高的偏移量提交。
			不同点:同步提交阻塞当前线程，一直到提交成功，并且会自动失败重试(由不可控因素导致，也会出现提交失败):而异步提交则没有失败重试机制，故有可能提交失败。
	3.一次性消费
		<span class="image featured"><img src="{{ 'assets/images/other/kafkaConsumerTransfer.jpg' | relative_url }}" alt="" /></span>
	4.数据积压
		1.增加分区同时增加消费者
优缺点：
	优点：
		可扩展:Kafka集群可以透明的扩展，增加新的服务器进集群。
		高性能:Kafka性能远超过传统的ActiveMQ、RabbitMQ等，Kafka支持Batch操作。
		容错性:Kafka每个Partition数据会复制到几台服务器，当某个Broker失效时，Zookeeper将通知生产者和消费者从而使用其他的Broker。
	缺点：
		重复消息:Kafka保证每条消息至少送达一次，虽然几率很小，但一条消息可能被送达多次。
		消息乱序:Kafka某一个固定的Partition内部的消息是保证有序的，如果一个Topic有多个Partition，partition之间的消息送达不保证有序。
		复杂性:Kafka需要Zookeeper的支持，Topic一般需要人工创建，部署和维护比一般MQ成本更高。
</pre>